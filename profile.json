{"data":{"user":{"name":"Sohanuzzaman Soad","bio":"Full-Stack Developer || Python & Django || Flutter || Kotlin || Android || Passionate to Create Something Innovative  & Efficient  \r\n","avatarUrl":"https://avatars.githubusercontent.com/u/44132311?u=d415c455a7304ef837ecd6319dc30b4cbe6627b0&v=4","location":"Dhaka,Bangladesh","pinnedItems":{"totalCount":6,"edges":[{"node":{"name":"BankingSystem","description":"Bank Management System using Java Swing","forkCount":101,"stargazers":{"totalCount":129},"url":"https://github.com/ssoad/BankingSystem","id":"MDEwOlJlcG9zaXRvcnkyNTQ5MDgzNzU=","diskUsage":736,"primaryLanguage":{"name":"Java","color":"#b07219"}}},{"node":{"name":"Employee-Management-System","description":"Employee Management System in C By Sohanuzzaman Soad","forkCount":36,"stargazers":{"totalCount":48},"url":"https://github.com/ssoad/Employee-Management-System","id":"MDEwOlJlcG9zaXRvcnkxNzUxNjM0Nzc=","diskUsage":433,"primaryLanguage":{"name":"C","color":"#555555"}}},{"node":{"name":"etaka","description":"eTaka is a Mobile Financial Mobile Application based on P2P Banking Concept for Android and iOS Platform Developed By Flutter and Django REST Backend","forkCount":20,"stargazers":{"totalCount":20},"url":"https://github.com/ssoad/etaka","id":"R_kgDOGOTBjw","diskUsage":8210,"primaryLanguage":{"name":"Dart","color":"#00B4AB"}}},{"node":{"name":"OnlineQuizPlatform","description":"Django Project For an Online Quiz Platform","forkCount":8,"stargazers":{"totalCount":10},"url":"https://github.com/ssoad/OnlineQuizPlatform","id":"MDEwOlJlcG9zaXRvcnkyODY2OTkxNTc=","diskUsage":137459,"primaryLanguage":{"name":"JavaScript","color":"#f1e05a"}}},{"node":{"name":"MyFolio","description":"My PortFolio","forkCount":0,"stargazers":{"totalCount":2},"url":"https://github.com/ssoad/MyFolio","id":"MDEwOlJlcG9zaXRvcnkzMTc5NzkwNjg=","diskUsage":42357,"primaryLanguage":{"name":"JavaScript","color":"#f1e05a"}}},{"node":{"name":"covid19_tracker","description":"COVID19 Tracker App using Worldometer API","forkCount":0,"stargazers":{"totalCount":1},"url":"https://github.com/ssoad/covid19_tracker","id":"MDEwOlJlcG9zaXRvcnkyNjQyNzczODM=","diskUsage":219,"primaryLanguage":{"name":"Dart","color":"#00B4AB"}}}]}},"viewer":{"repositories":{"nodes":[{"id":"MDEwOlJlcG9zaXRvcnkyNTQ5MDgzNzU=","name":"BankingSystem","description":"Bank Management System using Java Swing","url":"https://github.com/ssoad/BankingSystem","updatedAt":"2024-05-29T16:46:32Z","forkCount":101,"openGraphImageUrl":"https://opengraph.githubassets.com/0fb61a2ebb0fd069a1fb9b4d4a948e7e016f9441d6774e8c59ce8d1a99cf34bc/ssoad/BankingSystem","stargazers":{"totalCount":129},"readme":{"text":"# Banking System - Java Swing Project\n\n## Description\nThe Banking System is a Java Swing application that simulates basic banking operations. It provides a user-friendly interface for managing accounts, transactions, and other essential banking functions.\n\n## Features\n- Account creation and management\n- Deposit and withdrawal transactions\n- Balance inquiry\n- Transaction history\n- User-friendly GUI with Java Swing\n\n## Screenshots\n![Screenshot 1](screenshot/1.png)\n![Screenshot 2](screenshot/2.png)\n\n## Technologies Used\n- Java\n- Java Swing for GUI\n\n## Installation\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/your-username/banking-system.git\n   cd banking-system\n   \n   ```\n2. Run Project\n   ```bash\n   javac Main.java\n   java Main\n   ```\n## Usage\n1. Launch the application.\n2. Follow the on-screen instructions to perform banking operations.\n\n## Contribution\nContributions are welcome! If you'd like to contribute to the project, please follow these steps:\n\n1. Fork the repository\n2. Create a new branch (git checkout -b feature/new-feature)\n3. Commit your changes (git commit -m 'Add new feature')\n4. Push to the branch (git push origin feature/new-feature)\n5. Create a pull request\n\n## License\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgments\n- Thanks to Java for the programming language.\n- Special thanks to Java Swing for the GUI components.\n- Feel free to customize the content according to your project's specific details. Add more sections or information as needed.\n"},"licenseInfo":null,"primaryLanguage":{"name":"Java","color":"#b07219"},"languages":{"nodes":[{"name":"Java","color":"#b07219"}]}},{"id":"MDEwOlJlcG9zaXRvcnkxNzUxNjM0Nzc=","name":"Employee-Management-System","description":"Employee Management System in C By Sohanuzzaman Soad","url":"https://github.com/ssoad/Employee-Management-System","updatedAt":"2024-05-16T19:04:19Z","forkCount":36,"openGraphImageUrl":"https://opengraph.githubassets.com/d831d00de57c65112f7113666f06999a8a8a60045d007783be5d795ddbe8bbab/ssoad/Employee-Management-System","stargazers":{"totalCount":48},"readme":{"text":"# EMS-C-Project\nEmployee Management System in C Fully Based in Terminal a Simple but most relevant project of mine. \n\n\n\n\n## INTRODUCTION:\n### What is EMS?\n - Employee Management System is a distributed application, developed to maintain the details of employees working in any organization.\n - The EMS has been developed to override the problems prevailing in the practicing manual system.\n - It maintains the information about the personal and official details of the employees.\n\n\n\n\n## OBJECTIVES OF OUR PROJECT:\n - This project aims to simplify the task of maintaining records of the employees of Company.\n - To develop an well-designed database to store employee information.\n - Provides full functional reports to management of Company.\n - The objective of this project is to provide a comprehensive approach towards the management of employee information.\n\n\n\n## FEATURES :\n - Proper Login Screen (Invisible Password Typing).\n - Password Protected.\n - Encrypted File (Binary).\n - Easily Add, Delete, Modify Records.\n - Various Essential Queries.\n"},"licenseInfo":null,"primaryLanguage":{"name":"C","color":"#555555"},"languages":{"nodes":[{"name":"C","color":"#555555"},{"name":"HTML","color":"#e34c26"}]}},{"id":"R_kgDOGOTBjw","name":"etaka","description":"eTaka is a Mobile Financial Mobile Application based on P2P Banking Concept for Android and iOS Platform Developed By Flutter and Django REST Backend","url":"https://github.com/ssoad/etaka","updatedAt":"2024-05-25T18:58:06Z","forkCount":20,"openGraphImageUrl":"https://opengraph.githubassets.com/767cf76588fbbb08177a7039a3ad273f7c608971fba14240214690132b64095c/ssoad/etaka","stargazers":{"totalCount":20},"readme":{"text":"# etaka\nA Cross Platform Mobile Financial Service (MFS) Application. eTaka is a Mobile Financial Mobile Application based on P2P Banking Concept for Android and iOS Platform Developed By Flutter and Django REST Backend\n\n## ðŸ”¥Project environment\n\n[![eTaka Workflow](https://github.com/ssoad/etaka/actions/workflows/dart.yml/badge.svg)](https://github.com/ssoad/etaka/actions/workflows/dart.yml)\n\n    1. Flutter version 3.3.7\n\n    2. Dart version 2.18.4\n\n\n## âœ¨ Requirements\n* Any Operating System (ie. MacOS X, Linux, Windows)\n* Any IDE with Flutter SDK installed (ie. IntelliJ, Android Studio, VSCode etc)\n* A little knowledge of Dart and Flutter\n* A brain to think ðŸ¤“ðŸ¤“\n\n## ðŸ”¥Usage\n\nMake sure you have Flutter installed on your local machine. For more instructions on how to install flutter, look [here](https://flutter.io/docs/get-started/install).\n```\ngit clone https://github.com/ssoad/etaka.git\ncd etaka\nflutter pub get\nflutter run\n```\n\n## ðŸ“¸ ScreenShots\n\n<img src=\"https://github.com/ssoad/etaka/raw/master/docs/imgs/1.png\" alt=\"drawing\" style=\"width:250px;\"/> <img src=\"https://github.com/ssoad/etaka/raw/master/docs/imgs/2.png\" alt=\"drawing\" style=\"width:250px;\"/> <img src=\"https://github.com/ssoad/etaka/raw/master/docs/imgs/3.png\" alt=\"drawing\" style=\"width:250px;\"/> <img src=\"https://github.com/ssoad/etaka/raw/master/docs/imgs/4.png\" alt=\"drawing\" style=\"width:250px;\"/> <img src=\"https://github.com/ssoad/etaka/raw/master/docs/imgs/5.png\" alt=\"drawing\" style=\"width:250px;\"/> <img src=\"https://github.com/ssoad/etaka/raw/master/docs/imgs/6.png\" alt=\"drawing\" style=\"width:250px;\"/>\n\n## Getting Started\n\nThis project is a starting point for a Flutter application.\n\nA few resources to get you started if this is your first Flutter project:\n\n- [Lab: Write your first Flutter app](https://flutter.dev/docs/get-started/codelab)\n- [Cookbook: Useful Flutter samples](https://flutter.dev/docs/cookbook)\n\nFor help getting started with Flutter, view our\n[online documentation](https://flutter.dev/docs), which offers tutorials,\nsamples, guidance on mobile development, and a full API reference.\n"},"licenseInfo":null,"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyODY2OTkxNTc=","name":"OnlineQuizPlatform","description":"Django Project For an Online Quiz Platform","url":"https://github.com/ssoad/OnlineQuizPlatform","updatedAt":"2024-05-19T16:06:13Z","forkCount":8,"openGraphImageUrl":"https://opengraph.githubassets.com/c2ad035dfd53f909c08e4dd45aa88c0a6d1d3053f221dbd47a8e550702f64515/ssoad/OnlineQuizPlatform","stargazers":{"totalCount":10},"readme":{"text":"# Online Quiz Platform\n![Django CI](https://github.com/ssoad/OnlineQuizPlatform/workflows/Django%20CI/badge.svg)\n##### Requiremnts : \n* Python3 \n* Pycharm \n* Github Desktop or Git \n\n##### Usage : \n\n               git clone https://github.com/ssoad/OnlineQuizPlatform.git\n               cd OnlineQuizPlatform\n               pip install -r requirements.txt\n               python manage.py migrate\n               python manage.py runserver\n\n\nNow go to **127.0.0.1:8000**  from your browser \n\n##### Completed Tasks : \n* Homepage\n* User Authentication\n* Session Management\n* Data Model\n* Data Model Register with Admin\n* HTML For Check Output from Database\n* Required Forms Added\n* Proper UI Implemented\n* Profile Creation & View\n* Exam Creation\n* Exam Enrollment\n* Question & AnswerScript (Upload + Download)\n* Marks Submission\n* Show All Submission\n* Show Results\n* Searching Feature\n* Password Changing System\n* Email Verification System With UID\n* Ranking System (Exam wise)\n* Full Exam Results Log (Examinee & Examiner)\n\n\n##### TODO :\n* Result to PDF (Download)\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTEz"},"primaryLanguage":{"name":"JavaScript","color":"#f1e05a"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"},{"name":"JavaScript","color":"#f1e05a"},{"name":"HTML","color":"#e34c26"},{"name":"CSS","color":"#563d7c"}]}},{"id":"R_kgDOJo1EVA","name":"flutter_websocket_example","description":null,"url":"https://github.com/ssoad/flutter_websocket_example","updatedAt":"2024-04-07T07:21:19Z","forkCount":2,"openGraphImageUrl":"https://opengraph.githubassets.com/c9bac03d622d811be9c84bb1751304173f9aca2195ed6c3ff5d47c88d33b3b3e/ssoad/flutter_websocket_example","stargazers":{"totalCount":3},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"C++","color":"#f34b7d"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"},{"name":"CMake","color":"#DA3434"},{"name":"C++","color":"#f34b7d"},{"name":"C","color":"#555555"},{"name":"HTML","color":"#e34c26"}]}},{"id":"R_kgDOK7dfKA","name":"flutter_getx_clean_architecture","description":null,"url":"https://github.com/ssoad/flutter_getx_clean_architecture","updatedAt":"2024-04-07T07:21:27Z","forkCount":2,"openGraphImageUrl":"https://opengraph.githubassets.com/fb2c9a1e2d316c7fb6f297c4d0807c008eabf3561c01bd2e86dde3b68326ac7b/ssoad/flutter_getx_clean_architecture","stargazers":{"totalCount":2},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Ruby","color":"#701516"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"},{"name":"CMake","color":"#DA3434"},{"name":"C++","color":"#f34b7d"},{"name":"C","color":"#555555"},{"name":"HTML","color":"#e34c26"}]}},{"id":"R_kgDOGuAkCQ","name":"OpenGL_CodeBlocks","description":"Installation Procedure of OpenGL (GLUT 3.0) with CodeBlocks","url":"https://github.com/ssoad/OpenGL_CodeBlocks","updatedAt":"2024-04-07T07:20:50Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/8da1b0af55ae372265493a60acff98b571d14136db81e2454ccd8bbc6e3863bd/ssoad/OpenGL_CodeBlocks","stargazers":{"totalCount":2},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"C","color":"#555555"},"languages":{"nodes":[{"name":"C","color":"#555555"}]}},{"id":"MDEwOlJlcG9zaXRvcnk0MDMzODAzNzE=","name":"BookStore-Java","description":null,"url":"https://github.com/ssoad/BookStore-Java","updatedAt":"2024-04-07T07:20:10Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/e6993728eb1a415117647c0603c623c7386c1dba2cbb735cda859feb4d0e4f42/ssoad/BookStore-Java","stargazers":{"totalCount":2},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Java","color":"#b07219"},"languages":{"nodes":[{"name":"Java","color":"#b07219"}]}},{"id":"MDEwOlJlcG9zaXRvcnkzMTc5NzkwNjg=","name":"MyFolio","description":"My PortFolio","url":"https://github.com/ssoad/MyFolio","updatedAt":"2024-04-07T07:20:27Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/b7e7baeb6a66d1bb6ae4a6123478d38a3b49e7ec1da391c06f1b76ac5ddf335a/ssoad/MyFolio","stargazers":{"totalCount":2},"readme":null,"licenseInfo":{"id":"MDc6TGljZW5zZTEz"},"primaryLanguage":{"name":"JavaScript","color":"#f1e05a"},"languages":{"nodes":[{"name":"JavaScript","color":"#f1e05a"},{"name":"CSS","color":"#563d7c"},{"name":"HTML","color":"#e34c26"},{"name":"Dockerfile","color":"#384d54"},{"name":"SCSS","color":"#c6538c"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyOTg3ODQxMzU=","name":"CompleteDjangoProject","description":"An ecomerece website for learning purposes","url":"https://github.com/ssoad/CompleteDjangoProject","updatedAt":"2024-04-07T07:19:52Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/3e738fe078807bacf574183b87ff966fb47582d428190c5999f80837f3d59cee/ssoad/CompleteDjangoProject","stargazers":{"totalCount":2},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"},{"name":"HTML","color":"#e34c26"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyNzAzNTM5MDE=","name":"Hospital-Management-System","description":"Hospital Management System using Java and MySQL","url":"https://github.com/ssoad/Hospital-Management-System","updatedAt":"2024-04-07T07:21:00Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/3ad41ee882b30e026d26971b8db45834b3e00637d8eb0fef0de798eab050c09e/ssoad/Hospital-Management-System","stargazers":{"totalCount":2},"readme":{"text":"# Hospital-Management-System\nJava mini project Hospital Management System with SQL database.\nTo run this properly use wampserver or another sql server and creat table and database according to project code or modify code accordings to your database & table name.\n\nNote: This is not licensed for marketing or republishing, but you can use it for your personal work. copyright is strictly prohibited.\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTk="},"primaryLanguage":{"name":"Java","color":"#b07219"},"languages":{"nodes":[{"name":"Java","color":"#b07219"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyMjk2MTgxOTk=","name":"Codeforces-Solve","description":"All of Solved problems in CodeForces","url":"https://github.com/ssoad/Codeforces-Solve","updatedAt":"2024-04-07T07:21:24Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/18c9746b66830ea14dbb9569cd43809aba564f069db2234750ca45e8e0139b63/ssoad/Codeforces-Solve","stargazers":{"totalCount":2},"readme":{"text":"# Codeforces Solve\n"},"licenseInfo":null,"primaryLanguage":{"name":"C++","color":"#f34b7d"},"languages":{"nodes":[{"name":"C++","color":"#f34b7d"},{"name":"Python","color":"#3572A5"},{"name":"C#","color":"#178600"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyMTQ0Mjg5MDQ=","name":"UAPQuestionBank","description":"A Question Bank app for University of Asia Pacific","url":"https://github.com/ssoad/UAPQuestionBank","updatedAt":"2024-04-07T07:19:25Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/99837e896bfc133914e20db51e9d893a82dac90a5f25316624d023983f8cc29c/ssoad/UAPQuestionBank","stargazers":{"totalCount":2},"readme":{"text":"# UAPQuestionBank\nA Question Bank app for University of Asia Pacific\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTk="},"primaryLanguage":{"name":"Java","color":"#b07219"},"languages":{"nodes":[{"name":"Java","color":"#b07219"}]}},{"id":"R_kgDOHwbong","name":"Lexical_Analyzer","description":"Complex Lexical Analyzer Using Python 3","url":"https://github.com/ssoad/Lexical_Analyzer","updatedAt":"2024-04-07T07:20:34Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/6a29947129ca051c3729c77e1d3bb2c60e83a4bc81bba4f59bf4d741ad581906/ssoad/Lexical_Analyzer","stargazers":{"totalCount":1},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"C","color":"#555555"},{"name":"Python","color":"#3572A5"}]}},{"id":"R_kgDOHvzZ3g","name":"PyTorch-ImageSegementation","description":"Human Segmentation using PyTorch","url":"https://github.com/ssoad/PyTorch-ImageSegementation","updatedAt":"2024-04-07T07:20:35Z","forkCount":1,"openGraphImageUrl":"https://opengraph.githubassets.com/0b01bfd2093fb43502dbcacb49cc93a0678ca8401a0a64102fbc06fee11dad49/ssoad/PyTorch-ImageSegementation","stargazers":{"totalCount":1},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Jupyter Notebook","color":"#DA5B0B"},"languages":{"nodes":[{"name":"Jupyter Notebook","color":"#DA5B0B"}]}},{"id":"R_kgDOHOZPZA","name":"food_image_classification","description":"Food Image Classification using Food 101 Dataset","url":"https://github.com/ssoad/food_image_classification","updatedAt":"2024-04-07T07:20:42Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/26b4cc00e9184e747b34dc354f35dbf0a354a2c9d047e63aa3d53ac26fd767de/ssoad/food_image_classification","stargazers":{"totalCount":1},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Jupyter Notebook","color":"#DA5B0B"},"languages":{"nodes":[{"name":"Jupyter Notebook","color":"#DA5B0B"}]}},{"id":"MDEwOlJlcG9zaXRvcnk0MDQ3NDc0NTc=","name":"TensorFlow-Tutorials","description":"TensorFlow Tutorials with YouTube Videos","url":"https://github.com/ssoad/TensorFlow-Tutorials","updatedAt":"2024-04-07T07:19:57Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/3721041864872d24aec2b7b69960f17b5bcdbb9925439eeb036e45fe8fc28ae8/ssoad/TensorFlow-Tutorials","stargazers":{"totalCount":1},"readme":{"text":"# TensorFlow Tutorials\n\n[Original repository on GitHub](https://github.com/Hvass-Labs/TensorFlow-Tutorials)\n\nOriginal author is [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org)\n\n## Introduction\n\n* These tutorials are intended for beginners in Deep Learning and TensorFlow.\n* Each tutorial covers a single topic.\n* The source-code is well-documented.\n* There is a [YouTube video](https://www.youtube.com/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ) for each tutorial.\n\n## Tutorials for TensorFlow 2\n\nThe following tutorials have been updated and work with **TensorFlow 2**\n(some of them run in \"v.1 compatibility mode\").\n\n1. Simple Linear Model\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/01_Simple_Linear_Model.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/01_Simple_Linear_Model.ipynb))\n\n2. Convolutional Neural Network\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/02_Convolutional_Neural_Network.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/02_Convolutional_Neural_Network.ipynb))\n\n3-C. Keras API\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/03C_Keras_API.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/03C_Keras_API.ipynb))\n\n10. Fine-Tuning\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/10_Fine-Tuning.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/10_Fine-Tuning.ipynb))\n\n13-B. Visual Analysis for MNIST\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/13B_Visual_Analysis_MNIST.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/13B_Visual_Analysis_MNIST.ipynb))\n\n16. Reinforcement Learning\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/16_Reinforcement_Learning.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/16_Reinforcement_Learning.ipynb))\n\n19. Hyper-Parameter Optimization\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/19_Hyper-Parameters.ipynb)) \n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/19_Hyper-Parameters.ipynb))\n\n20. Natural Language Processing\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/20_Natural_Language_Processing.ipynb)) \n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/20_Natural_Language_Processing.ipynb))\n\n21. Machine Translation\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/21_Machine_Translation.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/21_Machine_Translation.ipynb))\n\n22. Image Captioning\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/22_Image_Captioning.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/22_Image_Captioning.ipynb))\n\n23. Time-Series Prediction\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/23_Time-Series-Prediction.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/23_Time-Series-Prediction.ipynb))\n\n## Tutorials for TensorFlow 1\n\nThe following tutorials only work with the older **TensorFlow 1** API, so you\nwould need to install an older version of TensorFlow to run these. It would take\ntoo much time and effort to convert these tutorials to TensorFlow 2.\n\n3. Pretty Tensor\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/03_PrettyTensor.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/03_PrettyTensor.ipynb))\n\n3-B. Layers API\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/03B_Layers_API.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/03B_Layers_API.ipynb))\n\n4. Save & Restore\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/04_Save_Restore.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/04_Save_Restore.ipynb))\n\n5. Ensemble Learning\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/05_Ensemble_Learning.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/05_Ensemble_Learning.ipynb))\n\n6. CIFAR-10\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/06_CIFAR-10.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/06_CIFAR-10.ipynb))\n\n7. Inception Model\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/07_Inception_Model.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/07_Inception_Model.ipynb))\n\n8. Transfer Learning\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/08_Transfer_Learning.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/08_Transfer_Learning.ipynb))\n\n9. Video Data\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/09_Video_Data.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/09_Video_Data.ipynb))\n\n11. Adversarial Examples\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/11_Adversarial_Examples.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/11_Adversarial_Examples.ipynb))\n\n12. Adversarial Noise for MNIST\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/12_Adversarial_Noise_MNIST.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/12_Adversarial_Noise_MNIST.ipynb))\n\n13. Visual Analysis\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/13_Visual_Analysis.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/13_Visual_Analysis.ipynb))\n\n14. DeepDream\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/14_DeepDream.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/14_DeepDream.ipynb))\n\n15. Style Transfer\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/15_Style_Transfer.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/15_Style_Transfer.ipynb))\n\n17. Estimator API\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/17_Estimator_API.ipynb))\n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/17_Estimator_API.ipynb))\n\n18. TFRecords & Dataset API\n([Notebook](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/18_TFRecords_Dataset_API.ipynb)) \n([Google Colab](https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/18_TFRecords_Dataset_API.ipynb))\n\n## Videos\n\nThese tutorials are also available as [YouTube videos](https://www.youtube.com/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ).\n\n## Translations\n\nThese tutorials have been translated to the following languages:\n\n* [Chinese](https://github.com/Hvass-Labs/TensorFlow-Tutorials-Chinese)\n\n### New Translations\n\nYou can help by translating the remaining tutorials or reviewing the ones that have already been translated. You can also help by translating to other languages.\n\nIt is a very big job to translate all the tutorials, so you should just start with Tutorials #01, #02 and #03-C which are the most important for beginners.\n\n### New Videos\n\nYou are also very welcome to record your own YouTube videos in other languages. It is strongly recommended that you get a decent microphone because good sound quality is very important. I used `vokoscreen` for recording the videos and the free [DaVinci Resolve](https://www.blackmagicdesign.com/products/davinciresolve/) for editing the videos.\n\n## Forks\n\nSee the [selected list of forks](forks.md) for community modifications to these tutorials.\n\n## Installation\n\nThere are different ways of installing and running TensorFlow. This section describes how I did it\nfor these tutorials. You may want to do it differently and you can search the internet for instructions.\n\nIf you are new to using Python and Linux then this may be challenging\nto get working and you may need to do internet searches for error-messages, etc.\nIt will get easier with practice. You can also run the tutorials without installing\nanything by using Google Colab, see further below.\n\nSome of the Python Notebooks use source-code located in different files to allow for easy re-use\nacross multiple tutorials. It is therefore recommended that you download the whole repository\nfrom GitHub, instead of just downloading the individual Python Notebooks.\n\n### Git\n\nThe easiest way to download and install these tutorials is by using git from the command-line:\n\n    git clone https://github.com/Hvass-Labs/TensorFlow-Tutorials.git\n\nThis will create the directory `TensorFlow-Tutorials` and download all the files to it.\n\nThis also makes it easy to update the tutorials, simply by executing this command inside that directory:\n\n    git pull\n\n### Download Zip-File\n\nYou can also [download](https://github.com/Hvass-Labs/TensorFlow-Tutorials/archive/master.zip)\nthe contents of the GitHub repository as a Zip-file and extract it manually.\n\n### Environment\n\nI use [Anaconda](https://www.continuum.io/downloads) because it comes with many Python\npackages already installed and it is easy to work with. After installing Anaconda,\nyou should create a [conda environment](http://conda.pydata.org/docs/using/envs.html)\nso you do not destroy your main installation in case you make a mistake somewhere:\n\n    conda create --name tf python=3\n\nWhen Python gets updated to a new version, it takes a while before TensorFlow also\nuses the new Python version. So if the TensorFlow installation fails, then you may\nhave to specify an older Python version for your new environment, such as: \n\n    conda create --name tf python=3.6\n\nNow you can switch to the new environment by running the following (on Linux):\n\n    source activate tf\n\n### Required Packages\n\nThe tutorials require several Python packages to be installed. The packages are listed in\n[requirements.txt](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/requirements.txt)\n\nTo install the required Python packages and dependencies you first have to activate the\nconda-environment as described above, and then you run the following command\nin a terminal:\n\n    pip install -r requirements.txt\n\nStarting with TensorFlow 2.1 it includes both the CPU and GPU versions and will\nautomatically switch if you have a GPU. But this requires the installation of various\nNVIDIA drivers, which is a bit complicated and is not described here.\n\n### Python Version 3.5 or Later\n\nThese tutorials were developed on Linux using **Python 3.5 / 3.6** (the [Anaconda](https://www.continuum.io/downloads) distribution) and [PyCharm](https://www.jetbrains.com/pycharm/).\n\nThere are reports that Python 2.7 gives error messages with these tutorials. Please make sure you are using **Python 3.5** or later!\n\n## How To Run\n\nIf you have followed the above installation instructions, you should\nnow be able to run the tutorials in the Python Notebooks:\n\n    cd ~/development/TensorFlow-Tutorials/  # Your installation directory.\n    jupyter notebook\n\nThis should start a web-browser that shows the list of tutorials. Click on a tutorial to load it.\n\n### Run in Google Colab\n\nIf you do not want to install anything on your own computer, then the Notebooks\ncan be viewed, edited and run entirely on the internet by using\n[Google Colab](https://colab.research.google.com). There is a\n[YouTube video](https://www.youtube.com/watch?v=Hs6HI2YWchM) explaining how to do this.\nYou click the \"Google Colab\"-link next to each tutorial listed above.\nYou can view the Notebook on Colab but in order to run it you need to login using\nyour Google account.\nThen you need to execute the following commands at the top of the Notebook,\nwhich clones the contents of this repository to your work-directory on Colab.\n\n    # Clone the repository from GitHub to Google Colab's temporary drive.\n    import os\n    work_dir = \"/content/TensorFlow-Tutorials/\"\n    if not os.path.exists(work_dir):\n        !git clone https://github.com/Hvass-Labs/TensorFlow-Tutorials.git\n    os.chdir(work_dir)\n\nAll required packages should already be installed on Colab, otherwise you\ncan run the following command:\n\n    !pip install -r requirements.txt\n\n## Older Versions\n\nSometimes the source-code has changed from that shown in the YouTube videos. This may be due to\nbug-fixes, improvements, or because code-sections are moved to separate files for easy re-use.\n\nIf you want to see the exact versions of the source-code that were used in the YouTube videos,\nthen you can [browse the history](https://github.com/Hvass-Labs/TensorFlow-Tutorials/commits/master)\nof commits to the GitHub repository.\n\n## License (MIT)\n\nThese tutorials and source-code are published under the [MIT License](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/LICENSE)\nwhich allows very broad use for both academic and commercial purposes.\n\nA few of the images used for demonstration purposes may be under copyright. These images are included under the \"fair usage\" laws.\n\nYou are very welcome to modify these tutorials and use them in your own projects.\nPlease keep a link to the [original repository](https://github.com/Hvass-Labs/TensorFlow-Tutorials).\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTEz"},"primaryLanguage":{"name":"Jupyter Notebook","color":"#DA5B0B"},"languages":{"nodes":[{"name":"Jupyter Notebook","color":"#DA5B0B"},{"name":"Python","color":"#3572A5"}]}},{"id":"MDEwOlJlcG9zaXRvcnk0MDM2ODc2Njc=","name":"awesome-public-datasets","description":"A topic-centric list of HQ open datasets.","url":"https://github.com/ssoad/awesome-public-datasets","updatedAt":"2024-04-07T07:19:40Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/da749460ff59ebdceb478c5d9a0499fe7fc4c2073723d455eaa29af22a660cb6/ssoad/awesome-public-datasets","stargazers":{"totalCount":1},"readme":null,"licenseInfo":{"id":"MDc6TGljZW5zZTEz"},"primaryLanguage":null,"languages":{"nodes":[]}},{"id":"MDEwOlJlcG9zaXRvcnkzNTk5NTQ5ODE=","name":"profile-summary-for-github","description":"Tool for visualizing GitHub profiles","url":"https://github.com/ssoad/profile-summary-for-github","updatedAt":"2024-04-07T07:20:02Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/fd9753fcecda18c01411bf4b0fdedaad621b1f87b731a104434b0b4580eb0eaa/ssoad/profile-summary-for-github","stargazers":{"totalCount":1},"readme":{"text":"# profile-summary-for-github\n\n## live at [https://profile-summary-for-github.com/](https://profile-summary-for-github.com/)\n\n## screenshot\n![screenshot](https://user-images.githubusercontent.com/1521451/34072014-4451dbf6-e280-11e7-90a7-32ad1f313541.PNG)\n\n## run locally\n* `git clone https://github.com/tipsy/profile-summary-for-github.git`\n* `cd profile-summary-for-github`\n* `mvn install`\n* `java -jar target/profile-summary-for-github-jar-with-dependencies.jar`\n\nIf no api-token is set, you only get ~50 requests/hour\n\nTo run the app with an api-token, first generate a token at\n[https://github.com/settings/tokens](https://github.com/settings/tokens),\nthen launch the jar with the token:\n\n* `java -Dapi-tokens=your-token -jar target/profile-summary-for-github-jar-with-dependencies.jar`\n\nYou can use a comma-separated list of tokens to increase your rate-limit\n\nYou can build a profile summary for any GitHub profile using `-Dunrestricted=true`:\n\n* `java -Dunrestricted=true -jar target/profile-summary-for-github-jar-with-dependencies.jar`\n\nYou can set when the app should require user-starring by passing `free-requests-cutoff`\nPassing 1000 will require the app to require starring if there are less than 1000 requests left:\n\n* `java -Dfree-requests-cutoff=1000 -jar target/profile-summary-for-github-jar-with-dependencies.jar`\n\nYou can enable Google Tag Manager on your instance by setting `gtm-id`:\n\n* `java -Dgtm-id=GTM-XXXXXX -jar target/profile-summary-for-github-jar-with-dependencies.jar`\n\n## run locally with docker\n\n* `git clone https://github.com/tipsy/profile-summary-for-github.git`\n* `cd profile-summary-for-github`\n* `docker build -t profile-summary-for-github .`\n* `docker run -it --rm --name profile-summary-for-github -p 7070:7070 profile-summary-for-github`\n* OR with a token `docker run -it --rm --name profile-summary-for-github -p 7070:7070 -e \"API_TOKENS=mytoken1,mytoken2\" profile-summary-for-github`\n* browse to http://localhost:7070\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTI="},"primaryLanguage":{"name":"Vue","color":"#41b883"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Dockerfile","color":"#384d54"},{"name":"Vue","color":"#41b883"},{"name":"HTML","color":"#e34c26"}]}},{"id":"MDEwOlJlcG9zaXRvcnkzNDcxNDk4MjE=","name":"siren_arduino","description":null,"url":"https://github.com/ssoad/siren_arduino","updatedAt":"2024-04-07T07:20:01Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/e8b84bf44d23084c3fa6497f801cb08a4302d3901406fabe926a19419d2de469/ssoad/siren_arduino","stargazers":{"totalCount":1},"readme":null,"licenseInfo":{"id":"MDc6TGljZW5zZTI="},"primaryLanguage":{"name":"C++","color":"#f34b7d"},"languages":{"nodes":[{"name":"C++","color":"#f34b7d"}]}},{"id":"MDEwOlJlcG9zaXRvcnkzMzMwNTE3OTY=","name":"coding_test","description":null,"url":"https://github.com/ssoad/coding_test","updatedAt":"2024-04-07T07:19:58Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/3b7de75086ad5c2c35c78c3c0d5cc599b3de0a6600a86ed488b99c9550b6a5d0/ssoad/coding_test","stargazers":{"totalCount":1},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Java","color":"#b07219"},"languages":{"nodes":[{"name":"Java","color":"#b07219"}]}},{"id":"MDEwOlJlcG9zaXRvcnkzMTY3Njg5NTk=","name":"datasharing","description":"The Leek group guide to data sharing ","url":"https://github.com/ssoad/datasharing","updatedAt":"2024-04-07T07:19:54Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/99de3717690f07d7df9d3bb20d2de25a20fe8f6ffec78a87615ae1ffd73c82cc/ssoad/datasharing","stargazers":{"totalCount":1},"readme":{"text":"How to share data with a statistician\n===========\n\nThis is a guide for anyone who needs to share data with a statistician or data scientist. The target audiences I have in mind are:\n\n* Collaborators who need statisticians or data scientists to analyze data for them\n* Students or postdocs in various disciplines looking for consulting advice\n* Junior statistics students whose job it is to collate/clean/wrangle data sets\n\nThe goals of this guide are to provide some instruction on the best way to share data to avoid the most common pitfalls\nand sources of delay in the transition from data collection to data analysis. The [Leek group](http://biostat.jhsph.edu/~jleek/) works with a large\nnumber of collaborators and the number one source of variation in the speed to results is the status of the data\nwhen they arrive at the Leek group. Based on my conversations with other statisticians this is true nearly universally.\n\nMy strong feeling is that statisticians should be able to handle the data in whatever state they arrive. It is important\nto see the raw data, understand the steps in the processing pipeline, and be able to incorporate hidden sources of\nvariability in one's data analysis. On the other hand, for many data types, the processing steps are well documented\nand standardized. So the work of converting the data from raw form to directly analyzable form can be performed \nbefore calling on a statistician. This can dramatically speed the turnaround time, since the statistician doesn't\nhave to work through all the pre-processing steps first. \n\n\nWhat you should deliver to the statistician\n====================\n\nTo facilitate the most efficient and timely analysis this is the information you should pass to a statistician:\n\n1. The raw data.\n2. A [tidy data set](http://vita.had.co.nz/papers/tidy-data.pdf) \n3. A code book describing each variable and its values in the tidy data set.  \n4. An explicit and exact recipe you used to go from 1 -> 2,3 \n\nLet's look at each part of the data package you will transfer. \n\n\n### The raw data\n\nIt is critical that you include the rawest form of the data that you have access to. This ensures\nthat data provenance can be maintained throughout the workflow.  Here are some examples of the\nraw form of data:\n\n* The strange [binary file](http://en.wikipedia.org/wiki/Binary_file) your measurement machine spits out\n* The unformatted Excel file with 10 worksheets the company you contracted with sent you\n* The complicated [JSON](http://en.wikipedia.org/wiki/JSON) data you got from scraping the [Twitter API](https://twitter.com/twitterapi)\n* The hand-entered numbers you collected looking through a microscope\n\nYou know the raw data are in the right format if you: \n\n1. Ran no software on the data\n1. Did not modify any of the data values\n1. You did not remove any data from the data set\n1. You did not summarize the data in any way\n\nIf you made any modifications of the raw data it is not the raw form of the data. Reporting modified data\nas raw data is a very common way to slow down the analysis process, since the analyst will often have to do a\nforensic study of your data to figure out why the raw data looks weird. (Also imagine what would happen if new data arrived?)\n\n### The tidy data set\n\nThe general principles of tidy data are laid out by [Hadley Wickham](http://had.co.nz/) in [this paper](http://vita.had.co.nz/papers/tidy-data.pdf)\nand [this video](http://vimeo.com/33727555). While both the paper and the video describe tidy data using [R](http://www.r-project.org/), the principles\nare more generally applicable:\n\n1. Each variable you measure should be in one column\n1. Each different observation of that variable should be in a different row\n1. There should be one table for each \"kind\" of variable\n1. If you have multiple tables, they should include a column in the table that allows them to be joined or merged\n\nWhile these are the hard and fast rules, there are a number of other things that will make your data set much easier\nto handle. First is to include a row at the top of each data table/spreadsheet that contains full row names. \nSo if you measured age at diagnosis for patients, you would head that column with the name `AgeAtDiagnosis` instead\nof something like `ADx` or another abbreviation that may be hard for another person to understand. \n\n\nHere is an example of how this would work from genomics. Suppose that for 20 people you have collected gene expression measurements with \n[RNA-sequencing](http://en.wikipedia.org/wiki/RNA-Seq). You have also collected demographic and clinical information\nabout the patients including their age, treatment, and diagnosis. You would have one table/spreadsheet that contains the clinical/demographic\ninformation. It would have four columns (patient id, age, treatment, diagnosis) and 21 rows (a row with variable names, then one row\nfor every patient). You would also have one spreadsheet for the summarized genomic data. Usually this type of data\nis summarized at the level of the number of counts per exon. Suppose you have 100,000 exons, then you would have a\ntable/spreadsheet that had 21 rows (a row for gene names, and one row for each patient) and 100,001 columns (one row for patient\nids and one row for each data type). \n\nIf you are sharing your data with the collaborator in Excel, the tidy data should be in one Excel file per table. They\nshould not have multiple worksheets, no macros should be applied to the data, and no columns/cells should be highlighted. \nAlternatively share the data in a [CSV](http://en.wikipedia.org/wiki/Comma-separated_values) or [TAB-delimited](http://en.wikipedia.org/wiki/Tab-separated_values) text file. (Beware however that reading CSV files into Excel can sometimes lead to non-reproducible handling of date and time variables.)\n\n\n### The code book\n\nFor almost any data set, the measurements you calculate will need to be described in more detail than you can or should sneak\ninto the spreadsheet. The code book contains this information. At minimum it should contain:\n\n1. Information about the variables (including units!) in the data set not contained in the tidy data \n1. Information about the summary choices you made\n1. Information about the experimental study design you used\n\nIn our genomics example, the analyst would want to know what the unit of measurement for each\nclinical/demographic variable is (age in years, treatment by name/dose, level of diagnosis and how heterogeneous). They \nwould also want to know how you picked the exons you used for summarizing the genomic data (UCSC/Ensembl, etc.). They\nwould also want to know any other information about how you did the data collection/study design. For example,\nare these the first 20 patients that walked into the clinic? Are they 20 highly selected patients by some characteristic\nlike age? Are they randomized to treatments? \n\nA common format for this document is a Word file. There should be a section called \"Study design\" that has a thorough\ndescription of how you collected the data. There is a section called \"Code book\" that describes each variable and its\nunits. \n\n### How to code variables\n\nWhen you put variables into a spreadsheet there are several main categories you will run into depending on their [data type](http://en.wikipedia.org/wiki/Statistical_data_type):\n\n1. Continuous\n1. Ordinal\n1. Categorical\n1. Missing \n1. Censored\n\nContinuous variables are anything measured on a quantitative scale that could be any fractional number. An example\nwould be something like weight measured in kg. [Ordinal data](http://en.wikipedia.org/wiki/Ordinal_data) are data that have a fixed, small (< 100) number of levels but are ordered. \nThis could be for example survey responses where the choices are: poor, fair, good. [Categorical data](http://en.wikipedia.org/wiki/Categorical_variable) are data where there\nare multiple categories, but they aren't ordered. One example would be sex: male or female. This coding is attractive because it is self-documenting.  [Missing data](http://en.wikipedia.org/wiki/Missing_data) are data\nthat are unobserved and you don't know the mechanism. You should code missing values as `NA`. [Censored data](http://en.wikipedia.org/wiki/Censoring_\\(statistics\\)) are data\nwhere you know the missingness mechanism on some level. Common examples are a measurement being below a detection limit\nor a patient being lost to follow-up. They should also be coded as `NA` when you don't have the data. But you should\nalso add a new column to your tidy data called, \"VariableNameCensored\" which should have values of `TRUE` if censored \nand `FALSE` if not. In the code book you should explain why those values are missing. It is absolutely critical to report\nto the analyst if there is a reason you know about that some of the data are missing. You should also not [impute](http://en.wikipedia.org/wiki/Imputation_\\(statistics\\))/make up/\nthrow away missing observations.\n\nIn general, try to avoid coding categorical or ordinal variables as numbers. When you enter the value for sex in the tidy\ndata, it should be \"male\" or \"female\". The ordinal values in the data set should be \"poor\", \"fair\", and \"good\" not 1, 2 ,3.\nThis will avoid potential mixups about which direction effects go and will help identify coding errors. \n\nAlways encode every piece of information about your observations using text. For example, if you are storing data in Excel and use a form of colored text or cell background formatting to indicate information about an observation (\"red variable entries were observed in experiment 1.\") then this information will not be exported (and will be lost!) when the data is exported as raw text.  Every piece of data should be encoded as actual text that can be exported.  \n\n### The instruction list/script\n\nYou may have heard this before, but [reproducibility is a big deal in computational science](http://www.sciencemag.org/content/334/6060/1226).\nThat means, when you submit your paper, the reviewers and the rest of the world should be able to exactly replicate\nthe analyses from raw data all the way to final results. If you are trying to be efficient, you will likely perform\nsome summarization/data analysis steps before the data can be considered tidy. \n\nThe ideal thing for you to do when performing summarization is to create a computer script (in `R`, `Python`, or something else) \nthat takes the raw data as input and produces the tidy data you are sharing as output. You can try running your script\na couple of times and see if the code produces the same output. \n\nIn many cases, the person who collected the data has incentive to make it tidy for a statistician to speed the process\nof collaboration. They may not know how to code in a scripting language. In that case, what you should provide the statistician\nis something called [pseudocode](http://en.wikipedia.org/wiki/Pseudocode). It should look something like:\n\n1. Step 1 - take the raw file, run version 3.1.2 of summarize software with parameters a=1, b=2, c=3\n1. Step 2 - run the software separately for each sample\n1. Step 3 - take column three of outputfile.out for each sample and that is the corresponding row in the output data set\n\nYou should also include information about which system (Mac/Windows/Linux) you used the software on and whether you \ntried it more than once to confirm it gave the same results. Ideally, you will run this by a fellow student/labmate\nto confirm that they can obtain the same output file you did. \n\n\n\n\nWhat you should expect from the analyst\n====================\n\nWhen you turn over a properly tidied data set it dramatically decreases the workload on the statistician. So hopefully\nthey will get back to you much sooner. But most careful statisticians will check your recipe, ask questions about\nsteps you performed, and try to confirm that they can obtain the same tidy data that you did with, at minimum, spot\nchecks.\n\nYou should then expect from the statistician:\n\n1. An analysis script that performs each of the analyses (not just instructions)\n1. The exact computer code they used to run the analysis\n1. All output files/figures they generated. \n\nThis is the information you will use in the supplement to establish reproducibility and precision of your results. Each\nof the steps in the analysis should be clearly explained and you should ask questions when you don't understand\nwhat the analyst did. It is the responsibility of both the statistician and the scientist to understand the statistical\nanalysis. You may not be able to perform the exact analyses without the statistician's code, but you should be able\nto explain why the statistician performed each step to a labmate/your principal investigator. \n\n\nContributors\n====================\n\n* [Jeff Leek](http://biostat.jhsph.edu/~jleek/) - Wrote the initial version.\n* [L. Collado-Torres](http://bit.ly/LColladoTorres) - Fixed typos, added links.\n* [Nick Reich](http://people.umass.edu/nick/) - Added tips on storing data as text.\n* [Nick Horton](https://www.amherst.edu/people/facstaff/nhorton) - Minor wording suggestions.\n\n\n"},"licenseInfo":null,"primaryLanguage":null,"languages":{"nodes":[]}},{"id":"MDEwOlJlcG9zaXRvcnkzMTY3Njc5NTM=","name":"datasciencecoursera","description":null,"url":"https://github.com/ssoad/datasciencecoursera","updatedAt":"2024-04-07T07:19:56Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/b4a99f85189e1b76e769f96ea7212f9b33f3a90416c0da0e06bbaac4fca99a77/ssoad/datasciencecoursera","stargazers":{"totalCount":1},"readme":null,"licenseInfo":null,"primaryLanguage":null,"languages":{"nodes":[]}},{"id":"MDEwOlJlcG9zaXRvcnkzMTIwNzcwNTU=","name":"weather_app","description":null,"url":"https://github.com/ssoad/weather_app","updatedAt":"2024-04-07T07:19:53Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/078536f2d18237e82e65385f710797ef2584bf023fc7b0c4557ffdfe6eec20fe/ssoad/weather_app","stargazers":{"totalCount":1},"readme":{"text":"# weather_app\n\nA Weather App in Flutter\n\n## Getting Started\n\nThis project is a starting point for a Flutter application.\n\nA few resources to get you started if this is your first Flutter project:\n\n- [Lab: Write your first Flutter app](https://flutter.dev/docs/get-started/codelab)\n- [Cookbook: Useful Flutter samples](https://flutter.dev/docs/cookbook)\n\nFor help getting started with Flutter, view our\n[online documentation](https://flutter.dev/docs), which offers tutorials,\nsamples, guidance on mobile development, and a full API reference.\n"},"licenseInfo":null,"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyOTg3ODQwMjY=","name":"Complete-Django-Project-B","description":null,"url":"https://github.com/ssoad/Complete-Django-Project-B","updatedAt":"2024-04-07T07:19:48Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/b466cdde6e17bb314240f125fcf70d9cc55475ec2451075a4beeeb1d40438680/ssoad/Complete-Django-Project-B","stargazers":{"totalCount":1},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"},{"name":"HTML","color":"#e34c26"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyOTUyMzM0MDY=","name":"django_eCommerce","description":null,"url":"https://github.com/ssoad/django_eCommerce","updatedAt":"2024-04-07T07:19:49Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/df3dd3111a3d6cbc022d888359946eaf9fe61d8a9c2d22c4449461abb06e43d4/ssoad/django_eCommerce","stargazers":{"totalCount":1},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyOTE1NTY5ODY=","name":"reactos","description":"A free Windows-compatible Operating System","url":"https://github.com/ssoad/reactos","updatedAt":"2024-04-07T07:19:43Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/b566ef67870194557ef5b4e9b71cd3c380cf6e63b763302bba42b872d3365449/ssoad/reactos","stargazers":{"totalCount":1},"readme":{"text":"<p align=center>\n  <a href=\"https://reactos.org/\">\n    <img alt=\"ReactOS\" src=\"https://reactos.org/wiki/images/0/02/ReactOS_logo.png\">\n  </a>\n</p>\n\n---\n\n<p align=center>\n  <a href=\"https://reactos.org/project-news/reactos-0413-released/\">\n    <img alt=\"ReactOS 0.4.13 Release\" src=\"https://img.shields.io/badge/release-0.4.13-0688CB.svg\">\n  </a>\n  <a href=\"https://reactos.org/download/\">\n    <img alt=\"Download ReactOS\" src=\"https://img.shields.io/badge/download-latest-0688CB.svg\">\n  </a>\n  <a href=\"https://sourceforge.net/projects/reactos/\">\n    <img alt=\"SourceForge Download\" src=\"https://img.shields.io/sourceforge/dm/reactos.svg?colorB=0688CB\">\n  </a>\n  <a href=\"https://github.com/reactos/reactos/blob/master/COPYING\">\n    <img alt=\"License\" src=\"https://img.shields.io/badge/license-GNU_GPL_2.0-0688CB.svg\">\n  </a>\n  <a href=\"https://reactos.org/donate/\">\n    <img alt=\"Donate\" src=\"https://img.shields.io/badge/%24-donate-E44E4A.svg\">\n  </a>\n  <a href=\"https://twitter.com/reactos\">\n    <img alt=\"Follow on Twitter\" src=\"https://img.shields.io/twitter/follow/reactos.svg?style=social&label=Follow%20%40reactos\">\n  </a>\n</p>\n\n## Quick Links\n[Website](https://reactos.org/) &bull;\n[Official chat](https://chat.reactos.org/) &bull;\n[Wiki](https://reactos.org/wiki/) &bull;\n[Forum](https://reactos.org/forum/) &bull;\n[JIRA Bug Tracker](https://jira.reactos.org/issues/) &bull;\n[ReactOS Git mirror](https://git.reactos.org/) &bull;\n[Testman](https://reactos.org/testman/)\n\n## What is ReactOS?\n\nReactOSâ„¢ is an Open Source effort to develop a quality operating system that is compatible with applications and drivers written for the MicrosoftÂ® Windowsâ„¢ NT family of operating systems (NT4, 2000, XP, 2003, Vista, Seven).\n\nThe ReactOS project, although currently focused on Windows Server 2003 compatibility, is always keeping an eye toward compatibility with Windows Vista and future Windows NT releases.\n\nThe code of ReactOS is licensed under [GNU GPL 2.0](https://github.com/reactos/reactos/blob/master/COPYING).\n\n***ReactOS is currently an Alpha quality operating system. This means that ReactOS is under heavy development, things may not work well and it can corrupt the data present on your hard disk. It is recommended to test ReactOS on a virtual machine or on a computer with no sensitive or critical data!***\n\n## Building\n\n![Build](https://github.com/reactos/reactos/workflows/Build/badge.svg) [![rosbewin.badge]][rosbewin.link] [![rosbeunix.badge]][rosbeunix.link] [![coverity.badge]][coverity.link]\n\nTo build the system it is strongly advised to use the _ReactOS Build Environment (RosBE)._\nUp-to-date versions for Windows and for Unix/GNU-Linux are available from our download page at: [\"Build Environment\"](https://reactos.org/wiki/Build_Environment).\n\nAlternatively one can use Microsoft Visual C++ (MSVC) version 2015+. Building with MSVC is covered here: [\"Visual Studio or Microsoft Visual C++\"](https://reactos.org/wiki/CMake#Visual_Studio_or_Microsoft_Visual_C.2B.2B).\n\nSee [\"Building ReactOS\"](https://reactos.org/wiki/Building_ReactOS) article for more details.\n\n### Binaries\n\nTo build ReactOS you must run the `configure` script in the directory you want to have your build files. Choose `configure.cmd` or `configure.sh` depending on your system. Then run `ninja <modulename>` to build a module you want or just `ninja` to build all modules.\n\n### Bootable images\n\nTo build a bootable CD image run `ninja bootcd` from the build directory. This will create a CD image with a filename `bootcd.iso`.\n\nYou can always download fresh binary builds of bootable images from the [\"Daily builds\"](https://reactos.org/getbuilds/) page.\n\n## Installing\n\nBy default, ReactOS currently can only be installed on a machine that has a FAT16 or FAT32 partition as the active (bootable) partition.\nThe partition on which ReactOS is to be installed (which may or may not be the bootable partition) must also be formatted as FAT16 or FAT32.\nReactOS Setup can format the partitions if needed.\n\nStarting with 0.4.10, ReactOS can be installed using the BtrFS file system. But consider this as an experimental feature and thus regressions not triggered on FAT setup may be observed.\n\nTo install ReactOS from the bootable CD distribution, extract the archive contents. Then burn the CD image, boot from it, and follow the instructions.\n\nSee [\"Installing ReactOS\"](https://reactos.org/wiki/Installing_ReactOS) Wiki page or [INSTALL](INSTALL) for more details.\n\n## Testing\n\nIf you discover a bug in ReactOS search on JIRA first - it might be reported already. If not report the bug providing logs and as much information as possible.\n\nSee [\"File Bugs\"](https://reactos.org/wiki/File_Bugs) for a guide.\n\n__NOTE:__ The bug tracker is _not_ for discussions. Please use our [official chat](https://chat.reactos.org/) or our [forum](https://reactos.org/forum/).\n\n## Contributing  [![prwelcome.badge]](https://reactos.org/wiki/Commiting_Changes)\n\nWe are always looking for developers! Check [how to contribute](CONTRIBUTING.md) if you are willing to participate.\n\n__Legal notice__: If you have seen proprietary Microsoft Windows source code (including but not limited to the leaked Windows NT 3.5, NT 4, 2000 source code and the Windows Research Kernel), your contribution won't be accepted because of potential copyright violation.\n\nTry out cloud-based ReactOS development using Gitpod and Docker:\n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/reactos/reactos)\n\nYou can also support ReactOS by [donating](https://reactos.org/donate/)! We rely on our backers to maintain our servers and accelerate development by [hiring full-time devs](https://reactos.org/contributing/#paid-jobs).\n\n## More information\n\nReactOS is a Free and Open Source operating system based on the Windows architecture,\nproviding support for existing applications and drivers, and an alternative to the current dominant consumer operating system.\n\nIt is not another wrapper built on Linux, like WINE. It does not attempt or plan to compete with WINE; in fact, the user-mode part of ReactOS is almost entirely WINE-based and our two teams have cooperated closely in the past.\n\nReactOS is also not \"yet another OS\". It does not attempt to be a third player like any other alternative OS out there. People are not meant to uninstall Linux and use ReactOS instead; ReactOS is a replacement for Windows users who want a Windows replacement that behaves just like Windows.\n\nMore information is available at: [reactos.org](https://reactos.org/).\n\nAlso see the [media/doc](/media/doc/) subdirectory for some sparse notes.\n\n## Who is responsible\n\nActive devs are listed as members of [GitHub organization](https://github.com/orgs/reactos/people).\nSee also the [CREDITS](CREDITS) file for others.\n\n## Code mirrors\n\nThe main development is done on [GitHub](https://github.com/reactos/reactos). We have an [alternative mirror](https://git.reactos.org/?p=reactos.git) in case GitHub is down.\n\nThere is also an obsolete [SVN archive repository](https://svn.reactos.org/reactos/) that is kept for historical purposes.\n\n[coverity.badge]:   https://scan.coverity.com/projects/205/badge.svg?flat=1\n[rosbewin.badge]:   https://img.shields.io/badge/RosBE_Windows-2.2.0-0688CB.svg\n[rosbeunix.badge]:  https://img.shields.io/badge/RosBE_Unix-2.2-0688CB.svg\n[prwelcome.badge]:  https://img.shields.io/badge/PR-welcome-0688CB.svg\n\n[coverity.link]:    https://scan.coverity.com/projects/205\n[rosbewin.link]:    https://sourceforge.net/projects/reactos/files/RosBE-Windows/i386/2.2.0/\n[rosbeunix.link]:   https://sourceforge.net/projects/reactos/files/RosBE-Unix/2.2/\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTg="},"primaryLanguage":{"name":"C","color":"#555555"},"languages":{"nodes":[{"name":"CMake","color":"#DA3434"},{"name":"C++","color":"#f34b7d"},{"name":"C","color":"#555555"},{"name":"Python","color":"#3572A5"},{"name":"Objective-C","color":"#438eff"},{"name":"HTML","color":"#e34c26"},{"name":"Batchfile","color":"#C1F12E"},{"name":"Shell","color":"#89e051"},{"name":"Makefile","color":"#427819"},{"name":"Ruby","color":"#701516"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyOTAyODk2NDY=","name":"SummaryGenerator","description":"Automated Summary Generator form huge text","url":"https://github.com/ssoad/SummaryGenerator","updatedAt":"2024-04-07T07:19:47Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/916c5f206eb20eca4a95bea21d40a126a6cf87d9453f3312975e44c498fd652b/ssoad/SummaryGenerator","stargazers":{"totalCount":1},"readme":{"text":"\n# SummaryGenerator\n\n\n[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/)\n\n\nAutomated Summary Generator form huge text\n\n## Usage : \n\n                    git clone https://github.com/sohanuzzamansoad/SummaryGenerator.git\n                    cd SummaryGenerator\n                    python generate.py\n\n\nNow go to **127.0.0.1:5000**  from your browser \n"},"licenseInfo":{"id":"MDc6TGljZW5zZTk="},"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"},{"name":"HTML","color":"#e34c26"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyNzkwMzgyNzk=","name":"CSE_310_18101064","description":null,"url":"https://github.com/ssoad/CSE_310_18101064","updatedAt":"2024-04-07T07:19:46Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/c959552f4c10a421744c0be7f06cdb59abc4b7aaa7d4e9328fc5e3547a0cfc5f/ssoad/CSE_310_18101064","stargazers":{"totalCount":1},"readme":{"text":"# CSE 310- Object Oriented Programming II:Visual and Web Programming\n### Spring 2020\n**In this Repository I store all of my OOP-2 Lab (Python and django) works may be It can help you**\n\n\nDocumentation\n---------------------\nYou will find complete documentation for python at  [Documentation](https://docs.python.org)<br>\nYou will find complete documentation for Colab at  [Documentation](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.01-Help-And-Documentation.ipynb)\n\n\n\n"},"licenseInfo":null,"primaryLanguage":{"name":"Jupyter Notebook","color":"#DA5B0B"},"languages":{"nodes":[{"name":"Jupyter Notebook","color":"#DA5B0B"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyNzI4MDE5NzI=","name":"it-cert-automation-practice","description":"Google IT Automation with Python Professional Certificate - Practice files","url":"https://github.com/ssoad/it-cert-automation-practice","updatedAt":"2024-04-07T07:19:39Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/98c0970fa04bd4ade142594f804fe4125f3be43dd910cf0375d4da36ddce7ba7/ssoad/it-cert-automation-practice","stargazers":{"totalCount":1},"readme":{"text":"# Google IT Automation with Python Professional Certificate - Practice files\n\nThis repository contains the practice files used throughout the courses that are\npart of the Google IT Automation with Python Professional Certificate\n\nThere's a separate folder for each course.\n\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTI="},"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyNzIyNTkyMTA=","name":"coursera","description":null,"url":"https://github.com/ssoad/coursera","updatedAt":"2024-04-07T07:19:38Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/5d1ca5407687d378e6c4b663200545dfd3e9ffd5cd6061d086b6a4f7444e0a33/ssoad/coursera","stargazers":{"totalCount":1},"readme":{"text":"I am editing the README file. Adding some more details about the project description.\n"},"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyNjQyNzczODM=","name":"covid19_tracker","description":"COVID19 Tracker App using Worldometer API","url":"https://github.com/ssoad/covid19_tracker","updatedAt":"2024-04-07T07:19:37Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/2772d08a09f3ff06b41c02d07c53b0e52b921dd5e76b5b277bd4bb4cd92da425/ssoad/covid19_tracker","stargazers":{"totalCount":1},"readme":{"text":"# covid19_tracker\n\nCOVID-19 Tracker using Worldometer API\n\n## Getting Started\n\nThis project is a starting point for a Flutter application.\n\nA few resources to get you started if this is your first Flutter project:\n\n- [Lab: Write your first Flutter app](https://flutter.dev/docs/get-started/codelab)\n- [Cookbook: Useful Flutter samples](https://flutter.dev/docs/cookbook)\n\nFor help getting started with Flutter, view our\n[online documentation](https://flutter.dev/docs), which offers tutorials,\nsamples, guidance on mobile development, and a full API reference.\n"},"licenseInfo":null,"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"},{"name":"Java","color":"#b07219"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyNjM5NDY5MDY=","name":"evaly_cashback","description":"Evaly Cashback Calulator","url":"https://github.com/ssoad/evaly_cashback","updatedAt":"2024-04-07T07:19:27Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/4f77e7aa3daf97eccd71b6d6a4d7e8011386d94c7de5c676124545d994c1085d/ssoad/evaly_cashback","stargazers":{"totalCount":1},"readme":{"text":"# evalycashback\n\nEvaly Cashback Calculator\n\n## Getting Started\n\nThis project is a starting point for a Flutter application.\n\nA few resources to get you started if this is your first Flutter project:\n\n- [Lab: Write your first Flutter app](https://flutter.dev/docs/get-started/codelab)\n- [Cookbook: Useful Flutter samples](https://flutter.dev/docs/cookbook)\n\nFor help getting started with Flutter, view our\n[online documentation](https://flutter.dev/docs), which offers tutorials,\nsamples, guidance on mobile development, and a full API reference.\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTk="},"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyNjMzMTk5MjA=","name":"CLima_WeatherApp","description":"A Real time Weather App using Openweather API","url":"https://github.com/ssoad/CLima_WeatherApp","updatedAt":"2024-04-07T07:19:26Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/51f59650487a89abb0a5a51f58129082052706b38e51b30f21603be07a7adde9/ssoad/CLima_WeatherApp","stargazers":{"totalCount":1},"readme":{"text":"# clima\n\nA Real time Weather App using Openweather API\n\n## Getting Started\n\nThis project is a starting point for a Flutter application.\n\nA few resources to get you started if this is your first Flutter project:\n\n- [Lab: Write your first Flutter app](https://flutter.dev/docs/get-started/codelab)\n- [Cookbook: Useful Flutter samples](https://flutter.dev/docs/cookbook)\n\nFor help getting started with Flutter, view our\n[online documentation](https://flutter.dev/docs), which offers tutorials,\nsamples, guidance on mobile development, and a full API reference.\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTk="},"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyNTcwODQzNjI=","name":"Advanced_Supply_Chain_Database","description":"Supply Chain Management System Database using SQL Server","url":"https://github.com/ssoad/Advanced_Supply_Chain_Database","updatedAt":"2024-04-07T07:20:55Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/da7acaaae5b0553d11deff80521aa86cb478f4ab57b778a72fb227a15d820336/ssoad/Advanced_Supply_Chain_Database","stargazers":{"totalCount":1},"readme":{"text":"# Advanced_Supply_Chain_Database\n Supply Chain Management System Database using SQL Server\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTk="},"primaryLanguage":null,"languages":{"nodes":[]}},{"id":"MDEwOlJlcG9zaXRvcnkyNTIxNzYwMjU=","name":"ssoad.github.io","description":"This Repository is created for my Portfolio","url":"https://github.com/ssoad/ssoad.github.io","updatedAt":"2024-06-09T17:39:23Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/dc8a552354e410807183266183222bdacb5620e0bf7c07bde71897a229bf85e7/ssoad/ssoad.github.io","stargazers":{"totalCount":1},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"HTML","color":"#e34c26"},"languages":{"nodes":[{"name":"HTML","color":"#e34c26"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyNTE3MTAwNjI=","name":"FlutterTravel","description":"Flutter representation of a Travel App Concept.","url":"https://github.com/ssoad/FlutterTravel","updatedAt":"2024-04-07T07:19:42Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/632523c0accaba159abc06f2950975d7ea5d2d17213874c53ffb2f9f684f7152/ssoad/FlutterTravel","stargazers":{"totalCount":1},"readme":{"text":"\n# ðŸ›«Flutter Travel App Concept [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)\n\nFlutter representation of a Travel App Concept i found in Uplabs. \n**It only consists of 2 screens.**\n\nStarâ­ the repo if you like what you seeðŸ˜‰.\n\n\nImages are from [Unsplash](https://unsplash.com)\n## ðŸ“¸ ScreenShots\n\n<img src=\"ss/1.png\"/>\n\n| 1 | 2|\n|------|-------|\n|<img src=\"ss/2.png\" width=\"400\">|<img src=\"ss/3.png\" width=\"400\">|\n\n| 3 | 4|\n|------|-------|\n|<img src=\"ss/4.png\" width=\"400\">|<img src=\"ss/5.png\" width=\"400\">|\n\n\n## Toggle theme\nTo toggle the theme, change the `isDark` variable in `main.dart`.\n\n`true` for dark and `false` for light.\n\n## âœ¨ Requirements\n* Any Operating System (ie. MacOS X, Linux, Windows)\n* Any IDE with Flutter SDK installed (ie. IntelliJ, Android Studio, VSCode etc)\n* A little knowledge of Dart and Flutter\n* A brain to think ðŸ¤“ðŸ¤“\n\n## ðŸ¤“ Author(s)\n**Sohanuzzaman Soad**\n\n\n## Getting Started\n\nThis project is a starting point for a Flutter application.\n\nA few resources to get you started if this is your first Flutter project:\n\n- [Lab: Write your first Flutter app](https://flutter.io/docs/get-started/codelab)\n- [Cookbook: Useful Flutter samples](https://flutter.io/docs/cookbook)\n\nFor help getting started with Flutter, view our \n[online documentation](https://flutter.io/docs), which offers tutorials, \nsamples, guidance on mobile development, and a full API reference.\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTE4"},"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyNTE3MDkxOTE=","name":"BMI_Calculator","description":"A Beautiful  BMI Calculator App using flutter","url":"https://github.com/ssoad/BMI_Calculator","updatedAt":"2024-04-07T07:19:29Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/f312409e86dcae3eef7ee8f9d91a737e941a046e68de4386793bd151b1c40044/ssoad/BMI_Calculator","stargazers":{"totalCount":1},"readme":{"text":"# BMI_Calculator\n A Beautiful  BMI Calculator App usimg flutter\n\n\n\n## Toggle theme\nTo toggle the theme, change the `isDark` variable in `main.dart`.\n\n`true` for dark and `false` for light.\n\n## âœ¨ Requirements\n* Any Operating System (ie. MacOS X, Linux, Windows)\n* Any IDE with Flutter SDK installed (ie. IntelliJ, Android Studio, VSCode etc)\n* A little knowledge of Dart and Flutter\n* A brain to think ðŸ¤“ï¿½ï¿½ï¿½\n\n## ðŸ¤“ Author(s)\n**Sohanuzzaman Soad**\n\n\n ## Getting Started\n\nThis project is a starting point for a Flutter application.\n\nA few resources to get you started if this is your first Flutter project:\n\n- [Lab: Write your first Flutter app](https://flutter.io/docs/get-started/codelab)\n- [Cookbook: Useful Flutter samples](https://flutter.io/docs/cookbook)\n\nFor help getting started with Flutter, view our \n[online documentation](https://flutter.io/docs), which offers tutorials, \nsamples, guidance on mobile development, and a full API reference.\n\n"},"licenseInfo":null,"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyMDI3NTYxMTU=","name":"Hacker-Rank-Problem-Solve","description":"Hacker Rank Problem Solve","url":"https://github.com/ssoad/Hacker-Rank-Problem-Solve","updatedAt":"2024-04-07T07:20:23Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/509b26d35d2656006242c9594813c4c1b9e735c2ccb8bc9032cc25a9653ebaed/ssoad/Hacker-Rank-Problem-Solve","stargazers":{"totalCount":1},"readme":{"text":"# Hacker-Rank Activites\n\n## 30Day Code Challenge\n\n## C-Language\n\n## Problem Solving\n\n## ProjectEuler+\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTMy"},"primaryLanguage":{"name":"C","color":"#555555"},"languages":{"nodes":[{"name":"C","color":"#555555"},{"name":"Java","color":"#b07219"},{"name":"C++","color":"#f34b7d"}]}},{"id":"R_kgDOMGXy7Q","name":"dokan","description":null,"url":"https://github.com/ssoad/dokan","updatedAt":"2024-06-07T17:58:17Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/ae8d9773c01286b2c8ede5cf450dab57a98c9894f51b1971893f8469386b7c08/ssoad/dokan","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Ruby","color":"#701516"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"}]}},{"id":"R_kgDOL-bVaw","name":"talker","description":null,"url":"https://github.com/ssoad/talker","updatedAt":"2024-05-21T06:37:47Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/cde3324b7b23a178bacdccc556f709ad654555d8a86add925c0d9db0bd11f704/ssoad/talker","stargazers":{"totalCount":0},"readme":null,"licenseInfo":{"id":"MDc6TGljZW5zZTE="},"primaryLanguage":{"name":"JavaScript","color":"#f1e05a"},"languages":{"nodes":[{"name":"JavaScript","color":"#f1e05a"},{"name":"Dockerfile","color":"#384d54"},{"name":"PHP","color":"#4F5D95"},{"name":"Python","color":"#3572A5"},{"name":"Shell","color":"#89e051"},{"name":"CSS","color":"#563d7c"},{"name":"HTML","color":"#e34c26"}]}},{"id":"R_kgDOL4v0OA","name":"Meta-React-Native-Specialization","description":null,"url":"https://github.com/ssoad/Meta-React-Native-Specialization","updatedAt":"2024-05-08T10:59:02Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/92b080f93fb46066033b61f100a3bf63e04acdb4ad3a7229e31b3ae3a779e9c2/ssoad/Meta-React-Native-Specialization","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"JavaScript","color":"#f1e05a"},"languages":{"nodes":[{"name":"JavaScript","color":"#f1e05a"}]}},{"id":"R_kgDOLoqYFQ","name":"super_qr_reader","description":"QR code (scan / picture) recognition ï¼ˆAndroidView / UiKitViewï¼‰","url":"https://github.com/ssoad/super_qr_reader","updatedAt":"2024-04-02T08:57:53Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/e7911f977628c0b34689ae774e830d5a4ae30bae15e81214869ea11363a8f952/ssoad/super_qr_reader","stargazers":{"totalCount":0},"readme":{"text":"*This is a forked package from [flutter_qr_code_scaner](https://github.com/SeasonLeee/flutter_qr_code_scaner)*\n\n\n# flutter_qr_code_scaner\n\n[![Pub](https://img.shields.io/pub/v/flutter_qr_code_scaner.svg)](https://pub.dartlang.org/packages/flutter_qr_code_scaner)\n[![Awesome Flutter](https://img.shields.io/badge/Awesome-Flutter-blue.svg?longCache=true&style=flat-square)]()\n[![Awesome Flutter](https://img.shields.io/badge/Platform-Android_iOS-blue.svg?longCache=true&style=flat-square)]()\n[![License](https://img.shields.io/badge/License-MIT-blue.svg)](/LICENSE)\n\nQR code (scan code &#x2F; picture) recognition ï¼ˆAndroidView&#x2F;UiKitViewï¼‰\n\n# features:\n- place the code inside the square frame to get the information from QR code\n- select QR code from your local library from the image picker inside the ScanView\n\n\n## Getting Started\n\n```dart\nimport 'package:flutter_qr_code_scaner/scan_view.dart';\n\nclass HomePage extends StatefulWidget {\n  HomePage({Key key}) : super(key: key);\n\n  @override\n  _HomePageState createState() => new _HomePageState();\n}\n\nclass _HomePageState extends State<HomePage> {\n  String result = '';\n\n  var scanResult;\n  @override\n  void initState() {\n    super.initState();\n  }\n\n  @override\n  Widget build(BuildContext context) {\n    return Scaffold(\n      appBar: AppBar(\n        title: const Text('Package example app'),\n      ),\n      body: Padding(\n        padding: const EdgeInsets.symmetric(horizontal: 16),\n        child: Column(\n          mainAxisAlignment: MainAxisAlignment.center,\n          crossAxisAlignment: CrossAxisAlignment.stretch,\n          children: <Widget>[\n            RaisedButton(\n              onPressed: () async {\n                String results = await Navigator.push( // waiting for the scan results\n                  context,\n                  MaterialPageRoute(\n                    builder: (context) => ScanView(), // open the scan view\n                  ),\n                );\n\n                if (results != null) {\n                  setState(() {\n                    result = results;\n                  });\n                }\n              },\n              child: Text(\"æ‰«ç /tap to scan\"),\n            ),\n            Text(result), // display the scan results\n          ],\n        ),\n      ),\n    );\n  }\n} \n```\n\n### For IOS\nOpt-in to the embedded views preview by adding a boolean property to the app's Info.plist file with the key io.flutter.embedded_views_preview and the value YES.\n\n\t<key>io.flutter.embedded_views_preview</key>\n\t<string>YES</string>\n\nAnd you will need provide the description of camera's permission to work properly, otherwise will crash your app.\n``` \n  <key>NSCameraUsageDescription</key>\n\t<string>The porpuse explaining why you will use the camera</string>\n```\n\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTU="},"primaryLanguage":{"name":"Java","color":"#b07219"},"languages":{"nodes":[{"name":"Ruby","color":"#701516"},{"name":"Objective-C","color":"#438eff"},{"name":"Java","color":"#b07219"},{"name":"Kotlin","color":"#A97BFF"},{"name":"Dart","color":"#00B4AB"},{"name":"Swift","color":"#F05138"},{"name":"HTML","color":"#e34c26"},{"name":"CMake","color":"#DA3434"},{"name":"C++","color":"#f34b7d"},{"name":"C","color":"#555555"}]}},{"id":"R_kgDOLUPgeg","name":"flutter_ecommerce","description":null,"url":"https://github.com/ssoad/flutter_ecommerce","updatedAt":"2024-04-07T07:21:29Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/850e18dddb9af9a984ad325d6a974ce3cc2518968f4552b26d3c9805bc2dea83/ssoad/flutter_ecommerce","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Ruby","color":"#701516"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"},{"name":"CMake","color":"#DA3434"},{"name":"C++","color":"#f34b7d"},{"name":"C","color":"#555555"},{"name":"HTML","color":"#e34c26"}]}},{"id":"R_kgDOK5Rl-Q","name":"storoco","description":"Minimalist application to write stories, notes, diary! ðŸŽƒ","url":"https://github.com/ssoad/storoco","updatedAt":"2024-05-12T20:26:02Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/eb1bf5b4f57706d9640f8c0c2b04c40d6f32acfee12285add7e629ebab2c1a17/ssoad/storoco","stargazers":{"totalCount":0},"readme":{"text":"# Spooky ðŸŽƒ\n\n![cover](https://repository-images.githubusercontent.com/444136870/43a054a0-50ad-47d7-a680-4a12507a77d2)\n\nFirst journal with Material 3 design! Spooky is a minimalist design application to write stories, journals, notes, diaries, todo, etc. We offer a variety of features that you can expect for your daily usage.\n\n[![App Store](https://img.shields.io/badge/App_Store-0D96F6?style=for-the-badge&logo=app-store&logoColor=white)](https://apps.apple.com/us/app/spooky/id1629372753?platform=iphone) [![Play Store](https://img.shields.io/badge/Google_Play-414141?style=for-the-badge&logo=google-play&logoColor=white)](https://play.google.com/store/apps/details?id=com.juniorise.spooky)\n\n## Installation\nSpooky is developed using Flutter 3.0.0. If you have a different version on your machine, please consider [installing FVM](https://soksereyphon8.medium.com/flutter-version-management-3c318c4ff97d). \n\n```s\nfvm flutter pub get\nfvm flutter run\n```\n\nSee [./docs.md](./docs.md) for details.\n\n## Support\nYou can support us by downloading the application & leave us feedback. Optionally, you can purchase add-ons in Spooky to try different features as well as support us.\n\nTo get news & updates on Spooky, please join our [Telegram channel](https://t.me/spookyjuniorise) & like our [Facebook page](https://web.facebook.com/spooky.juniorise)\n\n## License\nSpooky is licensed under the GNU General Public License v3.0. See the [LICENSE](LICENSE) file for details.\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTk="},"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Shell","color":"#89e051"},{"name":"JavaScript","color":"#f1e05a"},{"name":"Ruby","color":"#701516"},{"name":"C++","color":"#f34b7d"},{"name":"C","color":"#555555"},{"name":"Objective-C","color":"#438eff"},{"name":"Java","color":"#b07219"},{"name":"Kotlin","color":"#A97BFF"},{"name":"Dart","color":"#00B4AB"},{"name":"CSS","color":"#563d7c"}]}},{"id":"R_kgDOKaAyLg","name":"python-laravel-decrypt","description":null,"url":"https://github.com/ssoad/python-laravel-decrypt","updatedAt":"2024-04-07T07:21:22Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/d30ec0b5db2e81a8bbccf1aaaacd614f665ee0fbee2e203ad471f40472e0565a/ssoad/python-laravel-decrypt","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"R_kgDOJznTlQ","name":"django-documentation","description":" New Project For API Docs Learing Purpose","url":"https://github.com/ssoad/django-documentation","updatedAt":"2024-04-07T07:21:21Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/81e8712199a601157c35d859af342026e2b3fedd50a4f489bca69a6489cbae1b/ssoad/django-documentation","stargazers":{"totalCount":0},"readme":{"text":"# Django API Documentation\nThis is a Django API Documentation project. This Repository Contains API Documentation for Django Framework. This is a simple project to learn Django Framework and REST Framework in Django. The documentation contains multiple version like Docs/Swagger/ ReDoc and much more of the features.\n\n## Requirements\n- Python 3.6+\n- Virtualenv (optional)\n\n## Installation\n- Clone the repository `git clone\n- Create a virtualenv with `virtualenv venv` and activate it `source venv/bin/activate`\n- Install dependencies with `pip install -r requirements.txt`\n- Migrate database with `python manage.py migrate`\n- Run the server with `python manage.py runserver`\n- Go to `http://localhost:8000` and you'll see the available list documentations.\n- You can also go to `http://localhost:8000/docs` to see the Swagger Documentation.\n- You can also go to `http://localhost:8000/redoc` to see the ReDoc Documentation.\n- You can also go to `http://localhost:8000/swagger` to see the Swagger UI Documentation.\n- You can test all the API on the Swagger/ReDoc.\n\n## Screenshots\n- Docs Version\n![Screenshot 1](screenshots/docs.png)\n- Swagger Version\n![Screenshot 2](screenshots/swagger.png)\n- ReDoc Version\n![Screenshot 3](screenshots/redoc.png)"},"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"R_kgDOJeUFaQ","name":"DjangoGraphQL","description":null,"url":"https://github.com/ssoad/DjangoGraphQL","updatedAt":"2024-04-07T07:21:18Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/0aaad0e7a290a2efa3d580cfb4019b37d9af5403857683209e74010356790484/ssoad/DjangoGraphQL","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"R_kgDOJX2t7w","name":"Auto-GPT","description":"An experimental open-source attempt to make GPT-4 fully autonomous.","url":"https://github.com/ssoad/Auto-GPT","updatedAt":"2024-04-07T07:21:16Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/e28f9f7dea9eb511d605d9e38bb61e4ee7be92f94a8700ef799078dd226a479f/ssoad/Auto-GPT","stargazers":{"totalCount":0},"readme":{"text":"# Auto-GPT: An Autonomous GPT-4 Experiment\n[![Unit Tests](https://img.shields.io/github/actions/workflow/status/Significant-Gravitas/Auto-GPT/ci.yml?label=unit%20tests)](https://github.com/Significant-Gravitas/Auto-GPT/actions/workflows/ci.yml)\n[![Discord Follow](https://dcbadge.vercel.app/api/server/autogpt?style=flat)](https://discord.gg/autogpt)\n[![GitHub Repo stars](https://img.shields.io/github/stars/Significant-Gravitas/auto-gpt?style=social)](https://github.com/Significant-Gravitas/Auto-GPT/stargazers)\n[![Twitter Follow](https://img.shields.io/twitter/follow/siggravitas?style=social)](https://twitter.com/SigGravitas)\n\n## ðŸ’¡ Get help - [Q&A](https://github.com/Significant-Gravitas/Auto-GPT/discussions/categories/q-a) or [Discord ðŸ’¬](https://discord.gg/autogpt)\n\n<hr/>\n\n### ðŸ”´ ðŸ”´ ðŸ”´  Urgent: USE `stable` not `master`  ðŸ”´ ðŸ”´ ðŸ”´\n\n**Download the latest `stable` release from here: https://github.com/Significant-Gravitas/Auto-GPT/releases/latest.**\nThe `master` branch may often be in a **broken** state.\n\n<hr/>\n\n\nAuto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven by GPT-4, chains together LLM \"thoughts\", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI.\n\n<h2 align=\"center\"> Demo April 16th 2023 </h2>\n\nhttps://user-images.githubusercontent.com/70048414/232352935-55c6bf7c-3958-406e-8610-0913475a0b05.mp4\n\nDemo made by <a href=https://twitter.com/BlakeWerlinger>Blake Werlinger</a>\n\n<h2 align=\"center\"> ðŸ’– Help Fund Auto-GPT's Development ðŸ’–</h2>\n<p align=\"center\">\nIf you can spare a coffee, you can help to cover the costs of developing Auto-GPT and help push the boundaries of fully autonomous AI!\nYour support is greatly appreciated\nDevelopment of this free, open-source project is made possible by all the <a href=\"https://github.com/Significant-Gravitas/Auto-GPT/graphs/contributors\">contributors</a> and <a href=\"https://github.com/sponsors/Torantulino\">sponsors</a>. If you'd like to sponsor this project and have your avatar or company logo appear below <a href=\"https://github.com/sponsors/Torantulino\">click here</a>.\n</p>\n\n\n<h3 align=\"center\">Enterprise Sponsors</h3>\n<p align=\"center\">\n<a href=\"https://www.influxdata.com/\"><img src=\"https://user-images.githubusercontent.com/22963551/232278272-24712932-7bb3-4fbe-b7e9-4b649b8104b2.png\" height=\"40px\" alt=\"InfluxData\" /></a>&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"https://roost.ai\"><img src=\"https://roost.ai/hubfs/logos/Roost.ai-logo-gold.svg\" height=\"40px\" alt=\"Roost.AI\" /></a>&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"https://nuclei.ai/\"><img src=\"https://nuclei.ai/images/nuclei_logo_with_text_white.svg\" height=\"40px\" alt=\"NucleiAI\" /></a>&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"https://www.algohash.org/\"><img src=\"https://user-images.githubusercontent.com/22963551/232277567-78d642c1-ce21-4bcc-a209-c2a23495ab2d.png\" height=\"40px\" alt=\"AlgohashFe\" /></a>&nbsp;&nbsp;&nbsp;&nbsp;</p>\n\n<h3 align=\"center\">Individual Sponsors</h3>\n<p align=\"center\">\n<a href=\"https://github.com/robinicus\"><img src=\"https://github.com/robinicus.png\" width=\"50px\" alt=\"robinicus\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/prompthero\"><img src=\"https://github.com/prompthero.png\" width=\"50px\" alt=\"prompthero\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/crizzler\"><img src=\"https://github.com/crizzler.png\" width=\"50px\" alt=\"crizzler\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/tob-le-rone\"><img src=\"https://github.com/tob-le-rone.png\" width=\"50px\" alt=\"tob-le-rone\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/FSTatSBS\"><img src=\"https://github.com/FSTatSBS.png\" width=\"50px\" alt=\"FSTatSBS\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/toverly1\"><img src=\"https://github.com/toverly1.png\" width=\"50px\" alt=\"toverly1\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ddtarazona\"><img src=\"https://github.com/ddtarazona.png\" width=\"50px\" alt=\"ddtarazona\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Nalhos\"><img src=\"https://github.com/Nalhos.png\" width=\"50px\" alt=\"Nalhos\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Kazamario\"><img src=\"https://github.com/Kazamario.png\" width=\"50px\" alt=\"Kazamario\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/pingbotan\"><img src=\"https://github.com/pingbotan.png\" width=\"50px\" alt=\"pingbotan\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/indoor47\"><img src=\"https://github.com/indoor47.png\" width=\"50px\" alt=\"indoor47\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/AuroraHolding\"><img src=\"https://github.com/AuroraHolding.png\" width=\"50px\" alt=\"AuroraHolding\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/kreativai\"><img src=\"https://github.com/kreativai.png\" width=\"50px\" alt=\"kreativai\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/hunteraraujo\"><img src=\"https://github.com/hunteraraujo.png\" width=\"50px\" alt=\"hunteraraujo\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Explorergt92\"><img src=\"https://github.com/Explorergt92.png\" width=\"50px\" alt=\"Explorergt92\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/judegomila\"><img src=\"https://github.com/judegomila.png\" width=\"50px\" alt=\"judegomila\" /></a>&nbsp;&nbsp;\n<a href=\"https://github.com/thepok\"><img src=\"https://github.com/thepok.png\" width=\"50px\" alt=\"thepok\" /></a>\n&nbsp;&nbsp;<a href=\"https://github.com/SpacingLily\"><img src=\"https://github.com/SpacingLily.png\" width=\"50px\" alt=\"SpacingLily\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/merwanehamadi\"><img src=\"https://github.com/merwanehamadi.png\" width=\"50px\" alt=\"merwanehamadi\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/m\"><img src=\"https://github.com/m.png\" width=\"50px\" alt=\"m\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/zkonduit\"><img src=\"https://github.com/zkonduit.png\" width=\"50px\" alt=\"zkonduit\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/maxxflyer\"><img src=\"https://github.com/maxxflyer.png\" width=\"50px\" alt=\"maxxflyer\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/tekelsey\"><img src=\"https://github.com/tekelsey.png\" width=\"50px\" alt=\"tekelsey\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/digisomni\"><img src=\"https://github.com/digisomni.png\" width=\"50px\" alt=\"digisomni\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/nocodeclarity\"><img src=\"https://github.com/nocodeclarity.png\" width=\"50px\" alt=\"nocodeclarity\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/tjarmain\"><img src=\"https://github.com/tjarmain.png\" width=\"50px\" alt=\"tjarmain\" /></a>\n<a href=\"https://github.com/Dradstone\"><img src=\"https://github.com/Dradstone.png\" width=\"50px\" alt=\"Dradstone\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/CrypteorCapital\"><img src=\"https://github.com/CrypteorCapital.png\" width=\"50px\" alt=\"CrypteorCapital\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/avy-ai\"><img src=\"https://github.com/avy-ai.png\" width=\"50px\" alt=\"avy-ai\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/shawnharmsen\"><img src=\"https://github.com/shawnharmsen.png\" width=\"50px\" alt=\"shawnharmsen\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/sunchongren\"><img src=\"https://github.com/sunchongren.png\" width=\"50px\" alt=\"sunchongren\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/DailyBotHQ\"><img src=\"https://github.com/DailyBotHQ.png\" width=\"50px\" alt=\"DailyBotHQ\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/mathewhawkins\"><img src=\"https://github.com/mathewhawkins.png\" width=\"50px\" alt=\"mathewhawkins\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/MediConCenHK\"><img src=\"https://github.com/MediConCenHK.png\" width=\"50px\" alt=\"MediConCenHK\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/kMag410\"><img src=\"https://github.com/kMag410.png\" width=\"50px\" alt=\"kMag410\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/nicoguyon\"><img src=\"https://github.com/nicoguyon.png\" width=\"50px\" alt=\"nicoguyon\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Mobivs\"><img src=\"https://github.com/Mobivs.png\" width=\"50px\" alt=\"Mobivs\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/jazgarewal\"><img src=\"https://github.com/jazgarewal.png\" width=\"50px\" alt=\"jazgarewal\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/marv-technology\"><img src=\"https://github.com/marv-technology.png\" width=\"50px\" alt=\"marv-technology\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/rapidstartup\"><img src=\"https://github.com/rapidstartup.png\" width=\"50px\" alt=\"rapidstartup\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Brodie0\"><img src=\"https://github.com/Brodie0.png\" width=\"50px\" alt=\"Brodie0\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/lucas-chu\"><img src=\"https://github.com/lucas-chu.png\" width=\"50px\" alt=\"lucas-chu\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/rejunity\"><img src=\"https://github.com/rejunity.png\" width=\"50px\" alt=\"rejunity\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/comet-ml\"><img src=\"https://github.com/comet-ml.png\" width=\"50px\" alt=\"comet-ml\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ColinConwell\"><img src=\"https://github.com/ColinConwell.png\" width=\"50px\" alt=\"ColinConwell\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/cfarquhar\"><img src=\"https://github.com/cfarquhar.png\" width=\"50px\" alt=\"cfarquhar\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ikarosai\"><img src=\"https://github.com/ikarosai.png\" width=\"50px\" alt=\"ikarosai\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ChrisDMT\"><img src=\"https://github.com/ChrisDMT.png\" width=\"50px\" alt=\"ChrisDMT\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Odin519Tomas\"><img src=\"https://github.com/Odin519Tomas.png\" width=\"50px\" alt=\"Odin519Tomas\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/vkozacek\"><img src=\"https://github.com/vkozacek.png\" width=\"50px\" alt=\"vkozacek\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/belharethsami\"><img src=\"https://github.com/belharethsami.png\" width=\"50px\" alt=\"belharethsami\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/sultanmeghji\"><img src=\"https://github.com/sultanmeghji.png\" width=\"50px\" alt=\"sultanmeghji\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/scryptedinc\"><img src=\"https://github.com/scryptedinc.png\" width=\"50px\" alt=\"scryptedinc\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/johnculkin\"><img src=\"https://github.com/johnculkin.png\" width=\"50px\" alt=\"johnculkin\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/RealChrisSean\"><img src=\"https://github.com/RealChrisSean.png\" width=\"50px\" alt=\"RealChrisSean\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/fruition\"><img src=\"https://github.com/fruition.png\" width=\"50px\" alt=\"fruition\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/jd3655\"><img src=\"https://github.com/jd3655.png\" width=\"50px\" alt=\"jd3655\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Web3Capital\"><img src=\"https://github.com/Web3Capital.png\" width=\"50px\" alt=\"Web3Capital\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/allenstecat\"><img src=\"https://github.com/allenstecat.png\" width=\"50px\" alt=\"allenstecat\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/tob-le-rone\"><img src=\"https://github.com/tob-le-rone.png\" width=\"50px\" alt=\"tob-le-rone\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/SwftCoins\"><img src=\"https://github.com/SwftCoins.png\" width=\"50px\" alt=\"SwftCoins\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/MetaPath01\"><img src=\"https://github.com/MetaPath01.png\" width=\"50px\" alt=\"MetaPath01\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/joaomdmoura\"><img src=\"https://github.com/joaomdmoura.png\" width=\"50px\" alt=\"joaomdmoura\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ternary5\"><img src=\"https://github.com/ternary5.png\" width=\"50px\" alt=\"ternary5\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/refinery1\"><img src=\"https://github.com/refinery1.png\" width=\"50px\" alt=\"refinery1\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/josephcmiller2\"><img src=\"https://github.com/josephcmiller2.png\" width=\"50px\" alt=\"josephcmiller2\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/webbcolton\"><img src=\"https://github.com/webbcolton.png\" width=\"50px\" alt=\"webbcolton\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/tommygeee\"><img src=\"https://github.com/tommygeee.png\" width=\"50px\" alt=\"tommygeee\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/lmaugustin\"><img src=\"https://github.com/lmaugustin.png\" width=\"50px\" alt=\"lmaugustin\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/garythebat\"><img src=\"https://github.com/garythebat.png\" width=\"50px\" alt=\"garythebat\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Cameron-Fulton\"><img src=\"https://github.com/Cameron-Fulton.png\" width=\"50px\" alt=\"Cameron-Fulton\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/angiaou\"><img src=\"https://github.com/angiaou.png\" width=\"50px\" alt=\"angiaou\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/caitlynmeeks\"><img src=\"https://github.com/caitlynmeeks.png\" width=\"50px\" alt=\"caitlynmeeks\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/MBassi91\"><img src=\"https://github.com/MBassi91.png\" width=\"50px\" alt=\"MBassi91\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Daniel1357\"><img src=\"https://github.com/Daniel1357.png\" width=\"50px\" alt=\"Daniel1357\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/omphos\"><img src=\"https://github.com/omphos.png\" width=\"50px\" alt=\"omphos\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/abhinav-pandey29\"><img src=\"https://github.com/abhinav-pandey29.png\" width=\"50px\" alt=\"abhinav-pandey29\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/DataMetis\"><img src=\"https://github.com/DataMetis.png\" width=\"50px\" alt=\"DataMetis\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/concreit\"><img src=\"https://github.com/concreit.png\" width=\"50px\" alt=\"concreit\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/st617\"><img src=\"https://github.com/st617.png\" width=\"50px\" alt=\"st617\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/RThaweewat\"><img src=\"https://github.com/RThaweewat.png\" width=\"50px\" alt=\"RThaweewat\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/KiaArmani\"><img src=\"https://github.com/KiaArmani.png\" width=\"50px\" alt=\"KiaArmani\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Pythagora-io\"><img src=\"https://github.com/Pythagora-io.png\" width=\"50px\" alt=\"Pythagora-io\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/AryaXAI\"><img src=\"https://github.com/AryaXAI.png\" width=\"50px\" alt=\"AryaXAI\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/fabrietech\"><img src=\"https://github.com/fabrietech.png\" width=\"50px\" alt=\"fabrietech\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/jun784\"><img src=\"https://github.com/jun784.png\" width=\"50px\" alt=\"jun784\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/Mr-Bishop42\"><img src=\"https://github.com/Mr-Bishop42.png\" width=\"50px\" alt=\"Mr-Bishop42\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/rickscode\"><img src=\"https://github.com/rickscode.png\" width=\"50px\" alt=\"rickscode\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/projectonegames\"><img src=\"https://github.com/projectonegames.png\" width=\"50px\" alt=\"projectonegames\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/rocks6\"><img src=\"https://github.com/rocks6.png\" width=\"50px\" alt=\"rocks6\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/GalaxyVideoAgency\"><img src=\"https://github.com/GalaxyVideoAgency.png\" width=\"50px\" alt=\"GalaxyVideoAgency\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/thisisjeffchen\"><img src=\"https://github.com/thisisjeffchen.png\" width=\"50px\" alt=\"thisisjeffchen\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/TheStoneMX\"><img src=\"https://github.com/TheStoneMX.png\" width=\"50px\" alt=\"TheStoneMX\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/txtr99\"><img src=\"https://github.com/txtr99.png\" width=\"50px\" alt=\"txtr99\" /></a>&nbsp;&nbsp;<a href=\"https://github.com/ZERO-A-ONE\"><img src=\"https://github.com/ZERO-A-ONE.png\" width=\"50px\" alt=\"ZERO-A-ONE\" /></a>&nbsp;&nbsp;</p>\n\n\n## ðŸš€ Features\n\n- ðŸŒ Internet access for searches and information gathering\n- ðŸ’¾ Long-Term and Short-Term memory management\n- ðŸ§  GPT-4 instances for text generation\n- ðŸ”— Access to popular websites and platforms\n- ðŸ—ƒï¸ File storage and summarization with GPT-3.5\n\n## ðŸ“‹ Requirements\n\n- Environment (pick one)\n  - [VSCode + devcontainer](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers): It has been configured in the .devcontainer folder and can be used directly\n  - Docker\n  - Python 3.10 or later (instructions: [for Windows](https://www.tutorialspoint.com/how-to-install-python-in-windows))\n- [OpenAI API key](https://platform.openai.com/account/api-keys)\n\n### Optional\n- Memory backend (pick one)\n  - [Pinecone](https://www.pinecone.io/)\n  - [Milvus](https://milvus.io/)\n  - [Redis](https://redis.io)\n- ElevenLabs Key (If you want the AI to speak)\n\n## ðŸ’¾ Installation\n\nTo install Auto-GPT, follow these steps:\n\n1. Make sure you have all the **requirements** listed above, if not, install/get them\n\n_To execute the following commands, open a CMD, Bash, or Powershell window by navigating to a folder on your computer and typing `CMD` in the folder path at the top, then press enter._\n\n2. Clone the repository: For this step, you need Git installed. Alternatively,\n   you can download the [latest stable release](https://github.com/Significant-Gravitas/Auto-GPT/releases/latest) (`Source code (zip)`, bottom of the page).\n\n    ```bash\n    git clone https://github.com/Significant-Gravitas/Auto-GPT.git\n    ```\n\n3. Navigate to the directory where the repository was downloaded\n\n    ```bash\n    cd Auto-GPT\n    ```\n\n4. Install the required dependencies\n\n    ```bash\n    pip install -r requirements.txt\n    ```\n\n5. Configure Auto-GPT\n   1. Locate the file named `.env.template` in the main `/Auto-GPT` folder.\n   2. Create a copy of this file, called `.env` by removing the `template` extension.  The easiest way is to do this in a command prompt/terminal window `cp .env.template .env`.\n   3. Open the `.env` file in a text editor.  _Note: Files starting with a dot might be hidden by your Operating System._\n   4. Find the line that says `OPENAI_API_KEY=`.\n   5. After the `\"=\"`, enter your unique OpenAI API Key (without any quotes or spaces).\n   6. Enter any other API keys or Tokens for services you would like to utilize.\n   7. Save and close the `.env` file.\n\n   By completing these steps, you have properly configured the API Keys for your project.\n   \n   - See [OpenAI API Keys Configuration](#openai-api-keys-configuration) to obtain your OpenAI API key.\n   - Obtain your ElevenLabs API key from: https://elevenlabs.io. You can view your xi-api-key using the \"Profile\" tab on the website.\n   - If you want to use GPT on an Azure instance, set `USE_AZURE` to `True` and then follow these steps:\n     - Rename `azure.yaml.template` to `azure.yaml` and provide the relevant `azure_api_base`, `azure_api_version` and all the deployment IDs for the relevant models in the `azure_model_map` section:\n       - `fast_llm_model_deployment_id` - your gpt-3.5-turbo or gpt-4 deployment ID\n       - `smart_llm_model_deployment_id` - your gpt-4 deployment ID\n       - `embedding_model_deployment_id` - your text-embedding-ada-002 v2 deployment ID\n     - Please specify all of these values as double-quoted strings\n       ```yaml\n       # Replace string in angled brackets (<>) to your own ID\n       azure_model_map:\n         fast_llm_model_deployment_id: \"<my-fast-llm-deployment-id>\"\n         ...\n       ```\n     - Details can be found here: https://pypi.org/project/openai/ in the `Microsoft Azure Endpoints` section and here: https://learn.microsoft.com/en-us/azure/cognitive-services/openai/tutorials/embeddings?tabs=command-line for the embedding model.\n\n## ðŸ”§ Usage\n\n1. Run `autogpt` Python module in your terminal\n\n    ```\n    python -m autogpt\n    ```\n\n2. After each action, choose from options to authorize command(s),\nexit the program, or provide feedback to the AI.\n   1. Authorize a single command, enter `y`\n   2. Authorize a series of _N_ continuous commands, enter `y -N`\n   3. Exit the program, enter `n`\n\n\n### Logs\n\nActivity and error logs are located in the `./output/logs`\n\nTo print out debug logs:\n\n```\npython -m autogpt --debug\n```\n\n### Docker\n\nYou can also build this into a docker image and run it:\n\n```bash\ndocker build -t autogpt .\ndocker run -it --env-file=./.env -v $PWD/auto_gpt_workspace:/app/auto_gpt_workspace autogpt\n```\n\nOr if you have `docker-compose`:\n```bash\ndocker-compose run --build --rm auto-gpt\n```\n\nYou can pass extra arguments, for instance, running with `--gpt3only` and `--continuous` mode:\n```bash\ndocker run -it --env-file=./.env -v $PWD/auto_gpt_workspace:/app/auto_gpt_workspace autogpt --gpt3only --continuous\n```\n```bash\ndocker-compose run --build --rm auto-gpt --gpt3only --continuous\n```\n\n### Command Line Arguments\nHere are some common arguments you can use when running Auto-GPT:\n> Replace anything in angled brackets (<>) to a value you want to specify\n\n* View all available command line arguments\n    ```bash\n    python -m autogpt --help\n    ```\n* Run Auto-GPT with a different AI Settings file\n    ```bash\n    python -m autogpt --ai-settings <filename>\n    ```\n* Specify a memory backend\n    ```bash\n    python -m autogpt --use-memory  <memory-backend>\n    ```\n\n> **NOTE**: There are shorthands for some of these flags, for example `-m` for `--use-memory`. Use `python -m autogpt --help` for more information\n\n## ðŸ—£ï¸ Speech Mode\n\nUse this to use TTS _(Text-to-Speech)_ for Auto-GPT\n\n```bash\npython -m autogpt --speak\n```\n\n### List of IDs with names from eleven labs, you can use the name or ID:\n\n- Rachel : 21m00Tcm4TlvDq8ikWAM\n- Domi : AZnzlk1XvdvUeBnXmlld\n- Bella : EXAVITQu4vr4xnSDxMaL\n- Antoni : ErXwobaYiN019PkySvjV\n- Elli : MF3mGyEYCl7XYWbV9V6O\n- Josh : TxGEqnHWrfWFTfGW9XjX\n- Arnold : VR6AewLTigWG4xSOukaG\n- Adam : pNInz6obpgDQGcFmaJgB\n- Sam : yoZ06aMxZJJ28mfd3POQ\n\n\n## OpenAI API Keys Configuration\n\nObtain your OpenAI API key from: https://platform.openai.com/account/api-keys.\n\nTo use OpenAI API key for Auto-GPT, you NEED to have billing set up (AKA paid account).\n\nYou can set up paid account at https://platform.openai.com/account/billing/overview.\n\n![For OpenAI API key to work, set up paid account at OpenAI API > Billing](./docs/imgs/openai-api-key-billing-paid-account.png)\n\n\n## ðŸ” Google API Keys Configuration\n\nThis section is optional, use the official google api if you are having issues with error 429 when running a google search.\nTo use the `google_official_search` command, you need to set up your Google API keys in your environment variables.\n\n1. Go to the [Google Cloud Console](https://console.cloud.google.com/).\n2. If you don't already have an account, create one and log in.\n3. Create a new project by clicking on the \"Select a Project\" dropdown at the top of the page and clicking \"New Project\". Give it a name and click \"Create\".\n4. Go to the [APIs & Services Dashboard](https://console.cloud.google.com/apis/dashboard) and click \"Enable APIs and Services\". Search for \"Custom Search API\" and click on it, then click \"Enable\".\n5. Go to the [Credentials](https://console.cloud.google.com/apis/credentials) page and click \"Create Credentials\". Choose \"API Key\".\n6. Copy the API key and set it as an environment variable named `GOOGLE_API_KEY` on your machine. See setting up environment variables below.\n7. [Enable](https://console.developers.google.com/apis/api/customsearch.googleapis.com) the Custom Search API on your project. (Might need to wait few minutes to propagate)\n8. Go to the [Custom Search Engine](https://cse.google.com/cse/all) page and click \"Add\".\n9. Set up your search engine by following the prompts. You can choose to search the entire web or specific sites.\n10. Once you've created your search engine, click on \"Control Panel\" and then \"Basics\". Copy the \"Search engine ID\" and set it as an environment variable named `CUSTOM_SEARCH_ENGINE_ID` on your machine. See setting up environment variables below.\n\n_Remember that your free daily custom search quota allows only up to 100 searches. To increase this limit, you need to assign a billing account to the project to profit from up to 10K daily searches._\n\n### Setting up environment variables\n\nFor Windows Users:\n\n```bash\nsetx GOOGLE_API_KEY \"YOUR_GOOGLE_API_KEY\"\nsetx CUSTOM_SEARCH_ENGINE_ID \"YOUR_CUSTOM_SEARCH_ENGINE_ID\"\n```\n\nFor macOS and Linux users:\n\n```bash\nexport GOOGLE_API_KEY=\"YOUR_GOOGLE_API_KEY\"\nexport CUSTOM_SEARCH_ENGINE_ID=\"YOUR_CUSTOM_SEARCH_ENGINE_ID\"\n```\n\n## Setting Your Cache Type\n\nBy default, Auto-GPT is going to use LocalCache instead of redis or Pinecone.\n\nTo switch to either, change the `MEMORY_BACKEND` env variable to the value that you want:\n\n* `local` (default) uses a local JSON cache file\n* `pinecone` uses the Pinecone.io account you configured in your ENV settings\n* `redis` will use the redis cache that you configured\n* `milvus` will use the milvus cache that you configured\n* `weaviate` will use the weaviate cache that you configured\n\n## Memory Backend Setup\n\n### Redis Setup\n> _**CAUTION**_ \\\nThis is not intended to be publicly accessible and lacks security measures. Therefore, avoid exposing Redis to the internet without a password or at all\n1. Install docker (or Docker Desktop on Windows)\n2. Launch Redis container\n    ```bash\n    docker run -d --name redis-stack-server -p 6379:6379 redis/redis-stack-server:latest\n    ```\n    > See https://hub.docker.com/r/redis/redis-stack-server for setting a password and additional configuration.\n3. Set the following settings in `.env`\n    > Replace **PASSWORD** in angled brackets (<>)\n    ```bash\n    MEMORY_BACKEND=redis\n    REDIS_HOST=localhost\n    REDIS_PORT=6379\n    REDIS_PASSWORD=<PASSWORD>\n    ```\n\n    You can optionally set `WIPE_REDIS_ON_START=False` to persist memory stored in Redis.\n\nYou can specify the memory index for redis using the following:\n```bash\nMEMORY_INDEX=<WHATEVER>\n```\n\n### ðŸŒ² Pinecone API Key Setup\n\nPinecone enables the storage of vast amounts of vector-based memory, allowing for only relevant memories to be loaded for the agent at any given time.\n\n1. Go to [pinecone](https://app.pinecone.io/) and make an account if you don't already have one.\n2. Choose the `Starter` plan to avoid being charged.\n3. Find your API key and region under the default project in the left sidebar.\n\nIn the `.env` file set:\n- `PINECONE_API_KEY`\n- `PINECONE_ENV` (example: _\"us-east4-gcp\"_)\n- `MEMORY_BACKEND=pinecone`\n\nAlternatively, you can set them from the command line (advanced):\n\nFor Windows Users:\n\n```bash\nsetx PINECONE_API_KEY \"<YOUR_PINECONE_API_KEY>\"\nsetx PINECONE_ENV \"<YOUR_PINECONE_REGION>\" # e.g: \"us-east4-gcp\"\nsetx MEMORY_BACKEND \"pinecone\"\n```\n\nFor macOS and Linux users:\n\n```bash\nexport PINECONE_API_KEY=\"<YOUR_PINECONE_API_KEY>\"\nexport PINECONE_ENV=\"<YOUR_PINECONE_REGION>\" # e.g: \"us-east4-gcp\"\nexport MEMORY_BACKEND=\"pinecone\"\n```\n\n### Milvus Setup\n\n[Milvus](https://milvus.io/) is a open-source, high scalable vector database to storage huge amount of vector-based memory and provide fast relevant search.\n\n- setup milvus database, keep your pymilvus version and milvus version same to avoid compatible issues.\n  - setup by open source [Install Milvus](https://milvus.io/docs/install_standalone-operator.md)\n  - or setup by [Zilliz Cloud](https://zilliz.com/cloud)\n- set `MILVUS_ADDR` in `.env` to your milvus address `host:ip`.\n- set `MEMORY_BACKEND` in `.env` to `milvus` to enable milvus as backend.\n\n**Optional:**\n- set `MILVUS_COLLECTION` in `.env` to change milvus collection name as you want, `autogpt` is the default name.\n\n\n### Weaviate Setup\n[Weaviate](https://weaviate.io/) is an open-source vector database. It allows to store data objects and vector embeddings from ML-models and scales seamlessly to billion of data objects. [An instance of Weaviate can be created locally (using Docker), on Kubernetes or using Weaviate Cloud Services](https://weaviate.io/developers/weaviate/quickstart). \nAlthough still experimental, [Embedded Weaviate](https://weaviate.io/developers/weaviate/installation/embedded) is supported which allows the Auto-GPT process itself to start a Weaviate instance. To enable it, set `USE_WEAVIATE_EMBEDDED` to `True` and make sure you `pip install \"weaviate-client>=3.15.4\"`. \n\n#### Setting up environment variables\n\nIn your `.env` file set the following:\n\n```\nMEMORY_BACKEND=weaviate\nWEAVIATE_HOST=\"127.0.0.1\" # the IP or domain of the running Weaviate instance\nWEAVIATE_PORT=\"8080\" \nWEAVIATE_PROTOCOL=\"http\"\nWEAVIATE_USERNAME=\"your username\"\nWEAVIATE_PASSWORD=\"your password\"\nWEAVIATE_API_KEY=\"your weaviate API key if you have one\"\nWEAVIATE_EMBEDDED_PATH=\"/home/me/.local/share/weaviate\" # this is optional and indicates where the data should be persisted when running an embedded instance\nUSE_WEAVIATE_EMBEDDED=False # set to True to run Embedded Weaviate\nMEMORY_INDEX=\"Autogpt\" # name of the index to create for the application\n```\n \n## View Memory Usage\n\nView memory usage by using the `--debug` flag :)\n\n\n## ðŸ§  Memory pre-seeding\nMemory pre-seeding allows you to ingest files into memory and pre-seed it before running Auto-GPT.\n\n```bash\n# python data_ingestion.py -h \nusage: data_ingestion.py [-h] (--file FILE | --dir DIR) [--init] [--overlap OVERLAP] [--max_length MAX_LENGTH]\n\nIngest a file or a directory with multiple files into memory. Make sure to set your .env before running this script.\n\noptions:\n  -h, --help               show this help message and exit\n  --file FILE              The file to ingest.\n  --dir DIR                The directory containing the files to ingest.\n  --init                   Init the memory and wipe its content (default: False)\n  --overlap OVERLAP        The overlap size between chunks when ingesting files (default: 200)\n  --max_length MAX_LENGTH  The max_length of each chunk when ingesting files (default: 4000)\n\n# python data_ingestion.py --dir DataFolder --init --overlap 100 --max_length 2000\n```\nIn the example above, the script initializes the memory, ingests all files within the `Auto-Gpt/autogpt/auto_gpt_workspace/DataFolder` directory into memory with an overlap between chunks of 100 and a maximum length of each chunk of 2000.\n\nNote that you can also use the `--file` argument to ingest a single file into memory and that data_ingestion.py will only ingest files within the `/auto_gpt_workspace` directory.\n\nThe DIR path is relative to the auto_gpt_workspace directory, so `python data_ingestion.py --dir . --init` will ingest everything in `auto_gpt_workspace` directory.\n\nYou can adjust the `max_length` and overlap parameters to fine-tune the way the docuents are presented to the AI when it \"recall\" that memory:\n- Adjusting the overlap value allows the AI to access more contextual information from each chunk when recalling information, but will result in more chunks being created and therefore increase memory backend usage and OpenAI API requests.\n- Reducing the `max_length` value will create more chunks, which can save prompt tokens by allowing for more message history in the context, but will also increase the number of chunks.\n- Increasing the `max_length` value will provide the AI with more contextual information from each chunk, reducing the number of chunks created and saving on OpenAI API requests. However, this may also use more prompt tokens and decrease the overall context available to the AI.\n\nMemory pre-seeding is a technique for improving AI accuracy by ingesting relevant data into its memory. Chunks of data are split and added to memory, allowing the AI to access them quickly and generate more accurate responses. It's useful for large datasets or when specific information needs to be accessed quickly. Examples include ingesting API or GitHub documentation before running Auto-GPT.\n\nâš ï¸ If you use Redis as your memory, make sure to run Auto-GPT with the `WIPE_REDIS_ON_START=False` in your `.env` file.\n\nâš ï¸For other memory backend, we currently forcefully wipe the memory when starting Auto-GPT. To ingest data with those memory backend, you can call the `data_ingestion.py` script anytime during an Auto-GPT run. \n\nMemories will be available to the AI immediately as they are ingested, even if ingested while Auto-GPT is running.\n\n## ðŸ’€ Continuous Mode âš ï¸\n\nRun the AI **without** user authorization, 100% automated.\nContinuous mode is NOT recommended.\nIt is potentially dangerous and may cause your AI to run forever or carry out actions you would not usually authorize.\nUse at your own risk.\n\n1. Run the `autogpt` python module in your terminal:\n\n    ```bash\n    python -m autogpt --speak --continuous\n    ```\n\n2. To exit the program, press Ctrl + C\n\n## GPT3.5 ONLY Mode\n\nIf you don't have access to the GPT4 api, this mode will allow you to use Auto-GPT!\n\n```bash\npython -m autogpt --speak --gpt3only\n```\n\nIt is recommended to use a virtual machine for tasks that require high security measures to prevent any potential harm to the main computer's system and data.\n\n## ðŸ–¼ Image Generation\n\nBy default, Auto-GPT uses DALL-e for image generation. To use Stable Diffusion, a [Hugging Face API Token](https://huggingface.co/settings/tokens) is required.\n\nOnce you have a token, set these variables in your `.env`:\n\n```bash\nIMAGE_PROVIDER=sd\nHUGGINGFACE_API_TOKEN=\"YOUR_HUGGINGFACE_API_TOKEN\"\n```\n\n## Selenium\n```bash\nsudo Xvfb :10 -ac -screen 0 1024x768x24 & DISPLAY=:10 <YOUR_CLIENT>\n```\n\n## âš ï¸ Limitations\n\nThis experiment aims to showcase the potential of GPT-4 but comes with some limitations:\n\n1. Not a polished application or product, just an experiment\n2. May not perform well in complex, real-world business scenarios. In fact, if it actually does, please share your results!\n3. Quite expensive to run, so set and monitor your API key limits with OpenAI!\n\n## ðŸ›¡ Disclaimer\n\nDisclaimer\nThis project, Auto-GPT, is an experimental application and is provided \"as-is\" without any warranty, express or implied. By using this software, you agree to assume all risks associated with its use, including but not limited to data loss, system failure, or any other issues that may arise.\n\nThe developers and contributors of this project do not accept any responsibility or liability for any losses, damages, or other consequences that may occur as a result of using this software. You are solely responsible for any decisions and actions taken based on the information provided by Auto-GPT.\n\n**Please note that the use of the GPT-4 language model can be expensive due to its token usage.** By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.\n\nAs an autonomous experiment, Auto-GPT may generate content or take actions that are not in line with real-world business practices or legal requirements. It is your responsibility to ensure that any actions or decisions made based on the output of this software comply with all applicable laws, regulations, and ethical standards. The developers and contributors of this project shall not be held responsible for any consequences arising from the use of this software.\n\nBy using Auto-GPT, you agree to indemnify, defend, and hold harmless the developers, contributors, and any affiliated parties from and against any and all claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees) arising from your use of this software or your violation of these terms.\n\n## ðŸ¦ Connect with Us on Twitter\n\nStay up-to-date with the latest news, updates, and insights about Auto-GPT by following our Twitter accounts. Engage with the developer and the AI's own account for interesting discussions, project updates, and more.\n\n- **Developer**: Follow [@siggravitas](https://twitter.com/siggravitas) for insights into the development process, project updates, and related topics from the creator of Entrepreneur-GPT.\n- **Entrepreneur-GPT**: Join the conversation with the AI itself by following [@En_GPT](https://twitter.com/En_GPT). Share your experiences, discuss the AI's outputs, and engage with the growing community of users.\n\nWe look forward to connecting with you and hearing your thoughts, ideas, and experiences with Auto-GPT. Join us on Twitter and let's explore the future of AI together!\n\n<p align=\"center\">\n  <a href=\"https://star-history.com/#Torantulino/auto-gpt&Date\">\n    <img src=\"https://api.star-history.com/svg?repos=Torantulino/auto-gpt&type=Date\" alt=\"Star History Chart\">\n  </a>\n</p>\n\n## Run tests\n\nTo run all tests, run the following command:\n\n```bash\npytest \n\n```\n\nTo run just without integration tests:\n\n```\npytest --without-integration\n```\n\nTo run just without slow integration tests:\n\n```\npytest --without-slow-integration\n```\n\nTo run tests and see coverage, run the following command:\n\n```bash\npytest --cov=autogpt --without-integration --without-slow-integration\n```\n\n## Run linter\n\nThis project uses [flake8](https://flake8.pycqa.org/en/latest/) for linting. We currently use the following rules: `E303,W293,W291,W292,E305,E231,E302`. See the [flake8 rules](https://www.flake8rules.com/) for more information.\n\nTo run the linter, run the following command:\n\n```bash\nflake8 autogpt/ tests/\n\n# Or, if you want to run flake8 with the same configuration as the CI:\nflake8 autogpt/ tests/ --select E303,W293,W291,W292,E305,E231,E302\n```\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTEz"},"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Shell","color":"#89e051"},{"name":"JavaScript","color":"#f1e05a"},{"name":"Python","color":"#3572A5"},{"name":"Batchfile","color":"#C1F12E"},{"name":"Dockerfile","color":"#384d54"}]}},{"id":"R_kgDOJRM3_g","name":"the-algorithm","description":"Source code for Twitter's Recommendation Algorithm","url":"https://github.com/ssoad/the-algorithm","updatedAt":"2024-04-07T07:21:15Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/f6873652e7a9cbe8864d4ed5bdda0e7ef4f075e840b67c2c91f8da704ae095be/ssoad/the-algorithm","stargazers":{"totalCount":0},"readme":null,"licenseInfo":{"id":"MDc6TGljZW5zZTE="},"primaryLanguage":{"name":"Scala","color":"#c22d40"},"languages":{"nodes":[{"name":"Shell","color":"#89e051"},{"name":"C++","color":"#f34b7d"},{"name":"Python","color":"#3572A5"},{"name":"C","color":"#555555"},{"name":"Java","color":"#b07219"},{"name":"Scala","color":"#c22d40"},{"name":"Rust","color":"#dea584"},{"name":"Thrift","color":"#D12127"},{"name":"CMake","color":"#DA3434"},{"name":"Dockerfile","color":"#384d54"}]}},{"id":"R_kgDOJOz4JQ","name":"flutter_web_portfolio","description":null,"url":"https://github.com/ssoad/flutter_web_portfolio","updatedAt":"2024-04-07T07:21:14Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/5ce94e55777a7e808f0dd0d60ea3bb141d929e28c55fadf3effbfba520894e8f/ssoad/flutter_web_portfolio","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"C++","color":"#f34b7d"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"},{"name":"CMake","color":"#DA3434"},{"name":"C++","color":"#f34b7d"},{"name":"C","color":"#555555"},{"name":"HTML","color":"#e34c26"}]}},{"id":"R_kgDOJOFUmA","name":"ssoad_flutter_task","description":null,"url":"https://github.com/ssoad/ssoad_flutter_task","updatedAt":"2024-04-07T07:21:13Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/66f2bbbf414ebf05f4d5933a4976591860f4040874959cd3601efe80df654523/ssoad/ssoad_flutter_task","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Ruby","color":"#701516"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"},{"name":"CMake","color":"#DA3434"},{"name":"C++","color":"#f34b7d"},{"name":"C","color":"#555555"},{"name":"HTML","color":"#e34c26"}]}},{"id":"R_kgDOJJ0VRw","name":"flutter_bloc_moviedb","description":null,"url":"https://github.com/ssoad/flutter_bloc_moviedb","updatedAt":"2024-04-07T07:21:11Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/4770edf947ba997bc0ef3df816b2b908afacce38a9c278415d8f8e35a02ecc43/ssoad/flutter_bloc_moviedb","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"C++","color":"#f34b7d"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"},{"name":"CMake","color":"#DA3434"},{"name":"C++","color":"#f34b7d"},{"name":"C","color":"#555555"},{"name":"HTML","color":"#e34c26"}]}},{"id":"R_kgDOJF9H-w","name":"reFlutter","description":"Flutter Reverse Engineering Framework","url":"https://github.com/ssoad/reFlutter","updatedAt":"2024-04-07T07:20:47Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/b0e971f70cd9aff96759d58a859400884178f16324e9b80e119ff45d645a940a/ssoad/reFlutter","stargazers":{"totalCount":0},"readme":null,"licenseInfo":{"id":"MDc6TGljZW5zZTk="},"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"R_kgDOJF2TUA","name":"human-eval-infilling","description":"Code for the paper \"Efficient Training of Language Models to Fill in the Middle\"","url":"https://github.com/ssoad/human-eval-infilling","updatedAt":"2024-04-07T07:20:36Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/e372d056bc4a65cf89c0c40696b9064b40e63371035a2ac74d519aa809e5e756/ssoad/human-eval-infilling","stargazers":{"totalCount":0},"readme":{"text":"# HumanEval Infilling Benchmarks\n\nThis is an evaluation harness for the HumanEval infilling benchmarks described in the [FIM paper](https://arxiv.org/abs/2207.14255).\n\n## Installation\n\nMake sure to use python 3.7 or later:\n```\n$ conda create -n codex python=3.7\n$ conda activate codex\n```\n\nCheck out and install this repository:\n```\n$ git clone https://github.com/openai/human-eval-infilling\n$ pip install -e human-eval-infilling\n```\n\n## Usage\n\n**This program exists to run untrusted model-generated code. Users are strongly\nencouraged not to do so outside of a robust security sandbox. The [execution\ncall](https://github.com/openai/human-eval-infilling/blob/master/human_eval_infilling/execution.py#L74-L84)\nin `execution.py` is deliberately commented out to ensure users read this\ndisclaimer before running code in a potentially unsafe manner. See the comment in\n`execution.py` for more information and instructions.**\n\nAfter following the above instructions to enable execution, generate samples\nand save them in the following JSON Lines (jsonl) format, where each sample is\nformatted into a single line like so:\n```\n{\"task_id\": \"Corresponding task ID from the desired benchmark\", \"completion\": \"Completion only without the prompt\"}\n```\nEnsure that the `task_id` used matches the `task_id` from the desired benchmark. See below and the paper for information on the benchmarks available.\n\nWe provide `example_problem.jsonl` and `example_solutions.jsonl` under `data`\nto illustrate the format and help with debugging.\n\nHere is nearly functional example code (you just have to provide\n`generate_one_completion` to make it work) that saves generated completions for\nthe single-line infilling benchmark to `samples.jsonl`.\n```\nfrom human_eval_infilling.data import write_jsonl, read_problems\n\nproblems = read_problems(benchmark_name=\"single-line\")\n\nnum_samples_per_task = 100\nsamples = [\n    dict(task_id=task_id, completion=generate_one_completion(problems[task_id][\"prompt\"], problems[task_id][\"suffix\"]))\n    for task_id in problems\n    for _ in range(num_samples_per_task)\n]\nwrite_jsonl(\"samples.jsonl\", samples)\n```\n\nTo evaluate the samples, run\n```\n$ evaluate_infilling_functional_correctness samples.jsonl --benchmark_name=single-line\nReading samples...\n103300it [00:01, 23787.50it/s]\nRunning test suites...\n100%|...| 103300/103300 [16:11<00:00, 33.76it/s]\nWriting results to samples.jsonl_results.jsonl...\n100%|...| 103300/103300 [00:00<00:00, 42876.84it/s]\n{'pass@1': ..., 'pass@10': ..., 'pass@100': ...}\n```\nThis script provides more fine-grained information in a new file ending in\n`<input_path>_results.jsonl`. Each row now contains whether the completion\n`passed` along with the execution `result` which is one of \"passed\", \"timed\nout\", or \"failed\".\n\nAs a quick sanity-check, the example samples should yield 30% pass@1.\n```\n$ evaluate_infilling_functional_correctness data/example_samples.jsonl --benchmark_name=test\nReading samples...\n10it [00:00, 3365.94it/s]\n100%|...| 10/10 [00:03<00:00,  2.76it/s]\nWriting results to data/example_samples.jsonl_results.jsonl...\n100%|...| 10/10 [00:00<00:00, 1309.08it/s]\n{'pass@1': 0.30000000000000004, 'pass@10': 1.0}\n```\n\nThere are 4 available benchmarks: single-line, multi-line, random-span, random-span-light. The first two are introduced in the [InCoder paper](https://arxiv.org/abs/2204.05999) and the latter two are introduced in the [FIM paper](https://arxiv.org/abs/2207.14255). All benchmarks are used extensively in the FIM paper. There is also a dummy benchmark for testing.\n\nBecause there is no unbiased way of estimating pass@k when there are fewer\nsamples than k, the script does not evaluate pass@k for these cases. To\nevaluate with other k values, pass `--k=<comma-separated-values-here>`. For\nother options, see\n```\n$ evaluate_infilling_functional_correctness --help\n```\nHowever, we recommend that you use the default values for the rest.\n\n## Known Issues\n\nWhile evaluation uses very little memory, you might see the following error\nmessage when the system is running out of RAM. Since this may cause some\ncorrect programs to fail, we recommend that you free some memory and try again.\n```\nmalloc: can't allocate region\n```\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTEz"},"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"R_kgDOI-SxcA","name":"apprise","description":"Apprise - Push Notifications that work with just about every platform!","url":"https://github.com/ssoad/apprise","updatedAt":"2024-04-07T07:20:24Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/358ed492a8a74ac30a0017875b22e2f19598300c38b93c33383f138ca8de26c1/ssoad/apprise","stargazers":{"totalCount":0},"readme":{"text":"![Apprise Logo](https://raw.githubusercontent.com/caronc/apprise/master/apprise/assets/themes/default/apprise-logo.png)\n\n<hr/>\n\n**apÂ·prise** / *verb*<br/>\nTo inform or tell (someone). To make one aware of something.\n<hr/>\n\n*Apprise* allows you to send a notification to *almost* all of the most popular *notification* services available to us today such as: Telegram, Discord, Slack, Amazon SNS, Gotify, etc.\n\n* One notification library to rule them all.\n* A common and intuitive notification syntax.\n* Supports the handling of images and attachments (_to the notification services that will accept them_).\n* It's incredibly lightweight.\n* Amazing response times because all messages sent asynchronously.\n\nDevelopers who wish to provide a notification service no longer need to research each and every one out there. They no longer need to try to adapt to the new ones that comeout thereafter. They just need to include this one library and then they can immediately gain access to almost all of the notifications services available to us today.\n\nSystem Administrators and DevOps who wish to send a notification now no longer need to find the right tool for the job. Everything is already wrapped and supported within the `apprise` command line tool (CLI) that ships with this product.\n\n[![Paypal](https://img.shields.io/badge/paypal-donate-green.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=MHANV39UZNQ5E)\n[![Follow](https://img.shields.io/twitter/follow/l2gnux)](https://twitter.com/l2gnux/)<br/>\n[![Discord](https://img.shields.io/discord/558793703356104724.svg?colorB=7289DA&label=Discord&logo=Discord&logoColor=7289DA&style=flat-square)](https://discord.gg/MMPeN2D)\n[![Python](https://img.shields.io/pypi/pyversions/apprise.svg?style=flat-square)](https://pypi.org/project/apprise/)\n[![Build Status](https://github.com/caronc/apprise/actions/workflows/tests.yml/badge.svg)](https://github.com/caronc/apprise/actions/workflows/tests.yml)\n[![CodeCov Status](https://codecov.io/github/caronc/apprise/branch/master/graph/badge.svg)](https://codecov.io/github/caronc/apprise)\n[![PyPi](https://img.shields.io/pypi/dm/apprise.svg?style=flat-square)](https://pypi.org/project/apprise/)\n\n# Table of Contents\n<!--ts-->\n* [Supported Notifications](#supported-notifications)\n  * [Productivity Based Notifications](#productivity-based-notifications)\n  * [SMS Notifications](#sms-notifications)\n  * [Desktop Notifications](#desktop-notifications)\n  * [Email Notifications](#email-notifications)\n  * [Custom Notifications](#custom-notifications)\n* [Installation](#installation)\n* [Command Line Usage](#command-line-usage)\n  * [Configuration Files](#cli-configuration-files)\n  * [File Attachments](#cli-file-attachments)\n  * [Loading Custom Notifications/Hooks](#cli-loading-custom-notificationshooks)\n* [Developer API Usage](#developer-api-usage)\n  * [Configuration Files](#api-configuration-files)\n  * [File Attachments](#api-file-attachments)\n  * [Loading Custom Notifications/Hooks](#api-loading-custom-notificationshooks)\n* [More Supported Links and Documentation](#want-to-learn-more)\n<!--te-->\n\n# Supported Notifications\n\nThe section identifies all of the services supported by this library. [Check out the wiki for more information on the supported modules here](https://github.com/caronc/apprise/wiki).\n\n## Productivity Based Notifications\n\nThe table below identifies the services this tool supports and some example service urls you need to use in order to take advantage of it. Click on any of the services listed below to get more details on how you can configure Apprise to access them.\n\n| Notification Service | Service ID | Default Port | Example Syntax |\n| -------------------- | ---------- | ------------ | -------------- |\n| [Apprise API](https://github.com/caronc/apprise/wiki/Notify_apprise_api)  | apprise:// or apprises:// | (TCP) 80 or 443 | apprise://hostname/Token\n| [AWS SES](https://github.com/caronc/apprise/wiki/Notify_ses)  | ses://   | (TCP) 443   | ses://user@domain/AccessKeyID/AccessSecretKey/RegionName<br/>ses://user@domain/AccessKeyID/AccessSecretKey/RegionName/email1/email2/emailN\n| [Bark](https://github.com/caronc/apprise/wiki/Notify_bark)  | bark://   | (TCP) 80 or 443   | bark://hostname<br />bark://hostname/device_key<br />bark://hostname/device_key1/device_key2/device_keyN\n| [Boxcar](https://github.com/caronc/apprise/wiki/Notify_boxcar)  | boxcar://   | (TCP) 443   | boxcar://hostname<br />boxcar://hostname/@tag<br/>boxcar://hostname/device_token<br />boxcar://hostname/device_token1/device_token2/device_tokenN<br />boxcar://hostname/@tag/@tag2/device_token\n| [Discord](https://github.com/caronc/apprise/wiki/Notify_discord)  | discord://   | (TCP) 443   | discord://webhook_id/webhook_token<br />discord://avatar@webhook_id/webhook_token\n| [Emby](https://github.com/caronc/apprise/wiki/Notify_emby)  | emby:// or embys:// | (TCP) 8096 | emby://user@hostname/<br />emby://user:password@hostname\n| [Enigma2](https://github.com/caronc/apprise/wiki/Notify_enigma2)  | enigma2:// or enigma2s:// | (TCP) 80 or 443 | enigma2://hostname\n| [Faast](https://github.com/caronc/apprise/wiki/Notify_faast) | faast://    | (TCP) 443    | faast://authorizationtoken\n| [FCM](https://github.com/caronc/apprise/wiki/Notify_fcm) | fcm://    | (TCP) 443    | fcm://project@apikey/DEVICE_ID<br />fcm://project@apikey/#TOPIC<br/>fcm://project@apikey/DEVICE_ID1/#topic1/#topic2/DEVICE_ID2/\n| [Flock](https://github.com/caronc/apprise/wiki/Notify_flock) | flock://    | (TCP) 443    | flock://token<br/>flock://botname@token<br/>flock://app_token/u:userid<br/>flock://app_token/g:channel_id<br/>flock://app_token/u:userid/g:channel_id\n| [Gitter](https://github.com/caronc/apprise/wiki/Notify_gitter) | gitter://    | (TCP) 443    | gitter://token/room<br/>gitter://token/room1/room2/roomN\n| [Google Chat](https://github.com/caronc/apprise/wiki/Notify_googlechat) | gchat://    | (TCP) 443    | gchat://workspace/key/token\n| [Gotify](https://github.com/caronc/apprise/wiki/Notify_gotify) | gotify:// or gotifys://   | (TCP) 80 or 443    | gotify://hostname/token<br />gotifys://hostname/token?priority=high\n| [Growl](https://github.com/caronc/apprise/wiki/Notify_growl)  | growl://   | (UDP) 23053   | growl://hostname<br />growl://hostname:portno<br />growl://password@hostname<br />growl://password@hostname:port</br>**Note**: you can also use the get parameter _version_ which can allow the growl request to behave using the older v1.x protocol. An example would look like: growl://hostname?version=1\n| [Guilded](https://github.com/caronc/apprise/wiki/Notify_guilded)  | guilded://   | (TCP) 443   | guilded://webhook_id/webhook_token<br />guilded://avatar@webhook_id/webhook_token\n| [Home Assistant](https://github.com/caronc/apprise/wiki/Notify_homeassistant)       | hassio:// or hassios://   | (TCP) 8123 or 443 | hassio://hostname/accesstoken<br />hassio://user@hostname/accesstoken<br />hassio://user:password@hostname:port/accesstoken<br />hassio://hostname/optional/path/accesstoken\n| [IFTTT](https://github.com/caronc/apprise/wiki/Notify_ifttt) | ifttt://    | (TCP) 443    | ifttt://webhooksID/Event<br />ifttt://webhooksID/Event1/Event2/EventN<br/>ifttt://webhooksID/Event1/?+Key=Value<br/>ifttt://webhooksID/Event1/?-Key=value1\n| [Join](https://github.com/caronc/apprise/wiki/Notify_join) | join://   | (TCP) 443    | join://apikey/device<br />join://apikey/device1/device2/deviceN/<br />join://apikey/group<br />join://apikey/groupA/groupB/groupN<br />join://apikey/DeviceA/groupA/groupN/DeviceN/\n| [KODI](https://github.com/caronc/apprise/wiki/Notify_kodi) | kodi:// or kodis://    | (TCP) 8080 or 443   | kodi://hostname<br />kodi://user@hostname<br />kodi://user:password@hostname:port\n| [Kumulos](https://github.com/caronc/apprise/wiki/Notify_kumulos) | kumulos:// | (TCP) 443 | kumulos://apikey/serverkey\n| [LaMetric Time](https://github.com/caronc/apprise/wiki/Notify_lametric) | lametric:// | (TCP) 443 | lametric://apikey@device_ipaddr<br/>lametric://apikey@hostname:port<br/>lametric://client_id@client_secret\n| [Line](https://github.com/caronc/apprise/wiki/Notify_line) | line:// | (TCP) 443 | line://Token@User<br/>line://Token/User1/User2/UserN\n| [Mailgun](https://github.com/caronc/apprise/wiki/Notify_mailgun) | mailgun:// | (TCP) 443 | mailgun://user@hostname/apikey<br />mailgun://user@hostname/apikey/email<br />mailgun://user@hostname/apikey/email1/email2/emailN<br />mailgun://user@hostname/apikey/?name=\"From%20User\"\n| [Mastodon](https://github.com/caronc/apprise/wiki/Notify_mastodon) | mastodon:// or mastodons://| (TCP) 80 or 443  | mastodon://access_key@hostname<br />mastodon://access_key@hostname/@user<br />mastodon://access_key@hostname/@user1/@user2/@userN\n| [Matrix](https://github.com/caronc/apprise/wiki/Notify_matrix) | matrix:// or matrixs://  | (TCP) 80 or 443 | matrix://hostname<br />matrix://user@hostname<br />matrixs://user:pass@hostname:port/#room_alias<br />matrixs://user:pass@hostname:port/!room_id<br />matrixs://user:pass@hostname:port/#room_alias/!room_id/#room2<br />matrixs://token@hostname:port/?webhook=matrix<br />matrix://user:token@hostname/?webhook=slack&format=markdown\n| [Mattermost](https://github.com/caronc/apprise/wiki/Notify_mattermost) | mmost:// or mmosts:// | (TCP) 8065 | mmost://hostname/authkey<br />mmost://hostname:80/authkey<br />mmost://user@hostname:80/authkey<br />mmost://hostname/authkey?channel=channel<br />mmosts://hostname/authkey<br />mmosts://user@hostname/authkey<br />\n| [Microsoft Teams](https://github.com/caronc/apprise/wiki/Notify_msteams) | msteams://  | (TCP) 443   | msteams://TokenA/TokenB/TokenC/\n| [MQTT](https://github.com/caronc/apprise/wiki/Notify_mqtt) | mqtt://  or mqtts:// | (TCP) 1883 or 8883   | mqtt://hostname/topic<br />mqtt://user@hostname/topic<br />mqtts://user:pass@hostname:9883/topic\n| [Nextcloud](https://github.com/caronc/apprise/wiki/Notify_nextcloud) | ncloud:// or nclouds:// | (TCP) 80 or 443 | ncloud://adminuser:pass@host/User<br/>nclouds://adminuser:pass@host/User1/User2/UserN\n| [NextcloudTalk](https://github.com/caronc/apprise/wiki/Notify_nextcloudtalk) | nctalk:// or nctalks:// | (TCP) 80 or 443 | nctalk://user:pass@host/RoomId<br/>nctalks://user:pass@host/RoomId1/RoomId2/RoomIdN\n| [Notica](https://github.com/caronc/apprise/wiki/Notify_notica) | notica://  | (TCP) 443   | notica://Token/\n| [Notifico](https://github.com/caronc/apprise/wiki/Notify_notifico) | notifico://  | (TCP) 443   | notifico://ProjectID/MessageHook/\n| [ntfy](https://github.com/caronc/apprise/wiki/Notify_ntfy) | ntfy://  | (TCP) 80 or 443   | ntfy://topic/<br/>ntfys://topic/\n| [Office 365](https://github.com/caronc/apprise/wiki/Notify_office365) | o365://  | (TCP) 443   | o365://TenantID:AccountEmail/ClientID/ClientSecret<br />o365://TenantID:AccountEmail/ClientID/ClientSecret/TargetEmail<br />o365://TenantID:AccountEmail/ClientID/ClientSecret/TargetEmail1/TargetEmail2/TargetEmailN\n| [OneSignal](https://github.com/caronc/apprise/wiki/Notify_onesignal) | onesignal:// | (TCP) 443 | onesignal://AppID@APIKey/PlayerID<br/>onesignal://TemplateID:AppID@APIKey/UserID<br/>onesignal://AppID@APIKey/#IncludeSegment<br/>onesignal://AppID@APIKey/Email\n| [Opsgenie](https://github.com/caronc/apprise/wiki/Notify_opsgenie) | opsgenie:// | (TCP) 443 | opsgenie://APIKey<br/>opsgenie://APIKey/UserID<br/>opsgenie://APIKey/#Team<br/>opsgenie://APIKey/\\*Schedule<br/>opsgenie://APIKey/^Escalation\n| [PagerDuty](https://github.com/caronc/apprise/wiki/Notify_pagerduty) | pagerduty:// | (TCP) 443 | pagerduty://IntegrationKey@ApiKey<br/>pagerduty://IntegrationKey@ApiKey/Source/Component\n| [PagerTree](https://github.com/caronc/apprise/wiki/Notify_pagertree) | pagertree:// | (TCP) 443 | pagertree://integration_id\n| [ParsePlatform](https://github.com/caronc/apprise/wiki/Notify_parseplatform) | parsep:// or parseps:// | (TCP) 80 or 443 | parsep://AppID:MasterKey@Hostname<br/>parseps://AppID:MasterKey@Hostname\n| [PopcornNotify](https://github.com/caronc/apprise/wiki/Notify_popcornnotify) | popcorn://  | (TCP) 443   | popcorn://ApiKey/ToPhoneNo<br/>popcorn://ApiKey/ToPhoneNo1/ToPhoneNo2/ToPhoneNoN/<br/>popcorn://ApiKey/ToEmail<br/>popcorn://ApiKey/ToEmail1/ToEmail2/ToEmailN/<br/>popcorn://ApiKey/ToPhoneNo1/ToEmail1/ToPhoneNoN/ToEmailN\n| [Prowl](https://github.com/caronc/apprise/wiki/Notify_prowl) | prowl://   | (TCP) 443    | prowl://apikey<br />prowl://apikey/providerkey\n| [PushBullet](https://github.com/caronc/apprise/wiki/Notify_pushbullet) | pbul://    | (TCP) 443    | pbul://accesstoken<br />pbul://accesstoken/#channel<br/>pbul://accesstoken/A_DEVICE_ID<br />pbul://accesstoken/email@address.com<br />pbul://accesstoken/#channel/#channel2/email@address.net/DEVICE\n| [Pushjet](https://github.com/caronc/apprise/wiki/Notify_pushjet) | pjet:// or pjets:// | (TCP) 80 or 443 | pjet://hostname/secret<br />pjet://hostname:port/secret<br />pjets://secret@hostname/secret<br />pjets://hostname:port/secret\n| [Push (Techulus)](https://github.com/caronc/apprise/wiki/Notify_techulus) | push://    | (TCP) 443    | push://apikey/\n| [Pushed](https://github.com/caronc/apprise/wiki/Notify_pushed) | pushed://    | (TCP) 443    | pushed://appkey/appsecret/<br/>pushed://appkey/appsecret/#ChannelAlias<br/>pushed://appkey/appsecret/#ChannelAlias1/#ChannelAlias2/#ChannelAliasN<br/>pushed://appkey/appsecret/@UserPushedID<br/>pushed://appkey/appsecret/@UserPushedID1/@UserPushedID2/@UserPushedIDN\n| [Pushover](https://github.com/caronc/apprise/wiki/Notify_pushover)  | pover://   | (TCP) 443   | pover://user@token<br />pover://user@token/DEVICE<br />pover://user@token/DEVICE1/DEVICE2/DEVICEN<br />**Note**: you must specify both your user_id and token\n| [PushSafer](https://github.com/caronc/apprise/wiki/Notify_pushsafer)  | psafer:// or psafers://  | (TCP) 80 or 443  | psafer://privatekey<br />psafers://privatekey/DEVICE<br />psafer://privatekey/DEVICE1/DEVICE2/DEVICEN\n| [Reddit](https://github.com/caronc/apprise/wiki/Notify_reddit) | reddit:// | (TCP) 443   | reddit://user:password@app_id/app_secret/subreddit<br />reddit://user:password@app_id/app_secret/sub1/sub2/subN\n| [Rocket.Chat](https://github.com/caronc/apprise/wiki/Notify_rocketchat) | rocket:// or rockets://  | (TCP) 80 or 443   | rocket://user:password@hostname/RoomID/Channel<br />rockets://user:password@hostname:443/#Channel1/#Channel1/RoomID<br />rocket://user:password@hostname/#Channel<br />rocket://webhook@hostname<br />rockets://webhook@hostname/@User/#Channel\n| [Ryver](https://github.com/caronc/apprise/wiki/Notify_ryver) | ryver://  | (TCP) 443   | ryver://Organization/Token<br />ryver://botname@Organization/Token\n| [SendGrid](https://github.com/caronc/apprise/wiki/Notify_sendgrid) | sendgrid://  | (TCP) 443   | sendgrid://APIToken:FromEmail/<br />sendgrid://APIToken:FromEmail/ToEmail<br />sendgrid://APIToken:FromEmail/ToEmail1/ToEmail2/ToEmailN/\n| [ServerChan](https://github.com/caronc/apprise/wiki/Notify_serverchan) | schan://   | (TCP) 443    | schan://sendkey/\n| [Signal API](https://github.com/caronc/apprise/wiki/Notify_signal) | signal://  or signals:// | (TCP) 80 or 443  | signal://hostname:port/FromPhoneNo<br/>signal://hostname:port/FromPhoneNo/ToPhoneNo<br/>signal://hostname:port/FromPhoneNo/ToPhoneNo1/ToPhoneNo2/ToPhoneNoN/\n| [SimplePush](https://github.com/caronc/apprise/wiki/Notify_simplepush) | spush://   | (TCP) 443    | spush://apikey<br />spush://salt:password@apikey<br />spush://apikey?event=Apprise\n| [Slack](https://github.com/caronc/apprise/wiki/Notify_slack) | slack://  | (TCP) 443   | slack://TokenA/TokenB/TokenC/<br />slack://TokenA/TokenB/TokenC/Channel<br />slack://botname@TokenA/TokenB/TokenC/Channel<br />slack://user@TokenA/TokenB/TokenC/Channel1/Channel2/ChannelN\n| [SMTP2Go](https://github.com/caronc/apprise/wiki/Notify_smtp2go) | smtp2go:// | (TCP) 443 | smtp2go://user@hostname/apikey<br />smtp2go://user@hostname/apikey/email<br />smtp2go://user@hostname/apikey/email1/email2/emailN<br />smtp2go://user@hostname/apikey/?name=\"From%20User\"\n| [Streamlabs](https://github.com/caronc/apprise/wiki/Notify_streamlabs) | strmlabs:// | (TCP) 443 | strmlabs://AccessToken/<br/>strmlabs://AccessToken/?name=name&identifier=identifier&amount=0&currency=USD\n| [SparkPost](https://github.com/caronc/apprise/wiki/Notify_sparkpost) | sparkpost:// | (TCP) 443 | sparkpost://user@hostname/apikey<br />sparkpost://user@hostname/apikey/email<br />sparkpost://user@hostname/apikey/email1/email2/emailN<br />sparkpost://user@hostname/apikey/?name=\"From%20User\"\n| [Spontit](https://github.com/caronc/apprise/wiki/Notify_spontit) | spontit://  | (TCP) 443   | spontit://UserID@APIKey/<br />spontit://UserID@APIKey/Channel<br />spontit://UserID@APIKey/Channel1/Channel2/ChannelN\n| [Syslog](https://github.com/caronc/apprise/wiki/Notify_syslog) | syslog://  | (UDP) 514 (_if hostname specified_) | syslog://<br />syslog://Facility<br />syslog://hostname<br />syslog://hostname/Facility\n| [Telegram](https://github.com/caronc/apprise/wiki/Notify_telegram) | tgram://  | (TCP) 443   | tgram://bottoken/ChatID<br />tgram://bottoken/ChatID1/ChatID2/ChatIDN\n| [Twitter](https://github.com/caronc/apprise/wiki/Notify_twitter) | twitter://  | (TCP) 443   | twitter://CKey/CSecret/AKey/ASecret<br/>twitter://user@CKey/CSecret/AKey/ASecret<br/>twitter://CKey/CSecret/AKey/ASecret/User1/User2/User2<br/>twitter://CKey/CSecret/AKey/ASecret?mode=tweet\n| [Twist](https://github.com/caronc/apprise/wiki/Notify_twist) | twist://  | (TCP) 443   | twist://pasword:login<br/>twist://password:login/#channel<br/>twist://password:login/#team:channel<br/>twist://password:login/#team:channel1/channel2/#team3:channel\n| [XBMC](https://github.com/caronc/apprise/wiki/Notify_xbmc) | xbmc:// or xbmcs://    | (TCP) 8080 or 443   | xbmc://hostname<br />xbmc://user@hostname<br />xbmc://user:password@hostname:port\n| [Webex Teams (Cisco)](https://github.com/caronc/apprise/wiki/Notify_wxteams) | wxteams://  | (TCP) 443   | wxteams://Token\n| [Zulip Chat](https://github.com/caronc/apprise/wiki/Notify_zulip) | zulip://  | (TCP) 443   | zulip://botname@Organization/Token<br />zulip://botname@Organization/Token/Stream<br />zulip://botname@Organization/Token/Email\n\n## SMS Notifications\n\n| Notification Service | Service ID | Default Port | Example Syntax |\n| -------------------- | ---------- | ------------ | -------------- |\n| [AWS SNS](https://github.com/caronc/apprise/wiki/Notify_sns)  | sns://   | (TCP) 443   | sns://AccessKeyID/AccessSecretKey/RegionName/+PhoneNo<br/>sns://AccessKeyID/AccessSecretKey/RegionName/+PhoneNo1/+PhoneNo2/+PhoneNoN<br/>sns://AccessKeyID/AccessSecretKey/RegionName/Topic<br/>sns://AccessKeyID/AccessSecretKey/RegionName/Topic1/Topic2/TopicN\n| [BulkSMS](https://github.com/caronc/apprise/wiki/Notify_bulksms) | bulksms://  | (TCP) 443   | bulksms://user:password@ToPhoneNo<br/>bulksms://User:Password@ToPhoneNo1/ToPhoneNo2/ToPhoneNoN/\n| [ClickSend](https://github.com/caronc/apprise/wiki/Notify_clicksend) | clicksend://  | (TCP) 443   | clicksend://user:pass@PhoneNo<br/>clicksend://user:pass@ToPhoneNo1/ToPhoneNo2/ToPhoneNoN\n| [DAPNET](https://github.com/caronc/apprise/wiki/Notify_dapnet) | dapnet://  | (TCP) 80   | dapnet://user:pass@callsign<br/>dapnet://user:pass@callsign1/callsign2/callsignN\n| [D7 Networks](https://github.com/caronc/apprise/wiki/Notify_d7networks) | d7sms://  | (TCP) 443   | d7sms://token@PhoneNo<br/>d7sms://token@ToPhoneNo1/ToPhoneNo2/ToPhoneNoN\n| [DingTalk](https://github.com/caronc/apprise/wiki/Notify_dingtalk)  | dingtalk://   | (TCP) 443   | dingtalk://token/<br />dingtalk://token/ToPhoneNo<br />dingtalk://token/ToPhoneNo1/ToPhoneNo2/ToPhoneNo1/\n| [Kavenegar](https://github.com/caronc/apprise/wiki/Notify_kavenegar) | kavenegar://  | (TCP) 443   | kavenegar://ApiKey/ToPhoneNo<br/>kavenegar://FromPhoneNo@ApiKey/ToPhoneNo<br/>kavenegar://ApiKey/ToPhoneNo1/ToPhoneNo2/ToPhoneNoN\n| [MessageBird](https://github.com/caronc/apprise/wiki/Notify_messagebird) | msgbird://  | (TCP) 443   | msgbird://ApiKey/FromPhoneNo<br/>msgbird://ApiKey/FromPhoneNo/ToPhoneNo<br/>msgbird://ApiKey/FromPhoneNo/ToPhoneNo1/ToPhoneNo2/ToPhoneNoN/\n| [MSG91](https://github.com/caronc/apprise/wiki/Notify_msg91) | msg91://  | (TCP) 443   | msg91://AuthKey/ToPhoneNo<br/>msg91://SenderID@AuthKey/ToPhoneNo<br/>msg91://AuthKey/ToPhoneNo1/ToPhoneNo2/ToPhoneNoN/\n| [Signal API](https://github.com/caronc/apprise/wiki/Notify_signal) | signal://  or signals:// | (TCP) 80 or 443  | signal://hostname:port/FromPhoneNo<br/>signal://hostname:port/FromPhoneNo/ToPhoneNo<br/>signal://hostname:port/FromPhoneNo/ToPhoneNo1/ToPhoneNo2/ToPhoneNoN/\n| [Sinch](https://github.com/caronc/apprise/wiki/Notify_sinch) | sinch://  | (TCP) 443   | sinch://ServicePlanId:ApiToken@FromPhoneNo<br/>sinch://ServicePlanId:ApiToken@FromPhoneNo/ToPhoneNo<br/>sinch://ServicePlanId:ApiToken@FromPhoneNo/ToPhoneNo1/ToPhoneNo2/ToPhoneNoN/<br/>sinch://ServicePlanId:ApiToken@ShortCode/ToPhoneNo<br/>sinch://ServicePlanId:ApiToken@ShortCode/ToPhoneNo1/ToPhoneNo2/ToPhoneNoN/\n| [SMSEagle](https://github.com/caronc/apprise/wiki/Notify_smseagle) | smseagle://  or smseagles:// | (TCP) 80 or 443  | smseagles://hostname:port/ToPhoneNo<br/>smseagles://hostname:port/@ToContact<br/>smseagles://hostname:port/#ToGroup<br/>smseagles://hostname:port/ToPhoneNo1/#ToGroup/@ToContact/\n| [Twilio](https://github.com/caronc/apprise/wiki/Notify_twilio) | twilio://  | (TCP) 443   | twilio://AccountSid:AuthToken@FromPhoneNo<br/>twilio://AccountSid:AuthToken@FromPhoneNo/ToPhoneNo<br/>twilio://AccountSid:AuthToken@FromPhoneNo/ToPhoneNo1/ToPhoneNo2/ToPhoneNoN/<br/>twilio://AccountSid:AuthToken@FromPhoneNo/ToPhoneNo?apikey=Key<br/>twilio://AccountSid:AuthToken@ShortCode/ToPhoneNo<br/>twilio://AccountSid:AuthToken@ShortCode/ToPhoneNo1/ToPhoneNo2/ToPhoneNoN/\n| [Voipms](https://github.com/caronc/apprise/wiki/Notify_voipms) | voipms://  | (TCP) 443   | voipms://password:email/FromPhoneNo<br/>voipms://password:email/FromPhoneNo/ToPhoneNo<br/>voipms://password:email/FromPhoneNo/ToPhoneNo1/ToPhoneNo2/ToPhoneNoN/\n| [Vonage](https://github.com/caronc/apprise/wiki/Notify_nexmo) (formerly Nexmo) | nexmo://  | (TCP) 443   | nexmo://ApiKey:ApiSecret@FromPhoneNo<br/>nexmo://ApiKey:ApiSecret@FromPhoneNo/ToPhoneNo<br/>nexmo://ApiKey:ApiSecret@FromPhoneNo/ToPhoneNo1/ToPhoneNo2/ToPhoneNoN/\n\n## Desktop Notifications\n\n| Notification Service | Service ID | Default Port | Example Syntax |\n| -------------------- | ---------- | ------------ | -------------- |\n| [Linux DBus Notifications](https://github.com/caronc/apprise/wiki/Notify_dbus)  | dbus://<br />qt://<br />glib://<br />kde://  | n/a  | dbus://<br />qt://<br />glib://<br />kde://\n| [Linux Gnome Notifications](https://github.com/caronc/apprise/wiki/Notify_gnome) | gnome://    |        n/a          | gnome://\n| [MacOS X Notifications](https://github.com/caronc/apprise/wiki/Notify_macosx) | macosx://    |        n/a          | macosx://\n| [Windows Notifications](https://github.com/caronc/apprise/wiki/Notify_windows) | windows://    |        n/a          | windows://\n\n## Email Notifications\n\n| Service ID | Default Port | Example Syntax |\n| ---------- | ------------ | -------------- |\n| [mailto://](https://github.com/caronc/apprise/wiki/Notify_email)  |  (TCP) 25    | mailto://userid:pass@domain.com<br />mailto://domain.com?user=userid&pass=password<br/>mailto://domain.com:2525?user=userid&pass=password<br />mailto://user@gmail.com&pass=password<br />mailto://mySendingUsername:mySendingPassword@example.com?to=receivingAddress@example.com<br />mailto://userid:password@example.com?smtp=mail.example.com&from=noreply@example.com&name=no%20reply\n| [mailtos://](https://github.com/caronc/apprise/wiki/Notify_email) |  (TCP) 587   | mailtos://userid:pass@domain.com<br />mailtos://domain.com?user=userid&pass=password<br/>mailtos://domain.com:465?user=userid&pass=password<br />mailtos://user@hotmail.com&pass=password<br />mailtos://mySendingUsername:mySendingPassword@example.com?to=receivingAddress@example.com<br />mailtos://userid:password@example.com?smtp=mail.example.com&from=noreply@example.com&name=no%20reply\n\nApprise have some email services built right into it (such as yahoo, fastmail, hotmail, gmail, etc) that greatly simplify the mailto:// service.  See more details [here](https://github.com/caronc/apprise/wiki/Notify_email).\n\n## Custom Notifications\n\n| Post Method          | Service ID | Default Port | Example Syntax |\n| -------------------- | ---------- | ------------ | -------------- |\n| [Form](https://github.com/caronc/apprise/wiki/Notify_Custom_Form)       | form:// or form://   | (TCP) 80 or 443 | form://hostname<br />form://user@hostname<br />form://user:password@hostname:port<br />form://hostname/a/path/to/post/to\n| [JSON](https://github.com/caronc/apprise/wiki/Notify_Custom_JSON)       | json:// or jsons://   | (TCP) 80 or 443 | json://hostname<br />json://user@hostname<br />json://user:password@hostname:port<br />json://hostname/a/path/to/post/to\n| [XML](https://github.com/caronc/apprise/wiki/Notify_Custom_XML)         | xml:// or xmls://   | (TCP) 80 or 443 | xml://hostname<br />xml://user@hostname<br />xml://user:password@hostname:port<br />xml://hostname/a/path/to/post/to\n\n# Installation\n\nThe easiest way is to install this package is from pypi:\n```bash\npip install apprise\n```\n\nApprise is also packaged as an RPM and available through [EPEL](https://docs.fedoraproject.org/en-US/epel/) supporting CentOS, Redhat, Rocky, Oracle Linux, etc.\n```bash\n# Follow instructions on https://docs.fedoraproject.org/en-US/epel\n# to get your system connected up to EPEL and then:\n# Redhat/CentOS 7.x users\nyum install apprise\n\n# Redhat/CentOS 8.x+ and/or Fedora Users\ndnf install apprise\n```\n\nYou can also check out the [Graphical version of Apprise](https://github.com/caronc/apprise-api) to centralize your configuration and notifications through a managable webpage.\n\n# Command Line Usage\n\nA small command line interface (CLI) tool is also provided with this package called *apprise*. If you know the server urls you wish to notify, you can simply provide them all on the command line and send your notifications that way:\n```bash\n# Send a notification to as many servers as you want\n# as you can easily chain one after another (the -vv provides some\n# additional verbosity to help let you know what is going on):\napprise -vv -t 'my title' -b 'my notification body' \\\n   'mailto://myemail:mypass@gmail.com' \\\n   'pbul://o.gn5kj6nfhv736I7jC3cj3QLRiyhgl98b'\n\n# If you don't specify a --body (-b) then stdin is used allowing\n# you to use the tool as part of your every day administration:\ncat /proc/cpuinfo | apprise -vv -t 'cpu info' \\\n   'mailto://myemail:mypass@gmail.com'\n\n# The title field is totally optional\nuptime | apprise -vv \\\n   'discord:///4174216298/JHMHI8qBe7bk2ZwO5U711o3dV_js'\n```\n\n## CLI Configuration Files\n\nNo one wants to put their credentials out for everyone to see on the command line.  No problem *apprise* also supports configuration files.  It can handle both a specific [YAML format](https://github.com/caronc/apprise/wiki/config_yaml) or a very simple [TEXT format](https://github.com/caronc/apprise/wiki/config_text). You can also pull these configuration files via an HTTP query too! You can read more about the expected structure of the configuration files [here](https://github.com/caronc/apprise/wiki/config).\n```bash\n# By default if no url or configuration is specified apprise will attempt to load\n# configuration files (if present) from:\n#  ~/.apprise\n#  ~/.apprise.yml\n#  ~/.config/apprise\n#  ~/.config/apprise.yml\n\n# Also a subdirectory handling allows you to leverage plugins\n#  ~/.apprise/apprise\n#  ~/.apprise/apprise.yml\n#  ~/.config/apprise/apprise\n#  ~/.config/apprise/apprise.yml\n\n# Windows users can store their default configuration files here:\n#  %APPDATA%/Apprise/apprise\n#  %APPDATA%/Apprise/apprise.yml\n#  %LOCALAPPDATA%/Apprise/apprise\n#  %LOCALAPPDATA%/Apprise/apprise.yml\n\n# If you loaded one of those files, your command line gets really easy:\napprise -vv -t 'my title' -b 'my notification body'\n\n# If you want to deviate from the default paths or specify more than one,\n# just specify them using the --config switch:\napprise -vv -t 'my title' -b 'my notification body' \\\n   --config=/path/to/my/config.yml\n\n# Got lots of configuration locations? No problem, you can specify them all:\n# Apprise can even fetch the configuration from over a network!\napprise -vv -t 'my title' -b 'my notification body' \\\n   --config=/path/to/my/config.yml \\\n   --config=https://localhost/my/apprise/config\n```\n\n## CLI File Attachments\n\nApprise also supports file attachments too! Specify as many attachments to a notification as you want.\n```bash\n# Send a funny image you found on the internet to a colleague:\napprise -vv --title 'Agile Joke' \\\n        --body 'Did you see this one yet?' \\\n        --attach https://i.redd.it/my2t4d2fx0u31.jpg \\\n        'mailto://myemail:mypass@gmail.com'\n\n# Easily send an update from a critical server to your dev team\napprise -vv --title 'system crash' \\\n        --body 'I do not think Jim fixed the bug; see attached...' \\\n        --attach /var/log/myprogram.log \\\n        --attach /var/debug/core.2345 \\\n        --tag devteam\n```\n\n## CLI Loading Custom Notifications/Hooks\n\nTo create your own custom `schema://` hook so that you can trigger your own custom code,\nsimply include the `@notify` decorator to wrap your function.\n```python\nfrom apprise.decorators import notify\n#\n# The below assumes you want to catch foobar:// calls:\n#\n@notify(on=\"foobar\", name=\"My Custom Foobar Plugin\")\ndef my_custom_notification_wrapper(body, title, notify_type, *args, **kwargs):\n    \"\"\"My custom notification function that triggers on all foobar:// calls\n    \"\"\"\n    # Write all of your code here... as an example...\n    print(\"{}: {} - {}\".format(notify_type.upper(), title, body))\n\n    # Returning True/False is a way to relay your status back to Apprise.\n    # Returning nothing (None by default) is always interpreted as a Success\n```\n\nOnce you've defined your custom hook, you just need to tell Apprise where it is at runtime.\n```bash\n# By default if no plugin path is specified apprise will attempt to load\n# all plugin files (if present) from the following directory paths:\n#  ~/.apprise/plugins\n#  ~/.config/apprise/plugins\n\n# Windows users can store their default plugin files in these directories:\n#  %APPDATA%/Apprise/plugins\n#  %LOCALAPPDATA%/Apprise/plugins\n\n# If you placed your plugin file within one of the directories already defined\n# above, then your call simply needs to look like:\napprise -vv --title 'custom override' \\\n        --body 'the body of my message' \\\n        foobar:\\\\\n\n# However you can over-ride the path like so\napprise -vv --title 'custom override' \\\n        --body 'the body of my message' \\\n        --plugin-path /path/to/my/plugin.py \\\n        foobar:\\\\\n```\n\nYou can read more about creating your own custom notifications and/or hooks [here](https://github.com/caronc/apprise/wiki/decorator_notify).\n\n# Developer API Usage\n\nTo send a notification from within your python application, just do the following:\n```python\nimport apprise\n\n# Create an Apprise instance\napobj = apprise.Apprise()\n\n# Add all of the notification services by their server url.\n# A sample email notification:\napobj.add('mailto://myuserid:mypass@gmail.com')\n\n# A sample pushbullet notification\napobj.add('pbul://o.gn5kj6nfhv736I7jC3cj3QLRiyhgl98b')\n\n# Then notify these services any time you desire. The below would\n# notify all of the services loaded into our Apprise object.\napobj.notify(\n    body='what a great notification service!',\n    title='my notification title',\n)\n```\n\n## API Configuration Files\n\nDevelopers need access to configuration files too. The good news is their use just involves declaring another object (called *AppriseConfig*) that the *Apprise* object can ingest.  You can also freely mix and match config and notification entries as often as you wish! You can read more about the expected structure of the configuration files [here](https://github.com/caronc/apprise/wiki/config).\n```python\nimport apprise\n\n# Create an Apprise instance\napobj = apprise.Apprise()\n\n# Create an Config instance\nconfig = apprise.AppriseConfig()\n\n# Add a configuration source:\nconfig.add('/path/to/my/config.yml')\n\n# Add another...\nconfig.add('https://myserver:8080/path/to/config')\n\n# Make sure to add our config into our apprise object\napobj.add(config)\n\n# You can mix and match; add an entry directly if you want too\n# In this entry we associate the 'admin' tag with our notification\napobj.add('mailto://myuser:mypass@hotmail.com', tag='admin')\n\n# Then notify these services any time you desire. The below would\n# notify all of the services that have not been bound to any specific\n# tag.\napobj.notify(\n    body='what a great notification service!',\n    title='my notification title',\n)\n\n# Tagging allows you to specifically target only specific notification\n# services you've loaded:\napobj.notify(\n    body='send a notification to our admin group',\n    title='Attention Admins',\n    # notify any services tagged with the 'admin' tag\n    tag='admin',\n)\n\n# If you want to notify absolutely everything (regardless of whether\n# it's been tagged or not), just use the reserved tag of 'all':\napobj.notify(\n    body='send a notification to our admin group',\n    title='Attention Admins',\n    # notify absolutely everything loaded, regardless on wether\n    # it has a tag associated with it or not:\n    tag='all',\n)\n```\n\n## API File Attachments\n\nAttachments are very easy to send using the Apprise API:\n```python\nimport apprise\n\n# Create an Apprise instance\napobj = apprise.Apprise()\n\n# Add at least one service you want to notify\napobj.add('mailto://myuser:mypass@hotmail.com')\n\n# Then send your attachment.\napobj.notify(\n    title='A great photo of our family',\n    body='The flash caused Jane to close her eyes! hah! :)',\n    attach='/local/path/to/my/DSC_003.jpg',\n)\n\n# Send a web based attachment too! In the below example, we connect to a home\n# security camera and send a live image to an email. By default remote web\n# content is cached, but for a security camera we might want to call notify\n# again later in our code, so we want our last image retrieved to expire(in\n# this case after 3 seconds).\napobj.notify(\n    title='Latest security image',\n    attach='http://admin:password@hikvision-cam01/ISAPI/Streaming/channels/101/picture?cache=3'\n)\n```\n\nTo send more than one attachment, just use a list, set, or tuple instead:\n```python\nimport apprise\n\n# Create an Apprise instance\napobj = apprise.Apprise()\n\n# Add at least one service you want to notify\napobj.add('mailto://myuser:mypass@hotmail.com')\n\n# Now add all of the entries we're interested in:\nattach = (\n    # ?name= allows us to rename the actual jpeg as found on the site\n    # to be another name when sent to our receipient(s)\n    'https://i.redd.it/my2t4d2fx0u31.jpg?name=FlyingToMars.jpg',\n\n    # Now add another:\n    '/path/to/funny/joke.gif',\n)\n\n# Send your multiple attachments with a single notify call:\napobj.notify(\n    title='Some good jokes.',\n    body='Hey guys, check out these!',\n    attach=attach,\n)\n```\n\n## API Loading Custom Notifications/Hooks\n\nBy default, no custom plugins are loaded at all for those building from within the Apprise API.\nIt's at the developers discretion to load custom modules. But should you choose to do so, it's as easy\nas including the path reference in the `AppriseAsset()` object prior to the initialization of your `Apprise()`\ninstance.\n\nFor example:\n```python\nfrom apprise import Apprise\nfrom apprise import AppriseAsset\n\n# Prepare your Asset object so that you can enable the custom plugins to\n# be loaded for your instance of Apprise...\nasset = AppriseAsset(plugin_paths=\"/path/to/scan\")\n\n# OR You can also generate scan more then one file too:\nasset = AppriseAsset(\n    plugin_paths=[\n        # Iterate over all python libraries found in the root of the\n        # specified path. This is NOT a recursive (directory) scan; only\n        # the first level is parsed. HOWEVER, if a directory containing\n        # an __init__.py is found, it will be included in the load.\n        \"/dir/containing/many/python/libraries\",\n\n        # An absolute path to a plugin.py to exclusively load\n        \"/path/to/plugin.py\",\n\n        # if you point to a directory that has an __init__.py file found in\n        # it, then only that file is loaded (it's similar to point to a\n        # absolute .py file. Hence, there is no (level 1) scanning at all\n        # within the directory specified.\n        \"/path/to/dir/library\"\n    ]\n)\n\n# Now that we've got our asset, we just work with our Apprise object as we\n# normally do\naobj = Apprise(asset=asset)\n\n# If our new custom `foobar://` library was loaded (presuming we prepared\n# one like in the examples above).  then you would be able to safely add it\n# into Apprise at this point\naobj.add('foobar://')\n\n# Send our notification out through our foobar://\naobj.notify(\"test\")\n```\n\nYou can read more about creating your own custom notifications and/or hooks [here](https://github.com/caronc/apprise/wiki/decorator_notify).\n\n# Notable Sponsors\n\n- ðŸš€ [Novu - Open-source notification infrastructure](https://github.novu.co/apprise)\n\n# Want To Learn More?\n\nIf you're interested in reading more about this and other methods on how to customize your own notifications, please check out the following links:\n* ðŸ“£ [Using the CLI](https://github.com/caronc/apprise/wiki/CLI_Usage)\n* ðŸ› ï¸ [Development API](https://github.com/caronc/apprise/wiki/Development_API)\n* ðŸ”§ [Troubleshooting](https://github.com/caronc/apprise/wiki/Troubleshooting)\n* âš™ï¸ [Configuration File Help](https://github.com/caronc/apprise/wiki/config)\n* âš¡ [Create Your Own Custom Notifications](https://github.com/caronc/apprise/wiki/decorator_notify)\n* ðŸŒŽ [Apprise API/Web Interface](https://github.com/caronc/apprise-api)\n* ðŸŽ‰ [Showcase](https://github.com/caronc/apprise/wiki/showcase)\n\nWant to help make Apprise better?\n* ðŸ’¡ [Contribute to the Apprise Code Base](https://github.com/caronc/apprise/wiki/Development_Contribution)\n* â¤ï¸ [Sponsorship and Donations](https://github.com/caronc/apprise/wiki/Sponsors)\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTA="},"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Shell","color":"#89e051"},{"name":"Python","color":"#3572A5"},{"name":"HTML","color":"#e34c26"},{"name":"Roff","color":"#ecdebe"}]}},{"id":"R_kgDOI1PODQ","name":"Pesidious","description":"Malware Mutation Using Reinforcement Learning and Generative Adversarial Networks","url":"https://github.com/ssoad/Pesidious","updatedAt":"2024-04-07T07:19:50Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/c851100419c32ff46ed0d03d216c7411c24d206d59985277a5e6f4b0dd324256/ssoad/Pesidious","stargazers":{"totalCount":0},"readme":{"text":"\r\n![Logo](https://github.com/CyberForce/Pesidious/blob/master/pesidoius%20logo.png)\r\n\r\n# Malware Mutation using Deep Reinforcement Learning and GANs \r\n\r\nThe purpose of the tool is to use artificial intelligence to mutate a malware (PE32 only) sample to bypass AI powered classifiers while keeping its functionality intact. In the past, notable work has been done in this domain with researchers either looking at reinforcement learning or generative adversarial networks as their weapons of choice to modify the states of a malware executable in order to deceive anti-virus agents. Our solution makes use of a combination of deep reinforcement learning and GANs in order to overcome some of the limitations faced while using these approaches independently as showen below.\r\n\r\n\r\n![Diagram](https://github.com/CyberForce/Pesidious/blob/master/Pesidious%20architecture%20(simplified).png)\r\n\r\nFind our full documentation for the tool [here](https://vaya97chandni.gitbook.io/pesidious/) \r\n\r\n## Installation Instructions\r\n\r\n> :warning: Since this tool deals with malware files, it is strongly recommended to use a virtual machine. After installation of the tool, make sure to disconnect from the network.\r\n\r\n\r\nThe following steps will guide you through all the installations required to set up the environment.\r\n\r\n1. [Install and set up Python 3.6.](https://realpython.com/installing-python/)\r\n\r\n1. Clone the repository. \r\n    ```sh\r\n    git clone https://github.com/CyberForce/Pesidious\r\n    ```\r\n1. Move into the project directory. \r\n\r\n    ```sh\r\n    cd Pesidious\r\n    ```\r\n\r\n1. [Set up and activate a virtual environment with Python 3.6](https://docs.python.org/3/tutorial/venv.html)\r\n    > It is recommended to use a virtual environment to avoid conflicts between packages used by different applications\r\n\r\n\r\n1. Make sure that you have pip 8.1.1 installed and set up.\r\n   > This is due to later versions of pip not playing well with the PyTorch libary. \r\n\r\n   ```sh\r\n   pip install pip==8.1.1\r\n   ```\r\n    \r\n1. Install all the required libraries, by installing the requirements.txt file.\r\n\r\n    ```sh\r\n    pip install -r pip_requirements/requirements.txt\r\n    ```\r\n\r\n### Mutate Your Malware\r\n\r\nThe output from GAN has already been stored as (`RL_Features/adverarial_imports_set.pk` and `RL_Features/adverarial_sections_set.pk`) which will be used for when adding imports and sections to the malware for mutation. \r\n\r\n1. You can test the sample classifier to score malware files.\r\n\r\n    ```\r\n    python classifier.py -d /path/to/directory/with/malware/files\r\n    ```\r\n\r\n1. Run the `mutate.py` python script to mutate your malware samples. \r\n\r\n   ```\r\n   python mutate.py -d /path/to/directory/with/malware/files\r\n   ```\r\n\r\n1. The mutated malware files will be stored in a directory called Mutated_malware in the following format\r\n\r\n    ```\r\n    Mutated_malware/mutated_<name-of-the-file>\r\n    ```\r\n    \r\n1. Once the malware files are mutated, you can run the classifier again to score the mutated malware.\r\n    \r\n    ```\r\n    python classifier.py -d Mutated_malware/\r\n    ```\r\n\r\n## Known Issues and Fixes\r\n\r\n> :warning: WARNING: This segment is currently under construction. We apologize for any inconvinience caused. Please proceed to the next section. [click here](#to-do)\r\n\r\n1. `pip install -r requirements.txt` gives you an error.\r\n\r\n   Solution:\r\n    \r\n      ```\r\n      pip install tqdm\r\n      pip install sklearn\r\n      pip install lief\r\n      ```\r\n   \r\n1. **ModuleNotFoundError: No module named 'tensorboardX'** error while running `python main_malgan.py` script.\r\n      \r\n   Solution:\r\n      \r\n      ```\r\n      pip install tensorboardX\r\n      ```\r\n   \r\n1. **Error with the execution of import-append, section-append (not found)**\r\n     \r\n     Solution\r\n     Give execute permission to these executables using the following commands on your terminal\r\n     \r\n     ```\r\n     cd portable-executable/\r\n     chmod 777 project-add-sections/bin/Debug/project-append-section\r\n     chmod 777 project-add-imports/bin/Debug/project-append-imports\r\n     \r\n     ```\r\n\r\n## Built With\r\n\r\n* [PyTorch](https://pytorch.org/) -  Open source machine learning library based on the Torch library.\r\n* [Lief](https://github.com/lief-project/LIEF) - A cross platform library which can parse, modify and abstract ELF, PE and MachO formats.\r\n* [PE Bliss](https://github.com/BackupGGCode/portable-executable-library) - PE libarry for rebuilding PE files, written in C++.\r\n* [Gym-Malware](https://github.com/endgameinc/gym-malware/) - Malware manipulation environment for OpenAI's gym.\r\n* [MalwareGAN](https://github.com/ZaydH/MalwareGAN) - Adversarial Malware Generation Using GANs.\r\n\r\n\r\n## Authors\r\n\r\n* **Chandni Vaya** - *X-Force Incident Response, IBM Security* - [Github](https://github.com/Chandni97)\r\n* **Bedang Sen** - *X-Force Incident Response, IBM Security* - [Github](http://github.com/bedangSen/)\r\n\r\n## Acknowledgments\r\n\r\n* Gym-Malware Environment:  https://github.com/endgameinc/gym-malware. The environment was modified to add GAN and the mutations were added/changed/removed to improve the evasiveness of the malware and maintain functionality.\r\n* Yanming Lai's (https://github.com/yanminglai/Malware-GAN) and \r\n* Zayd Hammoudeh's (https://github.com/ZaydH/MalwareGAN) work on implementation on Han and Tan's MalGAN played a crucial role in our understanding of the architecture. A majority of the implementation of the MalGAN used in this project has been forked off Hammoudeh's work. \r\n\r\n## References\r\n\r\nAnderson, H., Kharkar, A., Filar, B., Evans, D. and Roth, P. (2018). Learning to Evade Static PE Machine Learning Malware Models via Reinforcement Learning. [online] arXiv.org. Available at: https://arxiv.org/abs/1801.08917.\r\n\r\nDocs.microsoft.com. (n.d.). PE Format - Windows applications. [online] Available at: https://docs.microsoft.com/en-us/windows/win32/debug/pe-format#general-concepts.\r\n\r\nFang, Z., Wang, J., Li, B., Wu, S., Zhou, Y. and Huang, H. (2019). Evading Anti-Malware Engines With Deep Reinforcement Learning. [online] Ieeexplore.ieee.org. Available at: https://ieeexplore.ieee.org/abstract/document/8676031 [Accessed 25 Aug. 2019].\r\nhttps://resources.infosecinstitute.com. (2019). \r\n\r\nMalware Researcherâ€™s Handbook (Demystifying PE File). [online] Available at: https://resources.infosecinstitute.com/2-malware-researchers-handbook-demystifying-pe-file/#gref.\r\n\r\nHu, W. and Tan, Y. (2018). Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN. [online] arXiv.org. Available at: https://arxiv.org/abs/1702.05983.\r\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTEz"},"primaryLanguage":{"name":"C++","color":"#f34b7d"},"languages":{"nodes":[{"name":"C++","color":"#f34b7d"},{"name":"Python","color":"#3572A5"},{"name":"C","color":"#555555"},{"name":"Makefile","color":"#427819"}]}},{"id":"R_kgDOI0ceiQ","name":"tuning_playbook","description":"A playbook for systematically maximizing the performance of deep learning models.","url":"https://github.com/ssoad/tuning_playbook","updatedAt":"2024-04-07T07:20:25Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/fbe3e67254be2fca50391ccf34b7b4a47f34224be3410551c9af8faa3a9f9ff8/ssoad/tuning_playbook","stargazers":{"totalCount":0},"readme":null,"licenseInfo":{"id":"MDc6TGljZW5zZTA="},"primaryLanguage":null,"languages":{"nodes":[]}},{"id":"R_kgDOIx6Wvg","name":"Bringing-Old-Photos-Back-to-Life","description":"Bringing Old Photo Back to Life (CVPR 2020 oral)","url":"https://github.com/ssoad/Bringing-Old-Photos-Back-to-Life","updatedAt":"2024-04-07T07:20:29Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/829c1ff0631b001505a333f0e6f1a81433a94258b81587bba6fecdb3800a0ee2/ssoad/Bringing-Old-Photos-Back-to-Life","stargazers":{"totalCount":0},"readme":{"text":"# Old Photo Restoration (Official PyTorch Implementation)\n\n<img src='imgs/0001.jpg'/>\n\n### [Project Page](http://raywzy.com/Old_Photo/) | [Paper (CVPR version)](https://arxiv.org/abs/2004.09484) | [Paper (Journal version)](https://arxiv.org/pdf/2009.07047v1.pdf) | [Pretrained Model](https://hkustconnect-my.sharepoint.com/:f:/g/personal/bzhangai_connect_ust_hk/Em0KnYOeSSxFtp4g_dhWdf0BdeT3tY12jIYJ6qvSf300cA?e=nXkJH2) | [Colab Demo](https://colab.research.google.com/drive/1NEm6AsybIiC5TwTU_4DqDkQO0nFRB-uA?usp=sharing)  | [Replicate Demo & Docker Image](https://replicate.ai/zhangmozhe/bringing-old-photos-back-to-life) :fire:\n\n**Bringing Old Photos Back to Life, CVPR2020 (Oral)**\n\n**Old Photo Restoration via Deep Latent Space Translation, TPAMI 2022**\n\n[Ziyu Wan](http://raywzy.com/)<sup>1</sup>,\n[Bo Zhang](https://www.microsoft.com/en-us/research/people/zhanbo/)<sup>2</sup>,\n[Dongdong Chen](http://www.dongdongchen.bid/)<sup>3</sup>,\n[Pan Zhang](https://panzhang0212.github.io/)<sup>4</sup>,\n[Dong Chen](https://www.microsoft.com/en-us/research/people/doch/)<sup>2</sup>,\n[Jing Liao](https://liaojing.github.io/html/)<sup>1</sup>,\n[Fang Wen](https://www.microsoft.com/en-us/research/people/fangwen/)<sup>2</sup> <br>\n<sup>1</sup>City University of Hong Kong, <sup>2</sup>Microsoft Research Asia, <sup>3</sup>Microsoft Cloud AI, <sup>4</sup>USTC\n\n<!-- ## Notes of this project\nThe code originates from our research project and the aim is to demonstrate the research idea, so we have not optimized it from a product perspective. And we will spend time to address some common issues, such as out of memory issue, limited resolution, but will not involve too much in engineering problems, such as speedup of the inference, fastapi deployment and so on. **We welcome volunteers to contribute to this project to make it more usable for practical application.** -->\n\n## :sparkles: News\n**2022.3.31**: Our new work regarding old film restoration will be published in CVPR 2022. For more details, please refer to the [project website](http://raywzy.com/Old_Film/) and [github repo](https://github.com/raywzy/Bringing-Old-Films-Back-to-Life).\n\nThe framework now supports the restoration of high-resolution input.\n\n<img src='imgs/HR_result.png'>\n\nTraining code is available and welcome to have a try and learn the training details. \n\nYou can now play with our [Colab](https://colab.research.google.com/drive/1NEm6AsybIiC5TwTU_4DqDkQO0nFRB-uA?usp=sharing) and try it on your photos. \n\n## Requirement\nThe code is tested on Ubuntu with Nvidia GPUs and CUDA installed. Python>=3.6 is required to run the code.\n\n## Installation\n\nClone the Synchronized-BatchNorm-PyTorch repository for\n\n```\ncd Face_Enhancement/models/networks/\ngit clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\ncp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\ncd ../../../\n```\n\n```\ncd Global/detection_models\ngit clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\ncp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\ncd ../../\n```\n\nDownload the landmark detection pretrained model\n\n```\ncd Face_Detection/\nwget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\nbzip2 -d shape_predictor_68_face_landmarks.dat.bz2\ncd ../\n```\n\nDownload the pretrained model, put the file `Face_Enhancement/checkpoints.zip` under `./Face_Enhancement`, and put the file `Global/checkpoints.zip` under `./Global`. Then unzip them respectively.\n\n```\ncd Face_Enhancement/\nwget https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life/releases/download/v1.0/face_checkpoints.zip\nunzip face_checkpoints.zip\ncd ../\ncd Global/\nwget https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life/releases/download/v1.0/global_checkpoints.zip\nunzip global_checkpoints.zip\ncd ../\n```\n\nInstall dependencies:\n\n```bash\npip install -r requirements.txt\n```\n\n## :rocket: How to use?\n\n**Note**: GPU can be set 0 or 0,1,2 or 0,2; use -1 for CPU\n\n### 1) Full Pipeline\n\nYou could easily restore the old photos with one simple command after installation and downloading the pretrained model.\n\nFor images without scratches:\n\n```\npython run.py --input_folder [test_image_folder_path] \\\n              --output_folder [output_path] \\\n              --GPU 0\n```\n\nFor scratched images:\n\n```\npython run.py --input_folder [test_image_folder_path] \\\n              --output_folder [output_path] \\\n              --GPU 0 \\\n              --with_scratch\n```\n\n**For high-resolution images with scratches**:\n\n```\npython run.py --input_folder [test_image_folder_path] \\\n              --output_folder [output_path] \\\n              --GPU 0 \\\n              --with_scratch \\\n              --HR\n```\n\nNote: Please try to use the absolute path. The final results will be saved in `./output_path/final_output/`. You could also check the produced results of different steps in `output_path`.\n\n### 2) Scratch Detection\n\nCurrently we don't plan to release the scratched old photos dataset with labels directly. If you want to get the paired data, you could use our pretrained model to test the collected images to obtain the labels.\n\n```\ncd Global/\npython detection.py --test_path [test_image_folder_path] \\\n                    --output_dir [output_path] \\\n                    --input_size [resize_256|full_size|scale_256]\n```\n\n<img src='imgs/scratch_detection.png'>\n\n### 3) Global Restoration\n\nA triplet domain translation network is proposed to solve both structured degradation and unstructured degradation of old photos.\n\n<p align=\"center\">\n<img src='imgs/pipeline.PNG' width=\"50%\" height=\"50%\"/>\n</p>\n\n```\ncd Global/\npython test.py --Scratch_and_Quality_restore \\\n               --test_input [test_image_folder_path] \\\n               --test_mask [corresponding mask] \\\n               --outputs_dir [output_path]\n\npython test.py --Quality_restore \\\n               --test_input [test_image_folder_path] \\\n               --outputs_dir [output_path]\n```\n\n<img src='imgs/global.png'>\n\n\n### 4) Face Enhancement\n\nWe use a progressive generator to refine the face regions of old photos. More details could be found in our journal submission and `./Face_Enhancement` folder.\n\n<p align=\"center\">\n<img src='imgs/face_pipeline.jpg' width=\"60%\" height=\"60%\"/>\n</p>\n\n\n<img src='imgs/face.png'>\n\n> *NOTE*: \n> This repo is mainly for research purpose and we have not yet optimized the running performance. \n> \n> Since the model is pretrained with 256*256 images, the model may not work ideally for arbitrary resolution.\n\n### 5) GUI\n\nA user-friendly GUI which takes input of image by user and shows result in respective window.\n\n#### How it works:\n\n1. Run GUI.py file.\n2. Click browse and select your image from test_images/old_w_scratch folder to remove scratches.\n3. Click Modify Photo button.\n4. Wait for a while and see results on GUI window.\n5. Exit window by clicking Exit Window and get your result image in output folder.\n\n<img src='imgs/gui.PNG'>\n\n## How to train?\n\n### 1) Create Training File\n\nPut the folders of VOC dataset, collected old photos (e.g., Real_L_old and Real_RGB_old) into one shared folder. Then\n```\ncd Global/data/\npython Create_Bigfile.py\n```\nNote: Remember to modify the code based on your own environment.\n\n### 2) Train the VAEs of domain A and domain B respectively\n\n```\ncd ..\npython train_domain_A.py --use_v2_degradation --continue_train --training_dataset domain_A --name domainA_SR_old_photos --label_nc 0 --loadSize 256 --fineSize 256 --dataroot [your_data_folder] --no_instance --resize_or_crop crop_only --batchSize 100 --no_html --gpu_ids 0,1,2,3 --self_gen --nThreads 4 --n_downsample_global 3 --k_size 4 --use_v2 --mc 64 --start_r 1 --kl 1 --no_cgan --outputs_dir [your_output_folder] --checkpoints_dir [your_ckpt_folder]\n\npython train_domain_B.py --continue_train --training_dataset domain_B --name domainB_old_photos --label_nc 0 --loadSize 256 --fineSize 256 --dataroot [your_data_folder]  --no_instance --resize_or_crop crop_only --batchSize 120 --no_html --gpu_ids 0,1,2,3 --self_gen --nThreads 4 --n_downsample_global 3 --k_size 4 --use_v2 --mc 64 --start_r 1 --kl 1 --no_cgan --outputs_dir [your_output_folder]  --checkpoints_dir [your_ckpt_folder]\n```\nNote: For the --name option, please ensure your experiment name contains \"domainA\" or \"domainB\", which will be used to select different dataset.\n\n### 3) Train the mapping network between domains\n\nTrain the mapping without scratches:\n```\npython train_mapping.py --use_v2_degradation --training_dataset mapping --use_vae_which_epoch 200 --continue_train --name mapping_quality --label_nc 0 --loadSize 256 --fineSize 256 --dataroot [your_data_folder] --no_instance --resize_or_crop crop_only --batchSize 80 --no_html --gpu_ids 0,1,2,3 --nThreads 8 --load_pretrainA [ckpt_of_domainA_SR_old_photos] --load_pretrainB [ckpt_of_domainB_old_photos] --l2_feat 60 --n_downsample_global 3 --mc 64 --k_size 4 --start_r 1 --mapping_n_block 6 --map_mc 512 --use_l1_feat --niter 150 --niter_decay 100 --outputs_dir [your_output_folder] --checkpoints_dir [your_ckpt_folder]\n```\n\n\nTraing the mapping with scraches:\n```\npython train_mapping.py --no_TTUR --NL_res --random_hole --use_SN --correlation_renormalize --training_dataset mapping --NL_use_mask --NL_fusion_method combine --non_local Setting_42 --use_v2_degradation --use_vae_which_epoch 200 --continue_train --name mapping_scratch --label_nc 0 --loadSize 256 --fineSize 256 --dataroot [your_data_folder] --no_instance --resize_or_crop crop_only --batchSize 36 --no_html --gpu_ids 0,1,2,3 --nThreads 8 --load_pretrainA [ckpt_of_domainA_SR_old_photos] --load_pretrainB [ckpt_of_domainB_old_photos] --l2_feat 60 --n_downsample_global 3 --mc 64 --k_size 4 --start_r 1 --mapping_n_block 6 --map_mc 512 --use_l1_feat --niter 150 --niter_decay 100 --outputs_dir [your_output_folder] --checkpoints_dir [your_ckpt_folder] --irregular_mask [absolute_path_of_mask_file]\n```\n\nTraing the mapping with scraches (Multi-Scale Patch Attention for HR input):\n```\npython train_mapping.py --no_TTUR --NL_res --random_hole --use_SN --correlation_renormalize --training_dataset mapping --NL_use_mask --NL_fusion_method combine --non_local Setting_42 --use_v2_degradation --use_vae_which_epoch 200 --continue_train --name mapping_Patch_Attention --label_nc 0 --loadSize 256 --fineSize 256 --dataroot [your_data_folder] --no_instance --resize_or_crop crop_only --batchSize 36 --no_html --gpu_ids 0,1,2,3 --nThreads 8 --load_pretrainA [ckpt_of_domainA_SR_old_photos] --load_pretrainB [ckpt_of_domainB_old_photos] --l2_feat 60 --n_downsample_global 3 --mc 64 --k_size 4 --start_r 1 --mapping_n_block 6 --map_mc 512 --use_l1_feat --niter 150 --niter_decay 100 --outputs_dir [your_output_folder] --checkpoints_dir [your_ckpt_folder] --irregular_mask [absolute_path_of_mask_file] --mapping_exp 1\n```\n\n\n## Citation\n\nIf you find our work useful for your research, please consider citing the following papers :)\n\n```bibtex\n@inproceedings{wan2020bringing,\ntitle={Bringing Old Photos Back to Life},\nauthor={Wan, Ziyu and Zhang, Bo and Chen, Dongdong and Zhang, Pan and Chen, Dong and Liao, Jing and Wen, Fang},\nbooktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\npages={2747--2757},\nyear={2020}\n}\n```\n\n```bibtex\n@article{wan2020old,\n  title={Old Photo Restoration via Deep Latent Space Translation},\n  author={Wan, Ziyu and Zhang, Bo and Chen, Dongdong and Zhang, Pan and Chen, Dong and Liao, Jing and Wen, Fang},\n  journal={arXiv preprint arXiv:2009.07047},\n  year={2020}\n}\n```\n\nIf you are also interested in the legacy photo/video colorization, please refer to [this work](https://github.com/zhangmozhe/video-colorization).\n\n## Maintenance\n\nThis project is currently maintained by Ziyu Wan and is for academic research use only. If you have any questions, feel free to contact raywzy@gmail.com.\n\n## License\n\nThe codes and the pretrained model in this repository are under the MIT license as specified by the LICENSE file. We use our labeled dataset to train the scratch detection model.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTEz"},"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Shell","color":"#89e051"},{"name":"Python","color":"#3572A5"},{"name":"Dockerfile","color":"#384d54"}]}},{"id":"R_kgDOIvTIIg","name":"downloads_path_provider","description":"Flutter plugin to get the download directory","url":"https://github.com/ssoad/downloads_path_provider","updatedAt":"2024-04-07T07:20:07Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/c73bf0f32a1b2df62b9992c716e994b3306ebfeb0db626452f64dc7c9a2e0e4d/ssoad/downloads_path_provider","stargazers":{"totalCount":0},"readme":{"text":"# downloads_path_provider_28\n\nFlutter plugin to get the downloads directory.  \n\n> This plugin has lots of inconsistencies and should no **longer be used**. Feel free to fork and tweak it.\n\n## Getting Started\n\nFor help getting started with Flutter, view our online\n[documentation](https://flutter.io/).\n\nFor help on editing plugin code, view the [documentation](https://flutter.io/developing-packages/#edit-plugin-package).\n\n## Usage\n\n  * Add [downloads_path_provider_28](https://pub.dartlang.org/packages/downloads_path_provider_28#-installing-tab-) as a dependency in your pubspec.yaml file.\n  * Add `<uses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\" />` to your `AndroidManifest.xml`\n\n## Example\n```dart\nimport 'package:downloads_path_provider_28/downloads_path_provider_28.dart';  \n\nFuture<Directory> downloadsDirectory = DownloadsPathProvider.downloadsDirectory;\n```\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTU="},"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Ruby","color":"#701516"},{"name":"Objective-C","color":"#438eff"},{"name":"Java","color":"#b07219"},{"name":"Dart","color":"#00B4AB"}]}},{"id":"R_kgDOIlFRLg","name":"awesome_otp_screen","description":"This Package is for Prebuilt Awesome OTP Verification Screen with Custom Keyboard","url":"https://github.com/ssoad/awesome_otp_screen","updatedAt":"2024-04-07T07:20:28Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/ca7d8be36c086e0c68e6a187f96c6eba201ad44037af43b5436b4031f7491c84/ssoad/awesome_otp_screen","stargazers":{"totalCount":0},"readme":null,"licenseInfo":{"id":"MDc6TGljZW5zZTEz"},"primaryLanguage":{"name":"C++","color":"#f34b7d"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"},{"name":"CMake","color":"#DA3434"},{"name":"C++","color":"#f34b7d"},{"name":"C","color":"#555555"},{"name":"HTML","color":"#e34c26"}]}},{"id":"R_kgDOIS2XGw","name":"flutter_gradients","description":"A curated collection of awesome gradients made in Dart for Flutter","url":"https://github.com/ssoad/flutter_gradients","updatedAt":"2024-04-07T07:20:57Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/e175123317d3d5174bf36f7b7aa70777b342c340582d891b7096ac350fe815c6/ssoad/flutter_gradients","stargazers":{"totalCount":0},"readme":{"text":"[![Flutter Community: after_layout](https://fluttercommunity.dev/_github/header/flutter_gradients)](https://github.com/fluttercommunity/community)\n\n# Flutter Gradients\n\n<img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/header.jpg\" align=\"center\" alt=\"Header\" height=\"500\" width=\"100%\"/>\n\nA curated collection of awesome gradients made in Dart (port of [https://webgradients.com](https://webgradients.com) for Flutter). Only linear gradients included for now.\n\n[![Pub](https://img.shields.io/badge/pub-1.0.0+3-blue)](https://pub.dev/packages/flutter_gradients)\n[![Build Status](https://travis-ci.org/JonathanMonga/flutter_gradients.svg?branch=master)](https://travis-ci.org/JonathanMonga/flutter_gradients)\n\n### Show some :heart: and star the repo to support the project\n\n[![GitHub stars](https://img.shields.io/github/stars/JonathanMonga/flutter_gradients.svg?style=social&label=Star)](https://github.com/JonathanMonga/flutter_gradients) [![GitHub forks](https://img.shields.io/github/forks/JonathanMonga/flutter_gradients.svg?style=social&label=Fork)](https://github.com/JonathanMonga/flutter_gradients/fork) [![GitHub watchers](https://img.shields.io/github/watchers/JonathanMonga/flutter_gradients.svg?style=social&label=Watch)](https://github.com/JonathanMonga/flutter_gradients) [![GitHub followers](https://img.shields.io/github/followers/JonathanMonga.svg?style=social&label=Follow)](https://github.com/JonathanMonga)  \n[![Twitter Follow](https://img.shields.io/twitter/follow/jonathan_monga.svg?style=social)](https://twitter.com/jonathan_monga)\n\n## Installation\n\nAdd the Package\n\n```yaml\ndependencies:\n  flutter_gradients: ^1.0.0+3\n```\n\n# Usage\n\n### Import the package\n\n```dart\nimport 'package:flutter_gradients/flutter_gradients.dart';\n```\n\n## How To Use\n\n### For LinearGradient\n\nBy default `FlutterGradient` will generates the `LinearGradient`.\n\n<img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/angel_care_linear_gradient.png\" align = \"right\" height = \"180\" alt=\"Exemple\">\n\n```dart\n   GradientType type: GradientType.linear;\n```\n\n```dart\n    Container(\n        width: 150,\n        height: 150,\n        decoration: BoxDecoration(\n            shape: BoxShape.circle,\n            gradient: FlutterGradient.warmFlame(),\n        ),\n    );\n```\n\nor\n\n```dart\n    Container(\n        width: 150,\n        height: 150,\n        decoration: BoxDecoration(\n            shape: BoxShape.circle,\n            gradient: FlutterGradient.warmFlame(type: GradientType.linear),\n        ),\n    );\n```\n\n### For RadialGradient\n\nYou can customize the follows values :\n\n- center : The center of the gradient, as an offset into the (-1.0, -1.0) x (1.0, 1.0) square describing the gradient which will be mapped onto the paint box.\n- radius : The radius of the gradient, as a fraction of the shortest side of the paint box.\n- tileMode : How this gradient should tile the plane beyond the outer ring at `radius` pixels from the `center`.\n\n<img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/angel_care_radial_gradient.png\" align = \"right\" height = \"180\" alt=\"Exemple\">\n\n```dart\n   GradientType type: GradientType.radial;\n```\n\n```dart\n    Container(\n        width: 150,\n        height: 150,\n        decoration: BoxDecoration(\n            shape: BoxShape.circle,\n            gradient: FlutterGradient.warmFlame(\n                type: GradientType.radial,\n                center: Alignment.center,\n                radius: 0.5,\n                tileMode = TileMode.clamp,\n           ),\n        ),\n    );\n```\n\n### For SweepGradient\n\nYou can customize the follows values :\n\n- center : The center of the gradient, as an offset into the (-1.0, -1.0) x (1.0, 1.0) square describing the gradient which will be mapped onto the paint box.\n- startAngle : The angle in radians at which stop 0.0 of the gradient is placed.\n- endAngle : The angle in radians at which stop 1.0 of the gradient is placed.\n- tileMode : How this gradient should tile the plane beyond the outer ring at `radius` pixels from the `center`.\n\n<img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/angel_care_sweep_gradient.png\" align = \"right\" height = \"180\" alt=\"Exemple\">\n\n```dart\n   GradientType type: GradientType.sweep;\n```\n\n```dart\n    Container(\n        width: 150,\n        height: 150,\n        decoration: BoxDecoration(\n            shape: BoxShape.circle,\n            gradient: FlutterGradient.warmFlame(\n                type: GradientType.sweep,\n                center: Alignment.center,\n                startAngle: 0.0,\n                endAngle: math.pi * 2,\n                tileMode = TileMode.clamp,\n            ),\n        ),\n    );\n```\n\n## Catalogue\n\n| 1                                                                                                                                      | 2                                                                                                                                      | 3                                                                                                                                      |\n| -------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------- |\n| <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_01.png\" height = \"350\" alt=\"Image 01\"> | <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_02.png\" height = \"350\" alt=\"Image 02\"> | <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_03.png\" height = \"350\" alt=\"Image 03\"> |\n| <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_04.png\" height = \"350\" alt=\"Image 04\"> | <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_05.png\" height = \"350\" alt=\"Image 05\"> | <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_06.png\" height = \"350\" alt=\"Image 06\"> |\n| <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_07.png\" height = \"350\" alt=\"Image 07\"> | <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_08.png\" height = \"350\" alt=\"Image 08\"> | <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_09.png\" height = \"350\" alt=\"Image 09\"> |\n| <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_10.png\" height = \"350\" alt=\"Image 10\"> | <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_11.png\" height = \"350\" alt=\"Image 11\"> | <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_12.png\" height = \"350\" alt=\"Image 12\"> |\n| <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_13.png\" height = \"350\" alt=\"Image 13\"> | <img src=\"https://raw.githubusercontent.com/JonathanMonga/flutter_gradients/master/images/image_14.png\" height = \"350\" alt=\"Image 14\"> |\n\n## Examples\n\nWeb and command-line examples can be found in the `example` folder.\n\n### Web Examples\n\nIn order to run the web examples, please follow these steps:\n\n1. Clone this repo and enter the directory\n2. Run `pub get`\n3. Run `pub run build_runner serve example`\n4. Navigate to [http://localhost:8080/web/](http://localhost:8080/web/) in your browser\n\n### Command Line Examples\n\nIn order to run the command line example, please follow these steps:\n\n1. Clone this repo and enter the directory\n2. Run `pub get`\n3. Run `dart example/lib/main.dart`\n\n### Flutter Example\n\n#### Install Flutter\n\nIn order to run the flutter example, you must have Flutter installed. For installation instructions, view the online\n[documentation](https://flutter.io/).\n\n#### Run the app\n\n1. Open up an Android Emulator, the iOS Simulator, or connect an appropriate mobile device for debugging.\n2. Open up a terminal\n3. `cd` into the `example/lib/` directory\n4. Run `flutter doctor` to ensure you have all Flutter dependencies working.\n5. Run `flutter packages get`\n6. Run `flutter run`\n\n# License\n\n    MIT License\n\n    Copyright (c) 2020 Jonathan Monga\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n    of this software and associated documentation files (the \"Software\"), to deal\n    in the Software without restriction, including without limitation the rights\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n    copies of the Software, and to permit persons to whom the Software is\n    furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in all\n    copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n    SOFTWARE.\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTEz"},"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Shell","color":"#89e051"},{"name":"Ruby","color":"#701516"},{"name":"Objective-C","color":"#438eff"},{"name":"Kotlin","color":"#A97BFF"},{"name":"Dart","color":"#00B4AB"},{"name":"Swift","color":"#F05138"}]}},{"id":"R_kgDOIQVqWA","name":"GodGenesis","description":"A Python3 based C2 server to make life of red teamer a bit easier. The payload is  capable to bypass all the known antiviruses and endpoints.","url":"https://github.com/ssoad/GodGenesis","updatedAt":"2024-04-07T07:20:31Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/bf2d68fcb67eafa6bd66c7b6e0e25a16ab6bdd391a521ac63fc11272c5e07ad2/ssoad/GodGenesis","stargazers":{"totalCount":0},"readme":null,"licenseInfo":{"id":"MDc6TGljZW5zZTEz"},"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"R_kgDOILa4QQ","name":"flutter_game_counter","description":null,"url":"https://github.com/ssoad/flutter_game_counter","updatedAt":"2024-04-07T07:20:33Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/36fe9bf949bcec75e7b238af5a0de40135960bd92cf50435582a9e2a83484040/ssoad/flutter_game_counter","stargazers":{"totalCount":0},"readme":{"text":"# flutter_game\n\nA new Flutter project.\n\n## Getting Started\n\nThis project is a starting point for a Flutter application.\n\nA few resources to get you started if this is your first Flutter project:\n\n- [Lab: Write your first Flutter app](https://docs.flutter.dev/get-started/codelab)\n- [Cookbook: Useful Flutter samples](https://docs.flutter.dev/cookbook)\n\nFor help getting started with Flutter development, view the\n[online documentation](https://docs.flutter.dev/), which offers tutorials,\nsamples, guidance on mobile development, and a full API reference.\n"},"licenseInfo":null,"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"}]}},{"id":"R_kgDOHur59w","name":"django-coding-test","description":null,"url":"https://github.com/ssoad/django-coding-test","updatedAt":"2024-04-07T07:20:38Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/78e552ef271778184419cba84278d783ad6975439eac71f39efcf58cd5c1ea59/ssoad/django-coding-test","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"HTML","color":"#e34c26"},"languages":{"nodes":[{"name":"JavaScript","color":"#f1e05a"},{"name":"Shell","color":"#89e051"},{"name":"Python","color":"#3572A5"},{"name":"HTML","color":"#e34c26"},{"name":"Vue","color":"#41b883"},{"name":"SCSS","color":"#c6538c"}]}},{"id":"R_kgDOHsmMPQ","name":"tf_test","description":null,"url":"https://github.com/ssoad/tf_test","updatedAt":"2024-04-07T07:20:39Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/43b303890a8b0c96b65fe1e82e03a4fa283e2e001db490308bfdddbeb71d5a89/ssoad/tf_test","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"JavaScript","color":"#f1e05a"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"},{"name":"Shell","color":"#89e051"},{"name":"JavaScript","color":"#f1e05a"},{"name":"CSS","color":"#563d7c"},{"name":"HTML","color":"#e34c26"},{"name":"PHP","color":"#4F5D95"}]}},{"id":"R_kgDOHlpUBQ","name":"django_transaction","description":null,"url":"https://github.com/ssoad/django_transaction","updatedAt":"2024-04-07T07:20:40Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/06140f448f2777835e534db4ce2a5c021c777a386941c838791d910538451f0c/ssoad/django_transaction","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"R_kgDOHk2zoA","name":"bdix_tester","description":null,"url":"https://github.com/ssoad/bdix_tester","updatedAt":"2024-04-07T07:20:41Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/7efb9b7190be798412b6235ad984a130c5edc807e11c1dfa2c260239e4d644d5/ssoad/bdix_tester","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"R_kgDOHVxQFw","name":"Lex-FLex","description":null,"url":"https://github.com/ssoad/Lex-FLex","updatedAt":"2024-04-07T07:20:32Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/a3fbdf91450fe60ee53d21a538653b65cbf5090966cec7d242499e179e40a901/ssoad/Lex-FLex","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"C","color":"#555555"},"languages":{"nodes":[{"name":"C","color":"#555555"},{"name":"Python","color":"#3572A5"},{"name":"Lex","color":"#DBCA00"}]}},{"id":"R_kgDOGuTllg","name":"Disease_gene_prioritization_GCN","description":"PGCN: Disease gene prioritization by disease and gene embedding through GCN","url":"https://github.com/ssoad/Disease_gene_prioritization_GCN","updatedAt":"2024-04-07T07:20:52Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/e409d680c6b503193da0a15344e004c67bd42ff7dc0985b723bfd121c02e6498/ssoad/Disease_gene_prioritization_GCN","stargazers":{"totalCount":0},"readme":{"text":"# PGCN: Disease gene prioritization by disease and gene embedding through GCN\nDisease gene prioritization is a fundamental step towards molecular diagnosis and treatment of diseases. This problem is highly challenging due to the very limited yet noisy knowledge of genes, diseases and, even more, on their associations. Despite the development of computational methods for disease gene prioritization, the performance of the existing methods is limited by manually-crafted features, network topology, or pre-defined rules of data fusion. Here we propose a novel graph convolutional network-based disease gene prioritization method, PGCN, through the systematic embedding of the heterogeneous network made by genes and diseases, as well as their individual features. The embedding learning model and the association prediction model are trained together in an end-to-end manner. We compared PGCN with five state-of-the-art methods on the Online Mendelian Inheritance in Man (OMIM) dataset, by challenging them on recovering missing associations, and on discovering associations for novel genes and/or diseases that are not seen in the training. Results show the significant improvements of PGCN over the existing methods. We further demonstrate that our embedding has biological meaning and can capture functional groups of genes.\n\nMore details can be referred to the [paper](https://www.biorxiv.org/content/10.1101/532226v1).\n\n```\n@article{li2019pgcn,\n  title={PGCN: Disease gene prioritization by disease and gene embedding through graph convolutional neural networks},\n  author={Li, Yu and Kuwahara, Hiroyuki and Yang, Peng and Song, Le and Gao, Xin},\n  journal={bioRxiv},\n  pages={532226},\n  year={2019},\n  publisher={Cold Spring Harbor Laboratory}\n}\n```\n\n## Overview\n<p align=\"center\">\n<img src=\"https://github.com/lykaust15/Disease_gene_prioritization_GCN/blob/master/figures/link_prediction.png\" width=\"400\"/>\n</p>\nDisease gene prioritization as a link prediction problem. The heterogeneous network contains three components, the gene-gene interaction network, the disease similarity network, and the disease-gene association network. The potential disease gene associations can be considered as missing links in the disease-gene association network. Our goal is to predict those links given the heterogeneous network and additional raw representations of the nodes (diseases and genes).\n\n<p align=\"center\">\n<img src=\"https://github.com/lykaust15/Disease_gene_prioritization_GCN/blob/master/figures/gcn.png\" width=\"800\"/>\n</p>\nOverview of the proposed method. (A) The input of our model contains two components, the heterogeneous network and the additional information for the nodes. As for the heterogeneous network, we used HumanNet as the gene network, disease similarity network as the disease network, and the associations from OMIM as the disease-gene network. For the additional information of diseases, we used Disease Ontology similarity and the TF-IDF calculated from OMIM. For the additional information of genes, we used association matrices from other species and the gene expression microarray data. (B) Examples of one layer of the graph convolutional neural network update for learning node embeddings. For each node, the model aggregates information from its neighbor nodes' previous layer embeddings and then apply activation to obtain the current layer embedding of that node. Note that for different nodes, the computational graphs can be different but the parameters are shared for the same operation in different computational graphs. (C) The link prediction model. We model the edge prediction from the learned node embeddings with bilinear edge decoder. (D) The cross-entropy loss calculated from the ground truth and the output of the link prediction model for certain edges (or non-edges) is used as the loss function to train both the node embedding model and the edge decoding model jointly in an end-to-end fashion.\n\n## Tested environment\n* Centos 7\n* Python 3.6.7\n\n## Install requirements\nAll the related packages have been summarized in *requirements.txt*. One can install all the packages with following command.\n```\npip install -r requirements.txt\n```\n\n(better to construct a virtual environment using conda and install the package inside the environment)\n\n## Download the data\nDue to the limit of the file size on Github, we store the data on Google Drive. Please download the data here: \n[data](https://drive.google.com/open?id=18yPVBjAvjtqLolno2RTAYt0Y_P-Hbdq7).\n\n## Run the code\nOne can run the code using the following command after configuring the environment and downloading the data.\n```\npython main_prioritization.py\n```\n\n## Result\nThe prediction matrix file can be downloaded here: [result](https://drive.google.com/open?id=1CDCrL9qmlirJUktnUULprUbDj9oUY0-W).\n\nHere is the embedding clustering result. For more explanation, please refer to the manuscript.\n<p align=\"center\">\n<img src=\"https://github.com/lykaust15/Disease_gene_prioritization_GCN/blob/master/figures/embedding.png\" width=\"400\"/>\n</p>\n\n## More explanation\nFor calculating BEDROC, here we provide the function from the skchem package for the reference. For more accurate calculation, one can output the prediction and use R packages to do the calculation.\n\n\n## Credits\nWe would like to thank for the SNAP group for open-sourcing the decagon code: [decagon](https://github.com/marinkaz/decagon).\n\n*This tool is for academic purposes and research use only. Any commercial use is subject for authorization from King Abdullah University of Science and technology â€œKAUSTâ€. Please contact us at ip@kaust.edu.sa.*"},"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"R_kgDOGpfbmw","name":"Study_Matrials_Spring_2021","description":null,"url":"https://github.com/ssoad/Study_Matrials_Spring_2021","updatedAt":"2024-04-07T07:20:49Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/8ab96d881656829364d8a4cfcb01d0dc3205a382d64dc1e40f4182d1d04ea46a/ssoad/Study_Matrials_Spring_2021","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Jupyter Notebook","color":"#DA5B0B"},"languages":{"nodes":[{"name":"Jupyter Notebook","color":"#DA5B0B"},{"name":"Python","color":"#3572A5"},{"name":"C","color":"#555555"},{"name":"Prolog","color":"#74283c"}]}},{"id":"R_kgDOGgy5aA","name":"BankManagement","description":null,"url":"https://github.com/ssoad/BankManagement","updatedAt":"2024-04-07T07:20:54Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/b85e6371e3e481fd66c62cac48dc92281ded2f0205970b1add77fe5b1cd48ab7/ssoad/BankManagement","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"PHP","color":"#4F5D95"},"languages":{"nodes":[{"name":"CSS","color":"#563d7c"},{"name":"PHP","color":"#4F5D95"},{"name":"Hack","color":"#878787"}]}},{"id":"R_kgDOGVv-Tw","name":"Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials","description":"A comprehensive list of Deep Learning / Artificial Intelligence and Machine Learning tutorials - rapidly expanding into areas of AI/Deep Learning / Machine Vision / NLP and industry specific areas such as Climate / Energy, Automotives, Retail, Pharma, Medicine, Healthcare, Policy, Ethics and more.","url":"https://github.com/ssoad/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials","updatedAt":"2024-04-07T07:21:03Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/27b7f7e65dad1eb13b19e6d233a7c4fdc785148854ba1ec1a7b7fa2ad743b652/ssoad/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials","stargazers":{"totalCount":0},"readme":{"text":"# NEW LIST 2020 - 2021: Machine-Learning / Deep-Learning / AI -Tutorials\n\nHi - Thanks for dropping by!<br>\n<br>\nI will be updating this tutorials site on a <b>daily basis</b> adding all relevant topcis, including latest researches papers from internet such as [arxiv.org](https://arxiv.org), [BIORXIV - Specifically Neuroscience](https://www.biorxiv.org/collection/neuroscience) to name a few. <br>\n<br>\nMore importantly the applications of ML/DL/AI into industry areas such as Transportation, Medicine/Healthcare etc. will be something I'll watch with keen interest and would love to share the same with you.\n<br>\nFinally, it is **YOUR** help I will seek to make it more useful and less boring, so please do suggest/comment/contribute!\n<p align=\"center\">\n  <img src=\"https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/AI.png\">\n</p>\n\n## Index\n\n* [deep-learning](#deep-learning)\n   * [UBER | Pyro](#uber-pyro-probabalistic-tutorials)\n   * [Netflix | VectorFlow](#netflix-vectorflow-tutorials)\n   * [PyTorch](#pytorch-tutorials)\n   * [tensorflow](#tensor-flow-tutorials)\n   * [theano](#theano-tutorials)\n   * [keras](#keras-tutorials)\n   * [caffe](#deep-learning-misc)\n   * [Torch/Lua]()\n   * [MXNET]()\n   \n* [scikit-learn](#scikit-learn)\n* [statistical-inference-scipy](#statistical-inference-scipy)\n* [pandas](#pandas)\n* [matplotlib](#matplotlib)\n* [numpy](#numpy)\n* [python-data](#python-data)\n* [kaggle-and-business-analyses](#kaggle-and-business-analyses)\n* [spark](#spark)\n* [mapreduce-python](#mapreduce-python)\n* [amazon web services](#aws)\n* [command lines](#commands)\n* [misc](#misc)\n* [notebook-installation](#notebook-installation)\n* [Curated list of Deep Learning / AI blogs](#curated-list-of-deeplearning-blogs)\n* [credits](#credits)\n* [contributing](#contributing)\n* [contact-info](#contact-info)\n* [license](#license)\n\n## deep-learning\n\nIPython Notebook(s) and other programming tools such as Torch/Lua/D lang in demonstrating deep learning functionality.\n\n### uber-pyro-probabalistic-tutorials\n<p align=\"center\">\n  <img src=\"https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/pyro.png\">\n</p>\n\nAdditional PyRo tutorials:\n\n* [pyro-examples/full examples](http://pyro.ai/examples/)\n* [pyro-examples/Variational Autoencoders](http://pyro.ai/examples/vae.html)\n* [pyro-examples/Bayesian Regression](http://pyro.ai/examples/bayesian_regression.html)\n* [pyro-examples/Deep Markov Model](http://pyro.ai/examples/dmm.html)\n* [pyro-examples/AIR(Attend Infer Repeat)](http://pyro.ai/examples/air.html)\n* [pyro-examples/Semi-Supervised VE](http://pyro.ai/examples/ss-vae.html)\n* [pyro-examples/GMM](http://pyro.ai/examples/gmm.html)\n* [pyro-examples/Gaussian Process](http://pyro.ai/examples/gp.html)\n* [pyro-examples/Bayesian Optimization](http://pyro.ai/examples/bo.html)\n* [Full Pyro Code](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/tree/master/deep-learning/UBER-pyro)\n\n\n\n### netflix-vectorflow-tutorials\n<p align=\"center\">\n  <img src=\"https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/VectorFlow.png\">\n</p>\n\n* [MNIST Example, running with Dlang](https://github.com/Netflix/vectorflow/tree/master/examples)\n\n### pytorch-tutorials\n<p align=\"center\">\n  <img src=\"https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/PyTorch.png\">\n</p>\n\n| Level | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [Beginners/Zakizhou](https://github.com/pytorch/tutorials/tree/master/beginner_source) | Learning the basics of PyTorch from Facebook. |\n| [Intermedia/Quanvuong](https://github.com/pytorch/tutorials/tree/master/intermediate_source) | Learning the intermediate stuff about PyTorch of from Facebook. |\n| [Advanced/Chsasank](https://github.com/pytorch/tutorials/tree/master/advanced_source) | Learning the advanced stuff about PyTorch of from Facebook. |\n| [Learning PyTorch by Examples - Numpy, Tensors and Autograd](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/tree/master/pytorch) | At its core, PyTorch provides two main features an n-dimensional Tensor, similar to numpy but can run on GPUs AND automatic differentiation for building and training neural networks. |\n| [PyTorch - Getting to know autograd.Variable, Gradient, Neural Network](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/pytorch/PyTorch%20NN%20Basics%20-%20Autograd%20Gradient%20Neural%20Network%20Loss%20Backprop.ipynb) | Here we start with ultimate basics of Tensors, wrap a Tensor with Variable module, play with nn.Module and implement forward and backward function. |\n\n\n### tensor-flow-tutorials\n<br/>\n<p align=\"center\">\n  <img src=\"https://avatars0.githubusercontent.com/u/15658638?v=3&s=100\">\n</p>\nAdditional TensorFlow tutorials:\n\n* [pkmital/tensorflow_tutorials](https://github.com/pkmital/tensorflow_tutorials)\n* [nlintz/TensorFlow-Tutorials](https://github.com/nlintz/TensorFlow-Tutorials)\n* [alrojo/tensorflow-tutorial](https://github.com/alrojo/tensorflow-tutorial)\n* [BinRoot/TensorFlow-Book](https://github.com/BinRoot/TensorFlow-Book)\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [tsf-basics](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/1_intro/basic_operations.ipynb) | Learn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google. |\n| [tsf-linear](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/linear_regression.ipynb) | Implement linear regression in TensorFlow. |\n| [tsf-logistic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/logistic_regression.ipynb) | Implement logistic regression in TensorFlow. |\n| [tsf-nn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/nearest_neighbor.ipynb) | Implement nearest neighboars in TensorFlow. |\n| [tsf-alex](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/alexnet.ipynb) | Implement AlexNet in TensorFlow. |\n| [tsf-cnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/convolutional_network.ipynb) | Implement convolutional neural networks in TensorFlow. |\n| [tsf-mlp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/multilayer_perceptron.ipynb) | Implement multilayer perceptrons in TensorFlow. |\n| [tsf-rnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/recurrent_network.ipynb) | Implement recurrent neural networks in TensorFlow. |\n| [tsf-gpu](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/4_multi_gpu/multigpu_basics.ipynb) | Learn about basic multi-GPU computation in TensorFlow. |\n| [tsf-gviz](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/graph_visualization.ipynb) | Learn about graph visualization in TensorFlow. |\n| [tsf-lviz](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/loss_visualization.ipynb) | Learn about loss visualization in TensorFlow. |\n\n### tensor-flow-exercises\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [tsf-not-mnist](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/1_notmnist.ipynb) | Learn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow. |\n| [tsf-fully-connected](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/2_fullyconnected.ipynb) | Progressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow. |\n| [tsf-regularization](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/3_regularization.ipynb) | Explore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow. |\n| [tsf-convolutions](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/4_convolutions.ipynb) | Create convolutional neural networks in TensorFlow. |\n| [tsf-word2vec](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/5_word2vec.ipynb) | Train a skip-gram model over Text8 data in TensorFlow. |\n| [tsf-lstm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/6_lstm.ipynb) | Train a LSTM character model over Text8 data in TensorFlow. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"http://www.deeplearning.net/software/theano/_static/theano_logo_allblue_200x46.png\">\n</p>\n\n### theano-tutorials\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [theano-intro](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/intro_theano/intro_theano.ipynb) | Intro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation. |\n| [theano-scan](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/scan_tutorial/scan_tutorial.ipynb) | Learn scans, a mechanism to perform loops in a Theano graph. |\n| [theano-logistic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/intro_theano/logistic_regression.ipynb) | Implement logistic regression in Theano. |\n| [theano-rnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/rnn_tutorial/simple_rnn.ipynb) | Implement recurrent neural networks in Theano. |\n| [theano-mlp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/theano_mlp/theano_mlp.ipynb) | Implement multilayer perceptrons in Theano. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/L45Q8c2.jpg\">\n</p>\n\n### keras-tutorials\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| keras | Keras is an open source neural network library written in Python. It is capable of running on top of either Tensorflow or Theano. |\n| [setup](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/README.md) | Learn about the tutorial goals and how to set up your Keras environment. |\n| [intro-deep-learning-ann](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1%20Introduction%20-%20Deep%20Learning%20and%20ANN.ipynb) | Get an intro to deep learning with Keras and Artificial Neural Networks (ANN). |\n| [Perceptrons and Adaline](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1.1%20Perceptron%20and%20Adaline.ipynb) | Implement Peceptron and adaptive linear neurons. |\n| [MLP and MNIST Data](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1.2%20MLP%20and%20MNIST.ipynb) | Classifying handwritten digits,implement MLP, train and debug ANN |\n| [theano](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.2%20Introduction%20-%20Theano.ipynb) | Learn about Theano by working with weights matrices and gradients. |\n| [keras-otto](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.3%20Introduction%20-%20Keras.ipynb) | Learn about Keras by looking at the Kaggle Otto challenge. |\n| [ann-mnist](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.4%20(Extra)%20A%20Simple%20Implementation%20of%20ANN%20for%20MNIST.ipynb) | Review a simple implementation of ANN for MNIST using Keras. |\n| [conv-nets](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.1%20Supervised%20Learning%20-%20ConvNets.ipynb) | Learn about Convolutional Neural Networks (CNNs) with Keras. |\n| [conv-net-1](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.2.1%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20I.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 1. |\n| [conv-net-2](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.2.2%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20II.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 2. |\n| [keras-models](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.3%20Supervised%20Learning%20-%20Famous%20Models%20with%20Keras.ipynb) | Use pre-trained models such as VGG16, VGG19, ResNet50, and Inception v3 with Keras. |\n| [auto-encoders](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/6.%20AutoEncoders%20and%20Embeddings/6.1.%20AutoEncoders%20and%20Embeddings.ipynb) | Learn about Autoencoders with Keras. |\n| [rnn-lstm](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/7.%20Recurrent%20Neural%20Networks/7.1%20RNN%20and%20LSTM.ipynb) | Learn about Recurrent Neural Networks (RNNs) with Keras. |\n| [lstm-sentence-gen](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/7.%20Recurrent%20Neural%20Networks/7.2%20LSTM%20for%20Sentence%20Generation.ipynb) |  Learn about RNNs using Long Short Term Memory (LSTM) networks with Keras. |\n| [nlp-deep-learning](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/6.%20AutoEncoders%20and%20Embeddings/6.2%20NLP%20and%20Deep%20Learning.ipynb) | Learn about NLP using ANN (Artificial Neural Networks. |\n| [hyperparamter-tuning](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/5.%20HyperParameter%20Tuning%20and%20Transfer%20Learning/5.1%20HyperParameter%20Tuning.ipynb) | Hyperparamters tuning using keras-wrapper.scikit-learn |\n\n### deep-learning-misc\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [deep-dream](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/deep-dream/dream.ipynb) | Caffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scikitlearn.png\">\n</p>\n\n## scikit-learn\n\nIPython Notebook(s) demonstrating scikit-learn functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [intro](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-intro.ipynb) | Intro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |\n| [knn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-intro.ipynb#K-Nearest-Neighbors-Classifier) | Implement k-nearest neighbors in scikit-learn. |\n| [linear-reg](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-linear-reg.ipynb) | Implement linear regression in scikit-learn. |\n| [svm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-svm.ipynb) | Implement support vector machine classifiers with and without kernels in scikit-learn. |\n| [random-forest](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-random-forest.ipynb) | Implement random forest classifiers and regressors in scikit-learn. |\n| [k-means](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-k-means.ipynb) | Implement k-means clustering in scikit-learn. |\n| [pca](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-pca.ipynb) | Implement principal component analysis in scikit-learn. |\n| [gmm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-gmm.ipynb) | Implement Gaussian mixture models in scikit-learn. |\n| [validation](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-validation.ipynb) | Implement validation and model selection in scikit-learn. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scipy.png\">\n</p>\n\n## statistical-inference-scipy\n\nIPython Notebook(s) demonstrating statistical inference with SciPy functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| scipy | SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. |\n| [effect-size](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/effect_size.ipynb) | Explore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States. |\n| [sampling](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/sampling.ipynb) | Explore random sampling by analyzing the average weight of men and women in the United States using BRFSS data. |\n| [hypothesis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/hypothesis.ipynb) | Explore hypothesis testing by analyzing the difference of first-born babies compared with others. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/pandas.png\">\n</p>\n\n## pandas\n\nIPython Notebook(s) demonstrating pandas functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [pandas](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/pandas.ipynb) | Software library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series. |\n| [github-data-wrangling](https://github.com/donnemartin/viz/blob/master/githubstats/data_wrangling.ipynb) | Learn how to load, clean, merge, and feature engineer by analyzing GitHub data from the [`Viz`](https://github.com/donnemartin/viz) repo. |\n| [Introduction-to-Pandas](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.00-Introduction-to-Pandas.ipynb) | Introduction to Pandas. |\n| [Introducing-Pandas-Objects](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.01-Introducing-Pandas-Objects.ipynb) | Learn about Pandas objects. |\n| [Data Indexing and Selection](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.02-Data-Indexing-and-Selection.ipynb) | Learn about data indexing and selection in Pandas. |\n| [Operations-in-Pandas](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.03-Operations-in-Pandas.ipynb) | Learn about operating on data in Pandas. |\n| [Missing-Values](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.04-Missing-Values.ipynb) | Learn about handling missing data in Pandas. |\n| [Hierarchical-Indexing](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.05-Hierarchical-Indexing.ipynb) | Learn about hierarchical indexing in Pandas. |\n| [Concat-And-Append](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.06-Concat-And-Append.ipynb) | Learn about combining datasets: concat and append in Pandas. |\n| [Merge-and-Join](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.07-Merge-and-Join.ipynb) | Learn about combining datasets: merge and join in Pandas. |\n| [Aggregation-and-Grouping](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.08-Aggregation-and-Grouping.ipynb) | Learn about aggregation and grouping in Pandas. |\n| [Pivot-Tables](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.09-Pivot-Tables.ipynb) | Learn about pivot tables in Pandas. |\n| [Working-With-Strings](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.10-Working-With-Strings.ipynb) | Learn about vectorized string operations in Pandas. |\n| [Working-with-Time-Series](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.11-Working-with-Time-Series.ipynb) | Learn about working with time series in pandas. |\n| [Performance-Eval-and-Query](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.12-Performance-Eval-and-Query.ipynb) | Learn about high-performance Pandas: eval() and query() in Pandas. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/matplotlib.png\">\n</p>\n\n## matplotlib\n\nIPython Notebook(s) demonstrating matplotlib functionality.\n\n| Notebook | Description |\n|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [matplotlib](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/matplotlib.ipynb) | Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. |\n| [matplotlib-applied](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/matplotlib-applied.ipynb) | Apply matplotlib visualizations to Kaggle competitions for exploratory data analysis.  Learn how to create bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots. |\n| [Introduction-To-Matplotlib](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.00-Introduction-To-Matplotlib.ipynb) | Introduction to Matplotlib. |\n| [Simple-Line-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.01-Simple-Line-Plots.ipynb) | Learn about simple line plots in Matplotlib. |\n| [Simple-Scatter-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.02-Simple-Scatter-Plots.ipynb) | Learn about simple scatter plots in Matplotlib. |\n| [Errorbars.ipynb](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.03-Errorbars.ipynb) | Learn about visualizing errors in Matplotlib. |\n| [Density-and-Contour-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.04-Density-and-Contour-Plots.ipynb) | Learn about density and contour plots in Matplotlib. |\n| [Histograms-and-Binnings](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.05-Histograms-and-Binnings.ipynb) | Learn about histograms, binnings, and density in Matplotlib. |\n| [Customizing-Legends](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.06-Customizing-Legends.ipynb) | Learn about customizing plot legends in Matplotlib. |\n| [Customizing-Colorbars](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.07-Customizing-Colorbars.ipynb) | Learn about customizing colorbars in Matplotlib. |\n| [Multiple-Subplots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.08-Multiple-Subplots.ipynb) | Learn about multiple subplots in Matplotlib. |\n| [Text-and-Annotation](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.09-Text-and-Annotation.ipynb) | Learn about text and annotation in Matplotlib. |\n| [Customizing-Ticks](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.10-Customizing-Ticks.ipynb) | Learn about customizing ticks in Matplotlib. |\n| [Settings-and-Stylesheets](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.11-Settings-and-Stylesheets.ipynb) | Learn about customizing Matplotlib: configurations and stylesheets. |\n| [Three-Dimensional-Plotting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.12-Three-Dimensional-Plotting.ipynb) | Learn about three-dimensional plotting in Matplotlib. |\n| [Geographic-Data-With-Basemap](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.13-Geographic-Data-With-Basemap.ipynb) | Learn about geographic data with basemap in Matplotlib. |\n| [Visualization-With-Seaborn](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.14-Visualization-With-Seaborn.ipynb) | Learn about visualization with Seaborn. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png\">\n</p>\n\n## numpy\n\nIPython Notebook(s) demonstrating NumPy functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [numpy](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/numpy.ipynb) | Adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |\n| [Introduction-to-NumPy](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.00-Introduction-to-NumPy.ipynb) | Introduction to NumPy. |\n| [Understanding-Data-Types](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.01-Understanding-Data-Types.ipynb) | Learn about data types in Python. |\n| [The-Basics-Of-NumPy-Arrays](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.02-The-Basics-Of-NumPy-Arrays.ipynb) | Learn about the basics of NumPy arrays. |\n| [Computation-on-arrays-ufuncs](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.03-Computation-on-arrays-ufuncs.ipynb) | Learn about computations on NumPy arrays: universal functions. |\n| [Computation-on-arrays-aggregates](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.04-Computation-on-arrays-aggregates.ipynb) | Learn about aggregations: min, max, and everything in between in NumPy. |\n| [Computation-on-arrays-broadcasting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.05-Computation-on-arrays-broadcasting.ipynb) | Learn about computation on arrays: broadcasting in NumPy. |\n| [Boolean-Arrays-and-Masks](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.06-Boolean-Arrays-and-Masks.ipynb) | Learn about comparisons, masks, and boolean logic in NumPy. |\n| [Fancy-Indexing](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.07-Fancy-Indexing.ipynb) | Learn about fancy indexing in NumPy. |\n| [Sorting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.08-Sorting.ipynb) | Learn about sorting arrays in NumPy. |\n| [Structured-Data-NumPy](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.09-Structured-Data-NumPy.ipynb) | Learn about structured data: NumPy's structured arrays. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/python.png\">\n</p>\n\n## python-data\n\nIPython Notebook(s) demonstrating Python functionality geared towards data analysis.\n\n| Notebook | Description |\n|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n| [data structures](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/structs.ipynb) | Learn Python basics with tuples, lists, dicts, sets. |\n| [data structure utilities](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/structs_utils.ipynb) | Learn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions. |\n| [functions](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/functions.ipynb) | Learn about more advanced Python features: Functions as objects, lambda functions, closures, *args, **kwargs currying, generators, generator expressions, itertools. |\n| [datetime](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/datetime.ipynb) | Learn how to work with Python dates and times: datetime, strftime, strptime, timedelta. |\n| [logging](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/logs.ipynb) | Learn about Python logging with RotatingFileHandler and TimedRotatingFileHandler. |\n| [pdb](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/pdb.ipynb) | Learn how to debug in Python with the interactive source code debugger. |\n| [unit tests](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/unit_tests.ipynb) | Learn how to test in Python with Nose unit tests. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/kaggle.png\">\n</p>\n\n## kaggle-and-business-analyses\n\nIPython Notebook(s) used in [kaggle](https://www.kaggle.com/) competitions and business analyses.\n\n| Notebook | Description |\n|-------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|\n| [titanic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/kaggle/titanic.ipynb) | Predict survival on the Titanic.  Learn data cleaning, exploratory data analysis, and machine learning. |\n| [churn-analysis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/analyses/churn.ipynb) | Predict customer churn.  Exercise logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Includes discussions of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.|\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/spark.png\">\n</p>\n\n## spark\n\nIPython Notebook(s) demonstrating spark and HDFS functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| [spark](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/spark/spark.ipynb) | In-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms. |\n| [hdfs](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/spark/hdfs.ipynb) | Reliably stores very large files across machines in a large cluster. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/mrjob.png\">\n</p>\n\n## mapreduce-python\n\nIPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| [mapreduce-python](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/mapreduce/mapreduce-python.ipynb) | Runs MapReduce jobs in Python, executing jobs locally or on Hadoop clusters. Demonstrates Hadoop Streaming in Python code with unit test and [mrjob](https://github.com/Yelp/mrjob) config file to analyze Amazon S3 bucket logs on Elastic MapReduce.  [Disco](https://github.com/discoproject/disco/) is another python-based alternative.|\n\n<br/>\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/aws.png\">\n</p>\n\n## aws\n\nIPython Notebook(s) demonstrating Amazon Web Services (AWS) and AWS tools functionality.\n\n\nAlso check out:\n\n* [SAWS](https://github.com/donnemartin/saws): A Supercharged AWS command line interface (CLI).\n* [Awesome AWS](https://github.com/donnemartin/awesome-aws): A curated list of libraries, open source repos, guides, blogs, and other resources.\n\n| Notebook | Description |\n|------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [boto](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#Boto) | Official AWS SDK for Python. |\n| [s3cmd](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3cmd) | Interacts with S3 through the command line. |\n| [s3distcp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3distcp) | Combines smaller files and aggregates them together by taking in a pattern and target file.  S3DistCp can also be used to transfer large volumes of data from S3 to your Hadoop cluster. |\n| [s3-parallel-put](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3-parallel-put) | Uploads multiple files to S3 in parallel. |\n| [redshift](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#redshift) | Acts as a fast data warehouse built on top of technology from massive parallel processing (MPP). |\n| [kinesis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#kinesis) | Streams data in real time with the ability to process thousands of data streams per second. |\n| [lambda](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#lambda) | Runs code in response to events, automatically managing compute resources. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/commands.png\">\n</p>\n\n## commands\n\nIPython Notebook(s) demonstrating various command lines for Linux, Git, etc.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [linux](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/linux.ipynb) | Unix-like and mostly POSIX-compliant computer operating system.  Disk usage, splitting files, grep, sed, curl, viewing running processes, terminal syntax highlighting, and Vim.|\n| [anaconda](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#anaconda) | Distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing, that aims to simplify package management and deployment. |\n| [ipython notebook](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#ipython-notebook) | Web-based interactive computational environment where you can combine code execution, text, mathematics, plots and rich media into a single document. |\n| [git](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#git) | Distributed revision control system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows. |\n| [ruby](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#ruby) | Used to interact with the AWS command line and for Jekyll, a blog framework that can be hosted on GitHub Pages. |\n| [jekyll](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#jekyll) | Simple, blog-aware, static site generator for personal, project, or organization sites.  Renders Markdown or Textile and Liquid templates, and produces a complete, static website ready to be served by Apache HTTP Server, Nginx or another web server. |\n| [pelican](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#pelican) | Python-based alternative to Jekyll. |\n| [django](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#django) | High-level Python Web framework that encourages rapid development and clean, pragmatic design. It can be useful to share reports/analyses and for blogging. Lighter-weight alternatives include [Pyramid](https://github.com/Pylons/pyramid), [Flask](https://github.com/pallets/flask), [Tornado](https://github.com/tornadoweb/tornado), and [Bottle](https://github.com/bottlepy/bottle).\n\n## misc\n\nIPython Notebook(s) demonstrating miscellaneous functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [regex](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/misc/regex.ipynb) | Regular expression cheat sheet useful in data wrangling.|\n[algorithmia](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/misc/Algorithmia.ipynb) | Algorithmia is a marketplace for algorithms. This notebook showcases 4 different algorithms: Face Detection, Content Summarizer, Latent Dirichlet Allocation and Optical Character Recognition.|\n\n## notebook-installation\n\n### anaconda\n\nAnaconda is a free distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing that aims to simplify package management and deployment.\n\nFollow instructions to install [Anaconda](https://docs.continuum.io/anaconda/install) or the more lightweight [miniconda](http://conda.pydata.org/miniconda.html).\n\n### dev-setup\n\nFor detailed instructions, scripts, and tools to set up your development environment for data analysis, check out the [dev-setup](https://github.com/donnemartin/dev-setup) repo.\n\n### running-notebooks\n\nNote: If you intend to learn the hard way (preferred method)then I'd strongly advice to write as much code as you can yourself and not just run pre-written code. If you still want to test it, then do the following: \n\nTo view interactive content or to modify elements within the IPython notebooks, you must first clone or download the repository then run the notebook.  More information on IPython Notebooks can be found [here.](http://ipython.org/notebook.html)\n\n    $ git clone https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials.git\n    $ cd Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials\n    $ jupyter notebook\n    \n\nNotebooks tested with Python 3.7+\n\n## curated-list-of-deeplearning-blogs\n\n* A Blog From a Human-engineer-being http://www.erogol.com/ [(RSS)](http://www.erogol.com/feed/)\n* Aakash Japi http://aakashjapi.com/ [(RSS)](http://logicx24.github.io/feed.xml)\n* Adit Deshpande https://adeshpande3.github.io/ [(RSS)](https://adeshpande3.github.io/adeshpande3.github.io/feed.xml)\n* Advanced Analytics & R http://advanceddataanalytics.net/ [(RSS)](http://advanceddataanalytics.net/feed/)\n* Adventures in Data Land http://blog.smola.org [(RSS)](http://blog.smola.org/rss)\n* Agile Data Science http://blog.sense.io/ [(RSS)](http://blog.sense.io/rss/)\n* Ahmed El Deeb https://medium.com/@D33B [(RSS)](https://medium.com/feed/@D33B)\n* Airbnb Data blog http://nerds.airbnb.com/data/ [(RSS)](http://nerds.airbnb.com/feed/)\n* Alex Castrounis | InnoArchiTech http://www.innoarchitech.com/ [(RSS)](http://www.innoarchitech.com/feed.xml)\n* Alex Perrier http://alexperrier.github.io/ [(RSS)](http://alexperrier.github.io/feed.xml)\n* Algobeans | Data Analytics Tutorials & Experiments for the Layman https://algobeans.com [(RSS)](https://algobeans.com/feed/)\n* Amazon AWS AI Blog https://aws.amazon.com/blogs/ai/ [(RSS)](https://aws.amazon.com/blogs/amazon-ai/feed/)\n* Analytics Vidhya http://www.analyticsvidhya.com/blog/ [(RSS)](http://feeds.feedburner.com/AnalyticsVidhya)\n* Analytics and Visualization in Big Data @ Sicara https://blog.sicara.com [(RSS)](https://blog.sicara.com/feed)\n* Andreas MÃ¼ller http://peekaboo-vision.blogspot.com/ [(RSS)](http://peekaboo-vision.blogspot.com/atom.xml)\n* Andrej Karpathy blog http://karpathy.github.io/ [(RSS)](http://karpathy.github.io/feed.xml)\n* Andrew Brooks http://brooksandrew.github.io/simpleblog/ [(RSS)](http://brooksandrew.github.io/simpleblog/feed.xml)\n* Andrey Kurenkov http://www.andreykurenkov.com/writing/ [(RSS)](http://www.andreykurenkov.com/writing/feed.xml/)\n* Anton Lebedevich's Blog http://mabrek.github.io/ [(RSS)](http://mabrek.github.io/feed.xml)\n* Arthur Juliani https://medium.com/@awjuliani [(RSS)](https://medium.com/feed/@awjuliani)\n* Audun M. Ã˜ygard http://www.auduno.com/ [(RSS)](http://auduno.tumblr.com/rss)\n* Avi Singh https://avisingh599.github.io/ [(RSS)](http://avisingh599.github.io/feed.xml)\n* Beautiful Data http://beautifuldata.net/ [(RSS)](http://beautifuldata.net/feed/)\n* Beckerfuffle http://mdbecker.github.io/ [(RSS)](http://mdbecker.github.io/atom.xml)\n* Becoming A Data Scientist http://www.becomingadatascientist.com/ [(RSS)](http://www.becomingadatascientist.com/feed/)\n* Ben Bolte's Blog http://benjaminbolte.com/ml/ [(RSS)](http://benjaminbolte.com/ml/)\n* Ben Frederickson http://www.benfrederickson.com/blog/ [(RSS)](http://www.benfrederickson.com/atom.xml)\n* Berkeley AI Research http://bair.berkeley.edu/blog/ [(RSS)](http://bair.berkeley.edu/blog/feed.xml)\n* Big-Ish Data http://bigishdata.com/ [(RSS)](http://bigishdata.com/feed/)\n* Blog on neural networks http://yerevann.github.io/ [(RSS)](http://yerevann.github.io/atom.xml)\n* Blogistic RegressionAbout Projects http://d10genes.github.io/blog/ [(RSS)](http://d10genes.github.io/blog/feed.xml)\n* blogR | R tips and tricks from a scientist https://drsimonj.svbtle.com/ [(RSS)](https://drsimonj.svbtle.com/)\n* Brain of mat kelcey http://matpalm.com/blog/ [(RSS)](http://matpalm.com/blog/feed)\n* Brilliantly wrong thoughts on science and programming https://arogozhnikov.github.io/ [(RSS)](http://arogozhnikov.github.io/feed.xml)\n* Bugra Akyildiz http://bugra.github.io/ [(RSS)](http://bugra.github.io/feeds/all.atom.xml)\n* Building Babylon https://building-babylon.net/ [(RSS)](http://building-babylon.net/feed/)\n* Carl Shan http://carlshan.com/ [(RSS)](http://feeds.feedburner.com/carlshan)\n* Chris Stucchio https://www.chrisstucchio.com/blog/index.html [(RSS)](http://www.chrisstucchio.com/blog/atom.xml)\n* Christophe Bourguignat https://medium.com/@chris_bour [(RSS)](https://medium.com/feed/@chris_bour)\n* Christopher Nguyen https://medium.com/@ctn [(RSS)](https://medium.com/feed/@ctn)\n* Cloudera Data Science Posts http://blog.cloudera.com/blog/category/data-science/ [(RSS)](http://blog.cloudera.com/blog/category/data-science/feed/)\n* colah's blog http://colah.github.io/archive.html [(RSS)](http://colah.github.io/rss.xml)\n* Cortana Intelligence and Machine Learning Blog https://blogs.technet.microsoft.com/machinelearning/ [(RSS)](http://blogs.technet.com/b/machinelearning/rss.aspx)\n* Daniel Forsyth http://www.danielforsyth.me/ [(RSS)](http://www.danielforsyth.me/rss/)\n* Daniel Homola http://danielhomola.com/category/blog/ [(RSS)](http://danielhomola.com/feed/)\n* Daniel Nee http://danielnee.com [(RSS)](http://danielnee.com/?feed=rss2)\n* Data Based Inventions http://datalab.lu/ [(RSS)](http://datalab.lu/atom.xml)\n* Data Blogger https://www.data-blogger.com/ [(RSS)](https://www.data-blogger.com/feed/)\n* Data Labs http://blog.insightdatalabs.com/ [(RSS)](http://blog.insightdatalabs.com/rss/)\n* Data Meets Media http://datameetsmedia.com/ [(RSS)](http://datameetsmedia.com/feed/)\n* Data Miners Blog http://blog.data-miners.com/ [(RSS)](http://blog.data-miners.com/feeds/posts/default?alt=rss)\n* Data Mining Research http://www.dataminingblog.com/ [(RSS)](http://feeds.feedburner.com/dataminingblog)\n* Data Mining: Text Mining, Visualization and Social Media http://datamining.typepad.com/data_mining/ [(RSS)](http://datamining.typepad.com/data_mining/atom.xml)\n* Data Piques http://blog.ethanrosenthal.com/ [(RSS)](http://blog.ethanrosenthal.com/feeds/all.atom.xml)\n* Data School http://www.dataschool.io/ [(RSS)](http://www.dataschool.io/rss/)\n* Data Science 101 http://101.datascience.community/ [(RSS)](http://101.datascience.community/feed/)\n* Data Science @ Facebook https://research.facebook.com/blog/datascience/ [(RSS)](https://research.facebook.com/blog/datascience/)\n* Data Science Insights http://www.datasciencebowl.com/data-science-insights/ [(RSS)](http://www.datasciencebowl.com/feed/)\n* Data Science Tutorials https://codementor.io/data-science/tutorial [(RSS)](https://www.codementor.io/data-science/tutorial/feed)\n* Data Science Vademecum http://datasciencevademecum.wordpress.com/ [(RSS)](http://datasciencevademecum.wordpress.com/feed/)\n* Dataaspirant http://dataaspirant.com/ [(RSS)](http://dataaspirant.wordpress.com/feed/)\n* Dataclysm http://blog.okcupid.com/ [(RSS)](http://blog.okcupid.com/index.php/feed/)\n* DataGenetics http://datagenetics.com/blog.html [(RSS)](http://datagenetics.com/feed/rss.xml)\n* Dataiku https://www.dataiku.com/blog/ [(RSS)](http://www.dataiku.com/feed.xml)\n* DataKind http://www.datakind.org/blog [(RSS)](http://feeds.feedburner.com/DataKin)\n* DataLook http://blog.datalook.io/ [(RSS)](http://blog.datalook.io/feed/)\n* Datanice https://datanice.wordpress.com/ [(RSS)](https://datanice.wordpress.com/feed/)\n* Dataquest Blog https://www.dataquest.io/blog/ [(RSS)](https://www.dataquest.io/blog/atom.xml)\n* DataRobot http://www.datarobot.com/blog/ [(RSS)](http://www.datarobot.com/feed/)\n* Datascope http://datascopeanalytics.com/blog [(RSS)](http://datascopeanalytics.com/rss)\n* DatasFrame http://tomaugspurger.github.io/ [(RSS)](http://tomaugspurger.github.io/feeds/all.rss.xml)\n* David Mimno http://www.mimno.org/ [(RSS)](http://mimno.infosci.cornell.edu/b/feed.xml)\n* Dayne Batten http://daynebatten.com [(RSS)](http://daynebatten.com/feed/)\n* Deep Learning http://deeplearning.net/blog/ [(RSS)](http://deeplearning.net/feed/)\n* Deepdish http://deepdish.io/ [(RSS)](http://deepdish.io/atom.xml)\n* Delip Rao http://deliprao.com/ [(RSS)](http://deliprao.com/feed)\n* DENNY'S BLOG http://blog.dennybritz.com/ [(RSS)](http://blog.dennybritz.com/feed/)\n* Dimensionless https://dimensionless.in/blog/ [(RSS)](https://dimensionless.in/feed)\n* Distill http://distill.pub/ [(RSS)](http://distill.pub/rss.xml)\n* District Data Labs http://districtdatalabs.silvrback.com/ [(RSS)](https://districtdatalabs.silvrback.com/feed)\n* Diving into data https://blog.datadive.net/ [(RSS)](http://blog.datadive.net/feed/)\n* Domino Data Lab's blog http://blog.dominodatalab.com/ [(RSS)](http://blog.dominodatalab.com/rss/)\n* Dr. Randal S. Olson http://www.randalolson.com/blog/ [(RSS)](http://www.randalolson.com/feed/)\n* Drew Conway https://medium.com/@drewconway [(RSS)](https://medium.com/feed/@drewconway)\n* Dustin Tran http://dustintran.com/blog/ [(RSS)](http://dustintran.com/blog/rss/)\n* Eder Santana https://edersantana.github.io/blog.html [(RSS)](http://edersantana.github.io/feed.xml)\n* Edwin Chen http://blog.echen.me [(RSS)](http://blog.echen.me/feeds/all.rss.xml)\n* EFavDB http://efavdb.com/ [(RSS)](http://efavdb.com/feed/)\n* Emilio Ferrara, Ph.D.  http://www.emilio.ferrara.name/ [(RSS)](http://www.emilio.ferrara.name/feed/)\n* Entrepreneurial Geekiness http://ianozsvald.com/ [(RSS)](http://ianozsvald.com/feed/)\n* Eric Jonas http://ericjonas.com/archives.html [(RSS)](http://ericjonas.com/archives.html)\n* Eric Siegel http://www.predictiveanalyticsworld.com/blog [(RSS)](http://feeds.feedburner.com/predictiveanalyticsworld/GXRy)\n* Erik Bern http://erikbern.com [(RSS)](http://erikbern.com/feed/)\n* ERIN SHELLMAN http://www.erinshellman.com/ [(RSS)](http://www.erinshellman.com/feed/)\n* Eugenio Culurciello http://culurciello.github.io/ [(RSS)](http://culurciello.github.io/feed.xml)\n* Fabian Pedregosa http://fa.bianp.net/ [(RSS)](http://fa.bianp.net/blog/feed/)\n* Fast Forward Labs http://blog.fastforwardlabs.com/ [(RSS)](http://blog.fastforwardlabs.com/rss)\n* FastML http://fastml.com/ [(RSS)](http://fastml.com/atom.xml)\n* Florian Hartl http://florianhartl.com/ [(RSS)](http://florianhartl.com/feed/)\n* FlowingData http://flowingdata.com/ [(RSS)](http://flowingdata.com/feed/)\n* Full Stack ML http://fullstackml.com/ [(RSS)](http://fullstackml.com/feed/)\n* GAB41 http://www.lab41.org/gab41/ [(RSS)](http://www.lab41.org/feed/)\n* Garbled Notes http://www.chioka.in/ [(RSS)](http://www.chioka.in/feed.xml)\n* Greg Reda http://www.gregreda.com/blog/ [(RSS)](http://www.gregreda.com/feeds/all.atom.xml)\n* Hyon S Chu https://medium.com/@adailyventure [(RSS)](https://medium.com/feed/@adailyventure)\n* i am trask http://iamtrask.github.io/ [(RSS)](http://iamtrask.github.io/feed.xml)\n* I Quant NY http://iquantny.tumblr.com/ [(RSS)](http://iquantny.tumblr.com/rss)\n* inFERENCe http://www.inference.vc/ [(RSS)](http://www.inference.vc/rss/)\n* Insight Data Science https://blog.insightdatascience.com/ [(RSS)](https://blog.insightdatascience.com/feed)\n* INSPIRATION INFORMATION http://myinspirationinformation.com/ [(RSS)](http://myinspirationinformation.com/feed/)\n* Ira Korshunova http://irakorshunova.github.io/ [(RSS)](http://irakorshunova.github.io/feed.xml)\n* Iâ€™m a bandit https://blogs.princeton.edu/imabandit/ [(RSS)](https://blogs.princeton.edu/imabandit/feed/)\n* Jason Toy http://www.jtoy.net/ [(RSS)](http://jtoy.net/atom.xml)\n* Jeremy D. Jackson, PhD http://www.jeremydjacksonphd.com/ [(RSS)](http://www.jeremydjacksonphd.com/?feed=rss2)\n* Jesse Steinweg-Woods https://jessesw.com/ [(RSS)](https://jessesw.com/feed.xml)\n* Joe Cauteruccio http://www.joecjr.com/ [(RSS)](http://www.joecjr.com/feed/)\n* John Myles White http://www.johnmyleswhite.com/ [(RSS)](http://www.johnmyleswhite.com/feed/)\n* John's Soapbox http://joschu.github.io/ [(RSS)](http://joschu.github.io/feed.xml)\n* Jonas Degrave http://317070.github.io/ [(RSS)](http://317070.github.io/feed.xml)\n* Joy Of Data http://www.joyofdata.de/blog/ [(RSS)](http://www.joyofdata.de/blog/feed/)\n* Julia Evans http://jvns.ca/ [(RSS)](http://jvns.ca/atom.xml)\n* KDnuggets http://www.kdnuggets.com/ [(RSS)](http://feeds.feedburner.com/kdnuggets-data-mining-analytics)\n* Keeping Up With The Latest Techniques http://colinpriest.com/ [(RSS)](http://colinpriest.com/feed/)\n* Kenny Bastani http://www.kennybastani.com/ [(RSS)](http://www.kennybastani.com/feeds/posts/default?alt=rss)\n* Kevin Davenport http://kldavenport.com/ [(RSS)](http://kldavenport.com/feed/)\n* kevin frans http://kvfrans.com/ [(RSS)](http://kvfrans.com/rss/)\n* korbonits | Math âˆ© Data http://korbonits.github.io/ [(RSS)](http://korbonits.github.io/feed.xml)\n* Large Scale Machine Learning  http://bickson.blogspot.com/ [(RSS)](http://bickson.blogspot.com/feeds/posts/default)\n* LATERAL BLOG https://blog.lateral.io/ [(RSS)](https://blog.lateral.io/feed/)\n* Lazy Programmer http://lazyprogrammer.me/ [(RSS)](http://lazyprogrammer.me/feed/)\n* Learn Analytics Here https://learnanalyticshere.wordpress.com/ [(RSS)](https://learnanalyticshere.wordpress.com/feed/)\n* LearnDataSci http://www.learndatasci.com/ [(RSS)](http://www.learndatasci.com/feed/)\n* Learning With Data http://learningwithdata.com/ [(RSS)](http://learningwithdata.com/rss_feed.xml)\n* Life, Language, Learning http://daoudclarke.github.io/ [(RSS)](http://daoudclarke.github.io/atom.xml)\n* Locke Data https://itsalocke.com/blog/ [(RSS)](https://itsalocke.com/feed)\n* Louis Dorard http://www.louisdorard.com/blog/ [(RSS)](http://www.louisdorard.com/blog?format=rss)\n* M.E.Driscoll http://medriscoll.com/ [(RSS)](http://medriscoll.com/rss)\n* Machinalis http://www.machinalis.com/blog [(RSS)](http://www.machinalis.com/blog/feeds/rss/)\n* Machine Learning (Theory) http://hunch.net/ [(RSS)](http://hunch.net/?feed=rss2)\n* Machine Learning and Data Science http://alexhwoods.com/blog/ [(RSS)](http://alexhwoods.com/feed/)\n* Machine Learning https://charlesmartin14.wordpress.com/ [(RSS)](http://charlesmartin14.wordpress.com/feed/)\n* Machine Learning Mastery http://machinelearningmastery.com/blog/ [(RSS)](http://machinelearningmastery.com/feed/)\n* Machine Learning Blogs https://machinelearningblogs.com/ [(RSS)](https://machinelearningblogs.com/feed/)\n* Machine Learning, etc http://yaroslavvb.blogspot.com [(RSS)](http://yaroslavvb.blogspot.com/feeds/posts/default)\n* Machine Learning, Maths and Physics https://mlopezm.wordpress.com/ [(RSS)](https://mlopezm.wordpress.com/feed/)\n* Machine Learning Flashcards https://machinelearningflashcards.com/ $10, but a nicely illustrated set of 300 flash cards\n* Machined Learnings http://www.machinedlearnings.com/ [(RSS)](http://www.machinedlearnings.com/feeds/posts/default)\n* MAPPING BABEL https://jack-clark.net/ [(RSS)](https://jack-clark.net/feed/)\n* MAPR Blog https://www.mapr.com/blog [(RSS)](https://www.mapr.com/bigdata.xml)\n* MAREK REI http://www.marekrei.com/blog/ [(RSS)](http://www.marekrei.com/blog/feed/)\n* MARGINALLY INTERESTING http://blog.mikiobraun.de/ [(RSS)](http://feeds.feedburner.com/MarginallyInteresting)\n* Math âˆ© Programming http://jeremykun.com/ [(RSS)](http://jeremykun.wordpress.com/feed/)\n* Matthew Rocklin http://matthewrocklin.com/blog/ [(RSS)](http://matthewrocklin.com/blog/atom.xml)\n* Melody Wolk http://melodywolk.com/projects/ [(RSS)](http://melodywolk.com/feed/)\n* Mic Farris http://www.micfarris.com/ [(RSS)](http://www.micfarris.com/feed/)\n* Mike Tyka http://mtyka.github.io/ [(RSS)](http://mtyka.github.io//feed.xml)\n* minimaxir | Max Woolf's Blog http://minimaxir.com/ [(RSS)](http://minimaxir.com/rss.xml)\n* Mirror Image https://mirror2image.wordpress.com/ [(RSS)](http://mirror2image.wordpress.com/feed/)\n* Mitch Crowe http://www.dataphoric.com/ [(RSS)](http://www.dataphoric.com/feed.xml)\n* MLWave http://mlwave.com/ [(RSS)](http://mlwave.com/feed/)\n* MLWhiz http://mlwhiz.com/ [(RSS)](http://mlwhiz.com/atom.xml)\n* Models are illuminating and wrong https://peadarcoyle.wordpress.com/ [(RSS)](http://peadarcoyle.wordpress.com/feed/)\n* Moody Rd http://blog.mrtz.org/ [(RSS)](http://blog.mrtz.org/feed.xml)\n* Moonshots http://jxieeducation.com/ [(RSS)](http://jxieeducation.com/feed.xml)\n* Mourad Mourafiq http://mourafiq.com/ [(RSS)](http://mourafiq.com/atom.xml)\n* My thoughts on Data science, predictive analytics, Python http://shahramabyari.com/ [(RSS)](http://shahramabyari.com/feed/)\n* Natural language processing blog http://nlpers.blogspot.fr/ [(RSS)](http://nlpers.blogspot.com/feeds/posts/default)\n* Neil Lawrence http://inverseprobability.com/blog.html [(RSS)](http://inverseprobability.com/rss.xml)\n* NLP and Deep Learning enthusiast http://camron.xyz/ [(RSS)](http://camron.xyz/index.php/feed/)\n* no free hunch http://blog.kaggle.com/ [(RSS)](http://blog.kaggle.com/feed/)\n* Nuit Blanche http://nuit-blanche.blogspot.com/ [(RSS)](http://nuit-blanche.blogspot.com/feeds/posts/default)\n* Number 2147483647 https://no2147483647.wordpress.com/ [(RSS)](http://no2147483647.wordpress.com/feed/)\n* On Machine Intelligence https://aimatters.wordpress.com/ [(RSS)](https://aimatters.wordpress.com/feed/)\n* Opiate for the masses Data is our religion. http://opiateforthemass.es/ [(RSS)](http://opiateforthemass.es/feed.xml)\n* p-value.info http://www.p-value.info/ [(RSS)](http://www.p-value.info/feeds/posts/default)\n* Pete Warden's blog http://petewarden.com/ [(RSS)](http://feeds.feedburner.com/typepad/petewarden)\n* Plotly Blog http://blog.plot.ly/ [(RSS)](http://blog.plot.ly/rss)\n* Probably Overthinking It http://allendowney.blogspot.ca/ [(RSS)](http://allendowney.blogspot.com/feeds/posts/default)\n* Prooffreader.com http://www.prooffreader.com [(RSS)](http://www.prooffreader.com/feeds/posts/default)\n* ProoffreaderPlus http://prooffreaderplus.blogspot.ca/ [(RSS)](http://prooffreaderplus.blogspot.ca/feeds/posts/default)\n* Publishable Stuff http://www.sumsar.net/ [(RSS)](http://www.sumsar.net/atom.xml)\n* PyImageSearch http://www.pyimagesearch.com/ [(RSS)](http://feeds.feedburner.com/Pyimagesearch)\n* Pythonic Perambulations https://jakevdp.github.io/ [(RSS)](http://jakevdp.github.com/atom.xml)\n* quintuitive http://quintuitive.com/ [(RSS)](http://quintuitive.com/feed/)\n* R and Data Mining https://rdatamining.wordpress.com/ [(RSS)](http://rdatamining.wordpress.com/feed/)\n* R-bloggers http://www.r-bloggers.com/ [(RSS)](http://feeds.feedburner.com/RBloggers)\n* R2RT http://r2rt.com/ [(RSS)](http://r2rt.com/feeds/all.atom.xml)\n* Ramiro GÃ³mez http://ramiro.org/notebooks/ [(RSS)](http://ramiro.org/notebook/rss.xml)\n* Random notes on Computer Science, Mathematics and Software Engineering http://barmaley-exe.github.io/ [(RSS)](http://feeds.feedburner.com/barmaley-exe-blog-feed)\n* Randy Zwitch http://randyzwitch.com/ [(RSS)](http://randyzwitch.com/feed.xml)\n* RaRe Technologies http://rare-technologies.com/blog/ [(RSS)](http://rare-technologies.com/feed/)\n* Rayli.Net http://rayli.net/blog/ [(RSS)](http://rayli.net/blog/feed/)\n* Revolutions http://blog.revolutionanalytics.com/ [(RSS)](http://blog.revolutionanalytics.com/atom.xml)\n* Rinu Boney http://rinuboney.github.io/ [(RSS)](http://rinuboney.github.io/feed.xml)\n* RNDuja Blog http://rnduja.github.io/ [(RSS)](http://rnduja.github.io/feed.xml)\n* Robert Chang https://medium.com/@rchang [(RSS)](https://medium.com/feed/@rchang)\n* Rocket-Powered Data Science http://rocketdatascience.org [(RSS)](http://rocketdatascience.org/?feed=rss2)\n* Sachin Joglekar's blog https://codesachin.wordpress.com/ [(RSS)](https://codesachin.wordpress.com/feed/)\n* samim https://medium.com/@samim [(RSS)](https://medium.com/feed/@samim)\n* Sean J. Taylor http://seanjtaylor.com/ [(RSS)](http://seanjtaylor.com/rss)\n* Sebastian Raschka http://sebastianraschka.com/blog/index.html [(RSS)](http://sebastianraschka.com/rss_feed.xml)\n* Sebastian Ruder http://sebastianruder.com/ [(RSS)](http://sebastianruder.com/rss/)\n* Sebastian's slow blog http://www.nowozin.net/sebastian/blog/ [(RSS)](http://www.nowozin.net/sebastian/blog/feeds/all.atom.xml)\n* SFL Scientific Blog https://sflscientific.com/blog/ [(RSS)](http://sflscientific.com/blog/?format=rss)\n* Shakir's Machine Learning Blog http://blog.shakirm.com/ [(RSS)](http://blog.shakirm.com/feed/)\n* Simply Statistics http://simplystatistics.org [(RSS)](http://simplystatistics.org/feed/)\n* Springboard Blog http://springboard.com/blog\n* Startup.ML Blog http://startup.ml/blog [(RSS)](http://www.startup.ml/blog?format=RSS)\n* Statistical Modeling, Causal Inference, and Social Science http://andrewgelman.com/ [(RSS)](http://andrewgelman.com/feed/)\n* Stigler Diet http://stiglerdiet.com/ [(RSS)](http://stiglerdiet.com/feeds/all.atom.xml)\n* Stitch Fix Tech Blog http://multithreaded.stitchfix.com/blog/ [(RSS)](http://multithreaded.stitchfix.com/feed.xml)\n* Stochastic R&D Notes http://arseny.info/ [(RSS)](http://arseny.info/feeds/all.rss.xml)\n* Storytelling with Statistics on Quora http://datastories.quora.com/ [(RSS)](http://datastories.quora.com/rss)\n* StreamHacker http://streamhacker.com/ [(RSS)](http://feeds.feedburner.com/StreamHacker)\n* Subconscious Musings http://blogs.sas.com/content/subconsciousmusings/ [(RSS)](http://feeds.feedburner.com/advanalytics)\n* Swan Intelligence http://swanintelligence.com/ [(RSS)](http://swanintelligence.com/feeds/all.rss.xml)\n* TechnoCalifornia http://technocalifornia.blogspot.se/ [(RSS)](http://technocalifornia.blogspot.com/feeds/posts/default)\n* TEXT ANALYSIS BLOG | AYLIEN http://blog.aylien.com/ [(RSS)](http://blog.aylien.com/rss)\n* The Angry Statistician http://angrystatistician.blogspot.com/ [(RSS)](http://angrystatistician.blogspot.com/feeds/posts/default)\n* The Clever Machine https://theclevermachine.wordpress.com/ [(RSS)](http://theclevermachine.wordpress.com/feed/)\n* The Data Camp Blog https://www.datacamp.com/community/blog [(RSS)](http://blog.datacamp.com/feed/)\n* The Data Incubator http://blog.thedataincubator.com/ [(RSS)](http://blog.thedataincubator.com/feed/)\n* The Data Science Lab https://datasciencelab.wordpress.com/ [(RSS)](http://datasciencelab.wordpress.com/feed/)\n* THE ETZ-FILES http://alexanderetz.com/ [(RSS)](http://nicebrain.wordpress.com/feed/)\n* The Science of Data http://www.martingoodson.com [(RSS)](http://www.martingoodson.com/rss/)\n* The Shape of Data https://shapeofdata.wordpress.com [(RSS)](https://shapeofdata.wordpress.com/feed/)\n* The unofficial Google data science Blog http://www.unofficialgoogledatascience.com/ [(RSS)](http://www.unofficialgoogledatascience.com/feeds/posts/default)\n* Tim Dettmers http://timdettmers.com/ [(RSS)](http://timdettmers.com/feed/)\n* Tombone's Computer Vision Blog http://www.computervisionblog.com/ [(RSS)](http://www.computervisionblog.com/feeds/posts/default)\n* Tommy Blanchard http://tommyblanchard.com/category/projects [(RSS)](http://tommyblanchard.com/feeds/all.atom.xml)\n* Trevor Stephens http://trevorstephens.com/ [(RSS)](http://trevorstephens.com/feed.xml)\n* Trey Causey http://treycausey.com/ [(RSS)](http://treycausey.com/feeds/all.atom.xml)\n* UW Data Science Blog http://datasciencedegree.wisconsin.edu/blog/ [(RSS)](http://datasciencedegree.wisconsin.edu/feed/)\n* Wellecks http://wellecks.wordpress.com/ [(RSS)](http://wellecks.wordpress.com/feed/)\n* Wes McKinney http://wesmckinney.com/archives.html [(RSS)](http://wesmckinney.com/feeds/all.atom.xml)\n* While My MCMC Gently Samples http://twiecki.github.io/ [(RSS)](http://twiecki.github.io/atom.xml)\n* WildML http://www.wildml.com/ [(RSS)](http://www.wildml.com/feed/)\n* Will do stuff for stuff http://rinzewind.org/blog-en [(RSS)](http://rinzewind.org/feed-en)\n* Will wolf http://willwolf.io/ [(RSS)](http://willwolf.io/feed/)\n* WILL'S NOISE http://www.willmcginnis.com/ [(RSS)](http://www.willmcginnis.com/feed/)\n* William Lyon http://www.lyonwj.com/ [(RSS)](http://www.lyonwj.com/atom.xml)\n* Win-Vector Blog http://www.win-vector.com/blog/ [(RSS)](http://www.win-vector.com/blog/feed/)\n* Yanir Seroussi http://yanirseroussi.com/ [(RSS)](http://yanirseroussi.com/feed/)\n* Zac Stewart http://zacstewart.com/ [(RSS)](http://zacstewart.com/feed.xml)\n* Å·hat http://blog.yhat.com/ [(RSS)](http://blog.yhat.com/rss.xml)\n* â„šuantitative âˆšourney http://outlace.com/ [(RSS)](http://outlace.com/feed.xml)\n* å¤§ãƒˆãƒ­ http://blog.otoro.net/ [(RSS)](http://blog.otoro.net/feed.xml)\n\n\n## credits\n\n* [Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793) by Wes McKinney\n* [PyCon 2015 Scikit-learn Tutorial](https://github.com/jakevdp/sklearn_pycon2015) by Jake VanderPlas\n* [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook) by Jake VanderPlas\n* [Parallel Machine Learning with scikit-learn and IPython](https://github.com/ogrisel/parallel_ml_tutorial) by Olivier Grisel\n* [Statistical Interference Using Computational Methods in Python](https://github.com/AllenDowney/CompStats) by Allen Downey\n* [TensorFlow Examples](https://github.com/aymericdamien/TensorFlow-Examples) by Aymeric Damien\n* [TensorFlow Tutorials](https://github.com/pkmital/tensorflow_tutorials) by Parag K Mital\n* [TensorFlow Tutorials](https://github.com/nlintz/TensorFlow-Tutorials) by Nathan Lintz\n* [TensorFlow Tutorials](https://github.com/alrojo/tensorflow-tutorial) by Alexander R Johansen\n* [TensorFlow Book](https://github.com/BinRoot/TensorFlow-Book) by Nishant Shukla\n* [Summer School 2015](https://github.com/mila-udem/summerschool2015) by mila-udem\n* [Keras tutorials](https://github.com/leriomaggio/deep-learning-keras-tensorflow) by Valerio Maggio\n* [Kaggle](https://www.kaggle.com/)\n* [Yhat Blog](http://blog.yhat.com/)\n\n## contributing\n\nContributions are welcome!  For bug reports or requests please [submit an issue](https://github.com/tarrysingh/Machine-Learning-Tutorials//issues).\n\n## contact-info\n\nFeel free to contact me to discuss any issues, questions, or comments.\n\n* Email: [tarry.singh@gmail.com](mailto:tarry.singh@gmail.com)\n* Twitter: [@tarrysingh](https://twitter.com/tarrysingh)\n* GitHub: [tarrysingh](https://github.com/tarrysingh.com)\n* LinkedIn: [Tarry Singh](https://www.linkedin.com/in/tarrysingh)\n* Website: [tarrysingh.com](https://tarrysingh.com)\n* Medium: [tarry@Medium](https://medium.com/@tarrysingh)\n* Quora : [Answers from Tarry on Quora](https://www.quora.com/profile/Tarry-Singh)\n\n## license\n\nThis repository contains a variety of content; some developed by Tarry Singh and some from third-parties and a lot will be maintained by me. The third-party content is distributed under the license provided by those parties.\n\nThe content was originally developed by Donne Martin is distributed under the following license. I will be maintaining and revamping it by adding PyTorch, Torch/Lua, MXNET and much more:\n\n*I am providing code and resources in this repository to you under an open source license.*\n\n    Copyright 2017 Tarry Singh\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTA="},"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"},{"name":"CSS","color":"#563d7c"},{"name":"Makefile","color":"#427819"},{"name":"HTML","color":"#e34c26"},{"name":"MATLAB","color":"#e16737"},{"name":"C++","color":"#f34b7d"},{"name":"TeX","color":"#3D6117"},{"name":"C","color":"#555555"},{"name":"R","color":"#198CE7"},{"name":"Shell","color":"#89e051"}]}},{"id":"R_kgDOGT8DBA","name":"sample-legacy-django-app","description":"A sample Django app demonstrating the use of the GoCardless Legacy API and the Python client.","url":"https://github.com/ssoad/sample-legacy-django-app","updatedAt":"2024-04-07T07:18:14Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/bb3a5d7cc6519b14b77d56734d763cefaa9616084f635cbca681a3b431c2d75e/ssoad/sample-legacy-django-app","stargazers":{"totalCount":0},"readme":{"text":"# GoCardless sample application\n\n## Setup\n\nThe first thing to do is to clone the repository:\n\n```sh\n$ git clone https://github.com/gocardless/sample-django-app.git\n$ cd sample-django-app\n```\n\nCreate a virtual environment to install dependencies in and activate it:\n\n```sh\n$ virtualenv2 --no-site-packages env\n$ source env/bin/activate\n```\n\nThen install the dependencies:\n\n```sh\n(env)$ pip install -r requirements.txt\n```\nNote the `(env)` in front of the prompt. This indicates that this terminal\nsession operates in a virtual environment set up by `virtualenv2`.\n\nOnce `pip` has finished downloading the dependencies:\n```sh\n(env)$ cd project\n(env)$ python manage.py runserver\n```\nAnd navigate to `http://127.0.0.1:8000/gocardless/`.\n\nIn order to test the purchase flows, fill in the account details in\n`project/gc_app/views.py` to match your **SANDBOX** developer credentials.\n\n## Walkthrough\n\nBefore you interact with the application, go to GoCardless Sandbox and set up\nthe Redirect URI in the Developer settings. To make it work with this\napplication, use the value `http://127.0.0.1:8000/gocardless/confirm/`. This is to\nmake sure you are redirected back to your site where the purchase is verified\nafter you have made a purchase.\n\n### One-off purchases\n\nThe simplest payment type is one-off. By clicking `Make purchase` on the sample\nappliation website, you are taken through the flow in making a single payment.\n\nA real-world example of one-off purchases is buying something in an online store.\n\n### Subscriptions\n\nSubscriptions are fixed periodic payments. Upon clicking `Subscribe` on the sample\napplication website, you are taken through the process of registering a subscription\nwith a merchant.\n\nAn example would be subscribing to a magazine or newspaper. The magazine is\npublished once a month and it costs Â£10, the payment flow sets up an automatic\ntransaction transferring Â£10 monthly to the merchant's account.\n\n### Pre-authorizations\n\nPre-authorizations are essentially subscriptions, with an added twist that it's\nup to the merchant to request funds from the customer's account, and the\ncustomer may be billed up to a certain, authorized amount every billing\nperiod. Upon clicking `Preauthorize` on the sample app website, you are taken\nthrough the flow of pre-authorizing a variable direct-debit payment.\n\nAn example from the real world would be a type of pay-as-you go service where\nthe customer authorizes the merchant to claim up to a certain amount per interval\ndepending on usage.\n\nIn the sample app, you pre-authorize a payment of up to Â£100 every 3 months.\n\nFor further information, refer to the [docs](https://sandbox.gocardless.com/docs/connect_guide#payment-types).\n\n## Webhooks\n\nSet up `localtunnel` to test out Webhooks. The `localtunnel` package should be\ninstalled as a dependency to the project.\nNote, however, that the port number is the same as the port that `python manage.py runserver` is\nrunning on, which is 8000.\n```sh\n(env)$ localtunnel-beta 8000\n=> Port 8000 is now publicly accessible from http://5bebd69e5222.v2.localtunnel.com ...\n```\nPlease refer to the [the Webhooks manual](https://sandbox.gocardless.com/docs/python/merchant_tutorial_webhook#receiving-webhooks) for more details.\n\n### Test your Webhooks\nOnce you have the app running with `python manage.py runserver` and tunneling\nset up with `localtunnel` (make sure you verify that by navigating to the URL\nthat `localtunnel` gives back to you) navigate to the \"Web hooks\" tab under the\nDeveloper section in GoCardless Sandbox. Make sure that the Webhook URL is the\nsame you got back from `localtunnel` with an added `/gocardless/webhook/` at the\nend, i.e `http://5bebd69e5222.v2.localtunnel.com/gocardless/webhook/`,\notherwise it does not work.  There should be a button for sending a test\nwebhook. Click that, select `Bill` as the object type and click `Fire webhook`.\n\nThe data from Webhook is accessible in the `Webhook` class-based view in\n`project/gc_app/views.py` in the `webhook_data` variable.\n\n## Tests\n\nTo run the tests, `cd` into the directory where `manage.py` is:\n```sh\n(env)$ python manage.py test gc_app\n```\n"},"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"R_kgDOGQyCbA","name":"PyCompressor","description":"File Compressor Using Python","url":"https://github.com/ssoad/PyCompressor","updatedAt":"2024-04-07T07:20:58Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/3f2d35349298ea2542466cc6a713906a2d09b33bf839388ad6e693b43c60da2a/ssoad/PyCompressor","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"R_kgDOGO4ONw","name":"PaddleFL","description":"Federated Deep Learning in PaddlePaddle","url":"https://github.com/ssoad/PaddleFL","updatedAt":"2024-04-07T07:20:08Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/895dccd5bfeffb36b1716c26006b33616a057f9e51f82147be311e2e7fb99c6e/ssoad/PaddleFL","stargazers":{"totalCount":0},"readme":{"text":"<img src='https://github.com/PaddlePaddle/PaddleFL/blob/master/docs/source/_static/FL-logo.png' width = \"400\" height = \"160\">\n\n[DOC](https://paddlefl.readthedocs.io/en/latest/) | [Quick Start](https://paddlefl.readthedocs.io/en/latest/compile_and_intall.html) | [ä¸­æ–‡](./README_cn.md)\n\n[![Release](https://img.shields.io/github/release/PaddlePaddle/PaddleFL.svg)](https://github.com/PaddlePaddle/PaddleFL/releases)\n[![License](https://img.shields.io/badge/license-Apache%202-blue.svg)](LICENSE)\n\nPaddleFL is an open source federated learning framework based on PaddlePaddle. Researchers can easily replicate and compare different federated learning algorithms with PaddleFL. Developers can also benefit from PaddleFL in that it is easy to deploy a federated learning system in large scale distributed clusters. In PaddleFL, several federated learning strategies will be provided with application in computer vision, natural language processing, recommendation and so on. Application of traditional machine learning training strategies such as Multi-task learning, Transfer Learning in Federated Learning settings will be provided. Based on PaddlePaddle's large scale distributed training and elastic scheduling of training job on Kubernetes, PaddleFL can be easily deployed based on full-stack open sourced software.\n\n\n## Overview of PaddleFL\n\nData is becoming more and more expensive nowadays, and sharing of raw data is very hard across organizations. Federated Learning aims to solve the problem of data isolation and secure sharing of data knowledge among organizations. The concept of federated learning is proposed by researchers in Google [1, 2, 3]. PaddleFL implements federated learning based on the PaddlePaddle framework. Application demonstrations in natural language processing, computer vision and recommendation will be provided in PaddleFL. PaddleFL supports the current two main federated learning strategies[4]: vertical federated learning and horizontal federated learning. Multi-tasking learning [7] and transfer learning [8] in federated learning will be developed and supported in PaddleFL in the future.\n\n- **Horizontal Federated Learning**: Federated Averaging [2], Differential Privacy [6], Secure Aggregation[11]\n- **Vertical Federated Learning**: Two-party training with PrivC[5], Three-party training with ABY3 [10]\n\n<img src='images/FL-framework.png' width = \"1000\" height = \"320\" align=\"middle\"/>\n\n## Recent Feature Release Roadmap\n\n- 2021.08: Two party federated learning in vertical scenario\n- 2021.Q4: GPU version of MPC, Split Learning Based vertical federated learning\n\n## Framework Design of PaddleFL\n\nThere are mainly two components in PaddleFL: **Data Parallel** and **Federated Learning with MPC (PFM)**.\n\n- With Data Parallel, distributed data holders can finish their Federated Learning tasks based on common horizontal federated strategies, such as FedAvg, DPSGD, etc.\n\n- PFM is implemented based on secure multi-party computation (MPC) to enable secure training and prediction. As a key product of PaddleFL, PFM intrinsically supports federated learning well, including horizontal, vertical and transfer learning scenarios. Users with little cryptography expertise can also train models or conduct prediction on encrypted data.\n\n### Data Parallel\n\nIn Data Parallel, the whole process of model training is divided into two stages: Compile Time and Run Time. Components for defining a federated learning task and training a federated learning job are as follows:\n\n<img src='images/FL-training.png' width = \"1000\" height = \"400\" align=\"middle\"/>\n\n#### A. Compile Time\n\n- **FL-Strategy**: a user can define federated learning strategies with FL-Strategy such as Fed-Avg[2]\n\n- **User-Defined-Program**: PaddlePaddle's program that defines the machine learning model structure and training strategies such as multi-task learning.\n\n- **Distributed-Config**: In federated learning, a system should be deployed in distributed settings. Distributed Training Config defines distributed training node information.\n\n- **FL-Job-Generator**: Given FL-Strategy, User-Defined Program and Distributed Training Config, FL-Job for federated server and worker will be generated through FL Job Generator. FL-Jobs will be sent to organizations and federated parameter server for run-time execution.\n\n#### B. Run Time\n\n- **FL-Server**: federated parameter server that usually runs in cloud or third-party clusters.\n\n- **FL-Worker**: Each organization participates in federated learning will have one or more federated workers that will communicate with the federated parameter server.\n\n- **FL-scheduler**: Decide which set of trainers can join the training before each updating cycle.\n\nFor more instructions, please refer to the [examples](./python/paddle_fl/paddle_fl/examples)\n\n### Federated Learning with MPC\n\nPaddleFL MPC implements secure training and inference tasks based on the underlying MPC protocol like ABY3[10] and PrivC[5], which are high efficient multi-party computing model. In PaddeFL, two-party federated learning based on PrivC mainly supports linear/logistic regression and DNN model. Three-party federated learning based on ABY3 supports linear/logistic regression, DNN model, CNN model and FM.\n\nIn PaddleFL MPC, participants can be classified into roles of Input Party (IP), Computing Party (CP) and Result Party (RP). Input Parties (e.g., the training data/model owners) encrypt and distribute data or models to Computing Parties (There exist three computing parties in ABY3 protocol while two computing parties in PrivC protocol). Computing Parties (e.g., the VM on the cloud) conduct training or inference tasks based on specific MPC protocols, being restricted to see only the encrypted data or models, and thus guarantee the data privacy. When the computation is completed, one or more Result Parties (e.g., data owners or specified third-party) receive the encrypted results from Computing Parties, and reconstruct the plaintext results. Roles can be overlapped, e.g., a data owner can also act as a computing party.\n\n<img src='images/PFM-overview.png' width = \"1000\" height = \"446\" align=\"middle\"/>\n\n\nA full training or inference process in PFM consists of mainly three phases: data preparation, training/inference, and result reconstruction.\n\n#### A. Data Preparation\n\n- **Private data alignment**: PFM enables data owners (IPs) to find out records with identical keys (like UUID) without revealing private data to each other. This is especially useful in the vertical learning cases where segmented features with same keys need to be identified and aligned from all owners in a private manner before training.\n\n- **Encryption and distribution**: PFM provides both online and offline data encryption and distribution solutions. If users choose the offline data sharing scheme, data and models from IPs will be encrypted using Secret-Sharing[9], and then be sent to CPs, via directly transmission or distributed storage like HDFS. If users adopt the online solution, IPs encrypt and distribute data and models online at the beginning of the training phase. Each CP can only obtain one share of each piece of data, and thus is unable to recover the original value in the Semi-honest model.\n\n#### B. Training/Inference\n\nA PFM program is exactly a PaddlePaddle program, and will be executed as normal PaddlePaddle programs. Before training/inference, user needs to choose a MPC protocol, define a machine learning model and their training strategies. Typical machine learning operators are provided in `paddle_fl.mpc` over encrypted data, of which the instances are created and run in order by Executor during run-time.\n\nFor more information of Training/inference phase, please refer to the following [doc](./docs/source/md/mpc_train.md).\n\n#### C. Result Reconstruction\n\nUpon completion of the secure training (or inference) job, the models (or prediction results) will be output by CPs in encrypted form. Result Parties can collect the encrypted results, decrypt them using the tools in PFM, and deliver the plaintext results to users (Currently, data sharing and reconstruction can be supported in both offline and online modes).\n\nFor more instructions, please refer to [mpc examples](./python/paddle_fl/mpc/examples)\n\n\n## Installation\n\n### Environment preparation\n\n* CentOS 7 (64 bit)\n* Python 3.5/3.6/3.7 ( 64 bit) or above\n* pip3 9.0.1+ (64 bit)\n* PaddlePaddle 1.8.5 \n* Redis 5.0.8 (64 bit)\n* GCC or G++ 8.3.1\n* cmake 3.15+\n\n### Installation steps\n\nWe provide three ways to install PaddleFLï¼š\n\n1. Use PaddleFL in docker\n\nWe **highly recommend** to run PaddleFL in Docker\n\n```sh\n#Pull and run the docker\ndocker pull paddlepaddle/paddlefl:1.1.2\ndocker run --name <docker_name> --net=host -it -v $PWD:/paddle <image id> /bin/bash\n\n```\n\n2. Install PaddleFL via installation package\n\nWe provide compiled PaddlePaddle and PaddleFL installation packages, you can download and install them directly.\n\nFirst, install PaddlePaddle\n```\n#Install PaddlePaddle\nwget https://paddlefl.bj.bcebos.com/paddlepaddle-1.8.5-cp**-cp**-linux_x86_64.whl\npip3 install paddlepaddle-1.8.5-cp**-cp**-linux_x86_64.whl\n```\nPlease replace ** with the python version in the installation environment. E.g., if you are using python3.8, the commands are as below:\n```\nwget https://paddlefl.bj.bcebos.com/paddlepaddle-1.8.5-cp38-cp38-linux_x86_64.whl\npip3 install paddlepaddle-1.8.5-cp38-cp38-linux_x86_64.whl\n```\nThen, install PaddleFL\n```\n#Install PaddleFL\npip3 install paddle_fl\n```\nThe above command will automatically install PaddleFL corresponding to python3.8. For other python3 environments, you can download the corresponding installation package from https://pypi.org/project/paddle-fl/1.1.2/#files and install it manually.\n\n\n3. Install PaddleFL from source code\n\nIf you want to compile and install from source code, please click [here](./docs/source/md/compile_and_install.md) to get instructions.\n\n\nIf you are using the gloo communication model, you will need Redis. We also provide a stable Redis installation package for download.\n\n```sh\nwget --no-check-certificate https://paddlefl.bj.bcebos.com/redis-stable.tar\ntar -xf redis-stable.tar\ncd redis-stable &&  make\n```\n\n## Easy Deployment with Kubernetes\n\n### Horizontal Federated Learning\n\n```sh\n\nkubectl apply -f ./python/paddle_fl/paddle_fl/examples/k8s_deployment/master.yaml\n\n```\nPlease refer [K8S deployment example](./python/paddle_fl/paddle_fl/examples/k8s_deployment/README.md) for details\n\nYou can also refer [K8S cluster application and kubectl installation](./python/paddle_fl/paddle_fl/examples/k8s_deployment/deploy_instruction.md) to deploy your K8S cluster\n\n\n\n## PaddleFL Extension\n\n### fl-mobile simulator\n\n[FL-mobile](./python/paddle_fl/mobile/) is a framework integrated algorithm simulation , training and deployment. The simulator is part of FL-mobile.\n\nThe design purpose of the simulator is to simulate the actual cooperated training among multiple mobile terminal devices online. FL-mobile simulates multiple mobile terminal devices online on the server to verify the effect of algorithms rapidly. The advantages of the simulator are as follows:\n\n- Support training for single machine and distributed networks\n- Support training for common open source datasets\n- Support private and shared parameters in the models, the private parameters do not participant in the global update\n\n\n## On Going and Future Work\n\n- Vertical Federated Learning will support more algorithms.\n\n- Add K8S deployment scheme for PFM.\n\n- FL mobile simulator will be open sourced in following versions.\n\n## Related Work\n\n[1]. Jakub KoneÄnÃ½, H. Brendan McMahan, Daniel Ramage, Peter RichtÃ¡rik. **Federated Optimization: Distributed Machine Learning for On-Device Intelligence.** arXiv preprint 2016\n\n[2]. H. Brendan McMahan, Eider Moore, Daniel Ramage, Blaise AgÃ¼era y Arcas. **Federated Learning of Deep Networks using Model Averaging.** arXiv preprint 2016\n\n[3]. Jakub KoneÄnÃ½, H. Brendan McMahan, Felix X. Yu, Peter RichtÃ¡rik, Ananda Theertha Suresh, Dave Bacon. **Federated Learning: Strategies for Improving Communication Efficiency.** arXiv preprint 2016\n\n[4]. Qiang Yang, Yang Liu, Tianjian Chen, Yongxin Tong. **Federated Machine Learning: Concept and Applications.** ACM Transactions on Intelligent Systems and Technology 2019\n\n[5]. Kai He, Liu Yang, Jue Hong, Jinghua Jiang, Jieming Wu, Xu Dong et al. **PrivC  - A framework for efficient Secure Two-Party Computation.** In Proc. of SecureComm 2019\n\n[6]. MartÃ­n Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, Li Zhang. **Deep Learning with Differential Privacy.** In Proc. of CCS 2016\n\n[7]. Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, Ameet Talwalkar. **Federated Multi-Task Learning**. In Proc. of NIPS 2017\n\n[8]. Yang Liu, Tianjian Chen, Qiang Yang. **Secure Federated Transfer Learning.**  IEEE Intelligent Systems 2018\n\n[9]. https://en.wikipedia.org/wiki/Secret_sharing\n\n[10]. Payman Mohassel and Peter Rindal. **ABY3: A Mixed Protocol Framework for Machine Learning.** In Proc. of CCS 2018\n\n[11]. Aaron Segal Antonio Marcedone Benjamin Kreuter Daniel Ramage H. Brendan McMahan Karn Seth K. A. Bonawitz Sarvar Patel Vladimir Ivanov. **Practical Secure Aggregation for Privacy-Preserving Machine Learning**.  In Proc. of CCS 2017\n\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTI="},"primaryLanguage":{"name":"C++","color":"#f34b7d"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"},{"name":"Shell","color":"#89e051"},{"name":"CMake","color":"#DA3434"},{"name":"C++","color":"#f34b7d"},{"name":"Makefile","color":"#427819"}]}},{"id":"R_kgDOGNlgEg","name":"FlutterAmazingOTP","description":null,"url":"https://github.com/ssoad/FlutterAmazingOTP","updatedAt":"2024-04-07T07:21:01Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/1af2e5dd708592585829b0bfec9b6c5d192845e1617ff1fb22512f69fd65853f/ssoad/FlutterAmazingOTP","stargazers":{"totalCount":0},"readme":{"text":"# otp_screen\n\nA new Flutter package for both android & iOS which helps developer in creating Otp screen with few lines of code.\n\n[![](https://img.shields.io/badge/version-0.0.2-blue)](https://pub.dev/packages/otp_screen)\n[![](https://img.shields.io/badge/package-flutter-blue)](https://github.com/lokesh-sudhakar/Flutter-OtpScreen)\n[![](https://img.shields.io/badge/platform-android%20%26%20ios-bg)](https://github.com/lokesh-sudhakar/Flutter-OtpScreen)\n\n### Show some :heart: and star the repo to support the project\n\n## Screenshots\n\n<img src=\"https://user-images.githubusercontent.com/35700254/88982227-57c39280-d2e5-11ea-8386-b846da22232a.png\" height=\"300em\" />  <img src=\"https://user-images.githubusercontent.com/35700254/88982239-614cfa80-d2e5-11ea-996a-3f9fcd14830c.png\" height=\"300em\" />  <img src=\"https://user-images.githubusercontent.com/35700254/88982248-6742db80-d2e5-11ea-92f0-ea4e1ea20093.png\" height=\"300em\" />\n\n---\n\n## Usage\n\n[Example](https://github.com/lokesh-sudhakar/Flutter-OtpScreen/blob/master/example/lib/main.dart)\n\nTo use this package:\n\n* add the dependency to your [pubspec.yaml](https://github.com/lokesh-sudhakar/Flutter-OtpScreen/blob/master/example/pubspec.yaml) file.\n\n```yaml\n    dependencies:\n        flutter:\n          sdk: flutter\n        otp_screen: <latest-version>\n```\n\n### How to use\n\n```dart\n\n  // logic to validate otp return [null] when success else error [String]\n  Future<String> validateOtp(String otp) async {\n    await Future.delayed(Duration(milliseconds: 2000));\n    if (otp == \"1234\") {\n      return null;\n    } else {\n      return \"The entered Otp is wrong\";\n    }\n  }\n\n  // action to be performed after OTP validation is success\n  void moveToNextScreen(context) {\n    Navigator.push(context, MaterialPageRoute(\n        builder: (context) => SuccessfulOtpScreen()));\n  }\n\n  @override\n  Widget build(BuildContext context) {\n    return MaterialApp(\n      debugShowCheckedModeBanner: false,\n      // initialize the OTP screen by passing validation logic and route callback\n      home: OtpScreen(\n        otpLength: 4,\n        validateOtp: validateOtp,\n        routeCallback: moveToNextScreen,\n        titleColor: Colors.black,\n        themeColor: Colors.black,\n      ),\n    );\n  }\n}\n\n```\nThe above code opens the simple OTP screen\n\n<img src=\"https://user-images.githubusercontent.com/35700254/88982283-7cb80580-d2e5-11ea-9041-4293a8c3ab04.png\" height=\"300em\" />\n\n---\n\n### Customize Options\n\nYou can play with different colors and add gradients as background to the screen\n\n```dart\n  @override\n  Widget build(BuildContext context) {\n    return MaterialApp(\n      debugShowCheckedModeBanner: false,\n      home: OtpScreen.withGradientBackground(\n          topColor: Color(0xFFcc2b5e),\n          bottomColor: Color(0xFF753a88),\n          otpLength: 4,\n          validateOtp: validateOtp,\n          routeCallback: moveToNextScreen,\n          themeColor: Colors.white,\n          titleColor: Colors.white,\n          title: \"Phone Number Verification\",\n          subTitle: \"Enter the code sent to \\n +919876543210\",\n          icon: Image.asset(\n            'images/phone_logo.png',\n            fit: BoxFit.fill,\n          ),\n      ),\n```\n\nThe output of the above code will open below screen.\n\n\n<img src=\"https://user-images.githubusercontent.com/35700254/88982272-745fca80-d2e5-11ea-8810-495f137fa997.png\" height=\"300em\" />\n\n\n### Created & Maintained By\n\n[Lokesh Chennamchetty] (https://github.com/lokesh-sudhakar) ([LinkedIn](https://www.linkedin.com/in/lokesh-chennamchetty))\n\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTA="},"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Java","color":"#b07219"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"},{"name":"HTML","color":"#e34c26"}]}},{"id":"R_kgDOGMz1yg","name":"pytorch-tutorial","description":"PyTorch Tutorial for Deep Learning Researchers","url":"https://github.com/ssoad/pytorch-tutorial","updatedAt":"2024-04-07T07:20:13Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/b4791ead862e29d811b00d5c3a189d77b65d6d4e3382f7cd8132d2335e6afacf/ssoad/pytorch-tutorial","stargazers":{"totalCount":0},"readme":{"text":"<p align=\"center\"><img width=\"40%\" src=\"logo/pytorch_logo_2018.svg\" /></p>\n\n--------------------------------------------------------------------------------\n\nThis repository provides tutorial code for deep learning researchers to learn [PyTorch](https://github.com/pytorch/pytorch). In the tutorial, most of the models were implemented with less than 30 lines of code. Before starting this tutorial, it is recommended to finish [Official Pytorch Tutorial](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).\n\n\n<br/>\n\n## Table of Contents\n\n#### 1. Basics\n* [PyTorch Basics](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/pytorch_basics/main.py)\n* [Linear Regression](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/linear_regression/main.py#L22-L23)\n* [Logistic Regression](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/logistic_regression/main.py#L33-L34)\n* [Feedforward Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/feedforward_neural_network/main.py#L37-L49)\n\n#### 2. Intermediate\n* [Convolutional Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/convolutional_neural_network/main.py#L35-L56)\n* [Deep Residual Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/deep_residual_network/main.py#L76-L113)\n* [Recurrent Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/recurrent_neural_network/main.py#L39-L58)\n* [Bidirectional Recurrent Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/bidirectional_recurrent_neural_network/main.py#L39-L58)\n* [Language Model (RNN-LM)](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/language_model/main.py#L30-L50)\n\n#### 3. Advanced\n* [Generative Adversarial Networks](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/generative_adversarial_network/main.py#L41-L57)\n* [Variational Auto-Encoder](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/variational_autoencoder/main.py#L38-L65)\n* [Neural Style Transfer](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/neural_style_transfer)\n* [Image Captioning (CNN-RNN)](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/image_captioning)\n\n#### 4. Utilities\n* [TensorBoard in PyTorch](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/04-utils/tensorboard)\n\n\n<br/>\n\n## Getting Started\n```bash\n$ git clone https://github.com/yunjey/pytorch-tutorial.git\n$ cd pytorch-tutorial/tutorials/PATH_TO_PROJECT\n$ python main.py\n```\n\n<br/>\n\n## Dependencies\n* [Python 2.7 or 3.5+](https://www.continuum.io/downloads)\n* [PyTorch 0.4.0+](http://pytorch.org/)\n\n\n\n\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTEz"},"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"},{"name":"Shell","color":"#89e051"}]}},{"id":"R_kgDOGJSMNg","name":"Bangla-Handwriting","description":null,"url":"https://github.com/ssoad/Bangla-Handwriting","updatedAt":"2024-04-07T07:20:15Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/5fcd012bd4dddd9c20f2e0654d1a888506a67954166621d0037f2b20eb56243c/ssoad/Bangla-Handwriting","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Jupyter Notebook","color":"#DA5B0B"},"languages":{"nodes":[{"name":"Jupyter Notebook","color":"#DA5B0B"}]}},{"id":"MDEwOlJlcG9zaXRvcnk0MDg1Nzk1MDQ=","name":"django_crud","description":null,"url":"https://github.com/ssoad/django_crud","updatedAt":"2024-04-07T07:20:14Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/347bb6258387e8d71591a9771089ca53c7e2c2cf616a5ef82a14b493cf115f57/ssoad/django_crud","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"},{"name":"CSS","color":"#563d7c"},{"name":"HTML","color":"#e34c26"}]}},{"id":"MDEwOlJlcG9zaXRvcnk0MDYwOTY3Mjg=","name":"process-scheduling-solver","description":"A web app to generate gantt chart and calculate turnaround time and waiting time for various CPU scheduling algorithms.","url":"https://github.com/ssoad/process-scheduling-solver","updatedAt":"2024-04-07T07:20:12Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/ba6d3a0d06bf78ebaec98f4b16cca4847cc07e6625b32c1426aafb2d306b0755/ssoad/process-scheduling-solver","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"TypeScript","color":"#3178c6"},"languages":{"nodes":[{"name":"JavaScript","color":"#f1e05a"},{"name":"TypeScript","color":"#3178c6"}]}},{"id":"MDEwOlJlcG9zaXRvcnkzOTY2Nzc5NDY=","name":"etaka_backend","description":null,"url":"https://github.com/ssoad/etaka_backend","updatedAt":"2024-04-07T07:21:32Z","forkCount":1,"openGraphImageUrl":"https://opengraph.githubassets.com/96499098aa935cd6973916458de86003b424c40dc26632b7d065baa85cecab33/ssoad/etaka_backend","stargazers":{"totalCount":0},"readme":{"text":"# eTaka Backend application\n\n## Setup\n\nThe first thing to do is to clone the repository:\n\n```sh\n$ git clone https://github.com/ssoad/etaka_backend.git\n$ cd etaka_backend\n```\n\nCreate a virtual environment to install dependencies in and activate it:\n\n```sh\n$ virtualenv2 --no-site-packages env\n$ source env/bin/activate\n```\n\nThen install the dependencies:\n\n```sh\n(env)$ pip install -r requirements.txt\n```\nNote the `(env)` in front of the prompt. This indicates that this terminal\nsession operates in a virtual environment set up by `virtualenv2`.\n\nOnce `pip` has finished downloading the dependencies:\n```sh\n(env)$ cd project\n(env)$ python manage.py runserver\n```\nAnd navigate to `http://127.0.0.1:8000/`.\n"},"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"},{"name":"CSS","color":"#563d7c"},{"name":"JavaScript","color":"#f1e05a"},{"name":"PowerShell","color":"#012456"},{"name":"Batchfile","color":"#C1F12E"}]}},{"id":"MDEwOlJlcG9zaXRvcnkzNzUyNjEwNjA=","name":"National-Healthcare-Online-Management","description":null,"url":"https://github.com/14201901/National-Healthcare-Online-Management","updatedAt":"2021-06-21T18:02:50Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/fc89b78f471b2cb3065ebe618e655348bddaebb88fe514b9adba16312515b52a/14201901/National-Healthcare-Online-Management","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"HTML","color":"#e34c26"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"},{"name":"CSS","color":"#563d7c"},{"name":"HTML","color":"#e34c26"},{"name":"JavaScript","color":"#f1e05a"}]}},{"id":"MDEwOlJlcG9zaXRvcnkzNzA0NzcxMzY=","name":"hospitalmanagement","description":null,"url":"https://github.com/ssoad/hospitalmanagement","updatedAt":"2024-04-07T07:20:06Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/20bc205df1f2a6e508618cb3be7c2b54d378867929d308256a0bdd4f2c2f499e/ssoad/hospitalmanagement","stargazers":{"totalCount":0},"readme":null,"licenseInfo":null,"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"},{"name":"CSS","color":"#563d7c"},{"name":"HTML","color":"#e34c26"},{"name":"JavaScript","color":"#f1e05a"},{"name":"PowerShell","color":"#012456"},{"name":"Batchfile","color":"#C1F12E"}]}},{"id":"MDEwOlJlcG9zaXRvcnkzNTMzMzMxOTM=","name":"sms_sender","description":null,"url":"https://github.com/ssoad/sms_sender","updatedAt":"2024-04-07T07:20:04Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/99e3df5b3e14f2dfed7ed858b5ae06e0f21b23efaeaed52027b14bc5cc45974e/ssoad/sms_sender","stargazers":{"totalCount":0},"readme":{"text":"# sms_sender\n\nA new Flutter application.\n\n## Getting Started\n\nThis project is a starting point for a Flutter application.\n\nA few resources to get you started if this is your first Flutter project:\n\n- [Lab: Write your first Flutter app](https://flutter.dev/docs/get-started/codelab)\n- [Cookbook: Useful Flutter samples](https://flutter.dev/docs/cookbook)\n\nFor help getting started with Flutter, view our\n[online documentation](https://flutter.dev/docs), which offers tutorials,\nsamples, guidance on mobile development, and a full API reference.\n"},"licenseInfo":null,"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"}]}},{"id":"MDEwOlJlcG9zaXRvcnkzNTIzNTM4NjE=","name":"PatientMonitoringSystem","description":null,"url":"https://github.com/ssoad/PatientMonitoringSystem","updatedAt":"2024-04-07T07:20:46Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/72f359a070c5406b1a67870f1f40a4f7d22404db76799a7716c4f8aa4ba22520/ssoad/PatientMonitoringSystem","stargazers":{"totalCount":0},"readme":{"text":"# Smart Patient Monitoring System\n\n## Motivation:\n<p>Every year in our high dense populated country lots of patients are admitted to\nhospitals for medical treatment but unfortunately for the shortage of doctors and\nnurses monitoring many patients don&#39;t get proper treatment. A smart patient\nmonitoring system can reduce this problem and can undoubtedly save a more\nvaluable life.</p><br>\n\n## Objective:\n<p>The objective of patient monitoring is to have a quantitative assessment of the\nimportant physiological variables of the patients during critical periods of their\nbiological functions. For diagnostic and research purposes, it is necessary to\nknow their actual value or trend of change. It also reduces health care costs by\nreducing physician office visits, hospitalizations, and diagnostic testing\nprocedures, and time-saving.</p><br>\n\n## Critical Challenges:\n<p>As our background is not from medical science so it&#39;s\nobviously tough for us to work with this project where the most critical\nchallenge is doing this type of sensitive project having a very low level of\nknowledge about medical science and one small error or miscalculation can\ncreate a massive accident. So the challenge is much critical.</p>\n\n## Technolgy Used:\n\n - Python, Django, Django REST API (Backend)\n - HTML, CSS, Bootstrap, ChartJS (Frontend)\n - Arduino UNO, Proteus (For Hardware Simulation)\n - Github (VCS)\n"},"licenseInfo":null,"primaryLanguage":{"name":"JavaScript","color":"#f1e05a"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"},{"name":"HTML","color":"#e34c26"},{"name":"CSS","color":"#563d7c"},{"name":"JavaScript","color":"#f1e05a"},{"name":"C++","color":"#f34b7d"}]}},{"id":"MDEwOlJlcG9zaXRvcnkzNDU0MDg4MzQ=","name":"encrytion_decryption","description":null,"url":"https://github.com/ssoad/encrytion_decryption","updatedAt":"2024-04-07T07:19:59Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/f1728b997843b9cb9bdf949f79d6393a45408efb00e835e6f45dc1f18ca378ee/ssoad/encrytion_decryption","stargazers":{"totalCount":0},"readme":null,"licenseInfo":{"id":"MDc6TGljZW5zZTI="},"primaryLanguage":{"name":"Python","color":"#3572A5"},"languages":{"nodes":[{"name":"Python","color":"#3572A5"}]}},{"id":"MDEwOlJlcG9zaXRvcnkzMTI2MDcyODM=","name":"health-monitoring-system","description":null,"url":"https://github.com/RafatMeraz/health-monitoring-system","updatedAt":"2020-11-14T13:07:12Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/da2dfb24d72ecffc1e272093eece6487e7288155910ace56cb08a803a8afeca7/RafatMeraz/health-monitoring-system","stargazers":{"totalCount":0},"readme":{"text":"# Health Monitoring System\n\n**Overview:**\n\nWe are going to develop an app that will provide the services about health monitoring. A doctor can check his/her patient data that s/he can monitor them even without physically available at the hospital. Important records like blood pressure, heart rate, temperature, etc. are read from the sensor, store in the database, and pass it to the doctor's end. Also, it will show the risk of the patient!\n\n## TEAM:\n\n**Rafat Maraz**\n\n**Rashik Rahman**\n\n**Mehedi Ul Hasnain**\n\n**Sohanuzzaman Soad**\n"},"licenseInfo":null,"primaryLanguage":{"name":"Dart","color":"#00B4AB"},"languages":{"nodes":[{"name":"Kotlin","color":"#A97BFF"},{"name":"Swift","color":"#F05138"},{"name":"Objective-C","color":"#438eff"},{"name":"Dart","color":"#00B4AB"}]}},{"id":"MDEwOlJlcG9zaXRvcnkyODk3MDY1MzQ=","name":"ssoad","description":"This repo is created for Self Identity in github profile","url":"https://github.com/ssoad/ssoad","updatedAt":"2024-06-10T17:36:11Z","forkCount":0,"openGraphImageUrl":"https://opengraph.githubassets.com/13d47f020e890b2bc8d71188f27471d01c9713c32fdd7f0bd5d5a57bde1902b2/ssoad/ssoad","stargazers":{"totalCount":0},"readme":{"text":"![](assets/Bottom_up.svg)\n<!--   my-icons -->\n<p align=\"center\">\n    ðŸ’œ I'm trying to romanticize programming<br><br>\n    Growing up, I was always fascinated with the way things worked. There was nothing that I could not set my mind to that I would try to figure out. I was always taking things apart and putting them back together. Failed a bunched but learned along the way.<br><br><br>\n    <a href=\"https://github.com/ssoad/ssoad\"><img src=\"https://img.shields.io/badge/status-updating-brightgreen.svg\"></a>\n    <a href=\"https://github.com/python/cpython\"><img src=\"https://img.shields.io/badge/Python-3.10-FF1493.svg\"></a>\n    <a href=\"https://github.com/ssoad/ssoad/graphs/contributors\"><img src=\"https://img.shields.io/github/contributors/ssoad/ssoad?color=blue\"></a>\n    <a href=\"https://github.com/ssoad/ssoad/stargazers\"><img src=\"https://img.shields.io/github/stars/ssoad/ssoad.svg?logo=github\"></a>\n    <a href=\"https://github.com/ssoad/soad/network/members\"><img src=\"https://img.shields.io/github/forks/ssoad/ssoad.svg?color=blue&logo=github\"></a>\n    <img src=\"https://komarev.com/ghpvc/?username=ssoad\" alt=\"ssoad\" />\n</p>\n\n\n[![Typing SVG](https://readme-typing-svg.herokuapp.com?color=%2336BCF7&center=true&vCenter=true&width=1000&lines=Hi+there+ðŸ‘‹,+I+am+Sohanuzzaman+Soad;+Welcome+to+My+Profile!;Over+4+years+of+programming+experience;Always+learning+new+things+;Machine+learning+enthusiast+;Kaggle+community+member)](https://git.io/typing-svg)\n\n\n<br>\n<br>\n<p align=\"center\">\n   <a href=\"https://stardev.io/developers/ssoad\"><img alt=\"Check out ssoad's profile on stardev.io\" src=\"https://stardev.io/developers/ssoad/badge/languages/locality.svg\" /></a> <br><br>\n    <img src=\"https://github-profile-trophy.vercel.app/?username=ssoad&theme=onedark&margin-w=30&margin-h=30&row=2&column=4\" alt=\"ssoad\" />\n</p>\n\n<br>\n<br>\n\n\n## ðŸŽ–ï¸ Earned Specialized Badges \n <p float=\"left\" align=\"center\">\n<!--      <img alt=\"Check out ssoad's profile on stardev.io\" src=\"https://stardev.io/developers/ssoad/badge/languages/locality.svg\" />\n      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -->\n  <img src=\"./badges/meta-android-developer-certificate.png\" height=\"150\" width=\"150\" />\n  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n  <img src=\"./badges/deep-learning-specialization.png\" height=\"150\" width=\"150\" />\n\n  \n</p>\n\n## Connect with me\n<p align=\"left\">\n<a href=\"https://codepen.io/ssoad\" target=\"blank\"><img align=\"center\" src=\"https://img.shields.io/badge/Codepen-000000?style=for-the-badge&logo=codepen&logoColor=white\" alt=\"ssoad\" /></a>\n<a href=\"https://dev.to/ssoad\" target=\"blank\"><img align=\"center\" src=\"https://img.shields.io/badge/dev.to-0A0A0A?style=for-the-badge&logo=devdotto&logoColor=white\" alt=\"ssoad\" /></a>\n<a href=\"https://twitter.com/_sssoad\" target=\"blank\"><img align=\"center\" src=\"https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white\" alt=\"_sssoad\"/></a>\n<a href=\"https://linkedin.com/in/ssoad\" target=\"blank\"><img align=\"center\" src=\"https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white\" alt=\"ssoad\"/></a>\n<a href=\"https://stackoverflow.com/users/ssoad\" target=\"blank\"><img align=\"center\" src=\"https://img.shields.io/badge/Stack_Overflow-FE7A16?style=for-the-badge&logo=stack-overflow&logoColor=white\" alt=\"ssoad\"/></a>\n<a href=\"https://kaggle.com/ssoad\" target=\"blank\"><img align=\"center\" src=\"https://img.shields.io/badge/Kaggle-20BEFF?style=for-the-badge&logo=Kaggle&logoColor=white\" alt=\"ssoad\"/></a>\n<a href=\"https://medium.com/@ssoad\" target=\"blank\"><img align=\"center\" src=\"https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white\" alt=\"@ssoad\" /></a>\n<a href=\"https://www.codechef.com/users/ssoad\" target=\"blank\"><img align=\"center\" src=\"https://img.shields.io/badge/-CodeChef-5B4638?style=for-the-badge&logo=CodeChef&logoColor=white\" alt=\"ssoad\" /></a>\n<a href=\"https://www.hackerrank.com/sssoad\" target=\"blank\"><img align=\"center\" src=\"https://img.shields.io/badge/-Hackerrank-2EC866?style=for-the-badge&logo=HackerRank&logoColor=white\" alt=\"sssoad\" /></a>\n<a href=\"https://codeforces.com/profile/sssoad\" target=\"blank\"><img align=\"center\" src=\"https://img.shields.io/badge/Codeforces-445f9d?style=for-the-badge&logo=Codeforces&logoColor=white\" alt=\"sssoad\" /></a>\n<a href=\"https://www.leetcode.com/ssoad\" target=\"blank\"><img align=\"center\" src=\"https://img.shields.io/badge/-LeetCode-FFA116?style=for-the-badge&logo=LeetCode&logoColor=black\" alt=\"ssoad\"/></a>\n<a href=\"https://www.hackerearth.com/@sssoad\" target=\"blank\"><img align=\"center\" src=\"https://img.shields.io/badge/HackerEarth-%232C3454.svg?&style=for-the-badge&logo=HackerEarth&logoColor=Blue\" alt=\"@sssoad\" /></a>\n</p>\n\n## Languages and Tools\n| Property                                        | Data                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n|-------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Programming Language**                              | ![Python](https://img.shields.io/badge/Python-14354C?style=for-the-badge&logo=python&logoColor=white) ![Java](https://img.shields.io/badge/Java-ED8B00?style=for-the-badge&logo=openjdk&logoColor=white) ![JavaScript](https://img.shields.io/badge/JavaScript-323330?style=for-the-badge&logo=javascript&logoColor=F7DF1E)  ![Dart](https://img.shields.io/badge/Dart-0175C2?style=for-the-badge&logo=dart&logoColor=white) ![Kotlin](https://img.shields.io/badge/Kotlin-0095D5?&style=for-the-badge&logo=kotlin&logoColor=white) ![C#](https://img.shields.io/badge/C%23-239120?style=for-the-badge&logo=c-sharp&logoColor=white) ![C++](https://img.shields.io/badge/C%2B%2B-00599C?style=for-the-badge&logo=c%2B%2B&logoColor=white)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| **Frameworks**                              | ![Flutter](https://img.shields.io/badge/Flutter-02569B?style=for-the-badge&logo=flutter&logoColor=white) ![Kotlin](https://img.shields.io/badge/Kotlin%20JetPack%20Compose-0095D5?&style=for-the-badge&logo=kotlin&logoColor=white) ![Android](https://img.shields.io/badge/Android-3DDC84?style=for-the-badge&logo=android&logoColor=white) ![React](https://img.shields.io/badge/react-%2320232a.svg?style=for-the-badge&logo=react&logoColor=%2361DAFB) ![React Native](https://img.shields.io/badge/react_native-%2320232a.svg?style=for-the-badge&logo=react&logoColor=%2361DAFB) ![Django](https://img.shields.io/badge/Django-092E20?style=for-the-badge&logo=django&logoColor=white) ![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi) ![Flask](https://img.shields.io/badge/flask-%23000.svg?style=for-the-badge&logo=flask&logoColor=white)\n| **Domain Knownledge**                           | ![Software Development Badge](https://img.shields.io/badge/Software%20Developement-F9DC1e?style=for-the-badge&logo=Dev&logoColor=black) ![Data Structures and Agorithms](https://img.shields.io/badge/Data%20Structures%20&%20Algorithms-CC2927?style=for-the-badge&logo=Dev&logoColor=black)  [![Machine Learning Badge](https://img.shields.io/badge/-Machine%20Learning-01D277?style=for-the-badge&logoColor=white)](https://github.com/BEPb/BEPb) [![Computer Science Development Badge](https://img.shields.io/badge/-Computer%20Science-FAB040?style=for-the-badge&logoColor=white)](https://github.com/search?q=user%3ABEPb&type=Repositories) [![Electrical Engineering Development Badge](https://img.shields.io/badge/-Electrical%20Engineering-4C8CBF?style=for-the-badge&logoColor=white)](https://github.com/search?q=user%3ABEPb&type=Repositories)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n| **CI / CD**                                     | ![GitHub Actions](https://img.shields.io/badge/github%20actions-%232671E5.svg?style=for-the-badge&logo=githubactions&logoColor=white)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| **Databases**                                   | ![Firebase](https://img.shields.io/badge/Firebase-039BE5?style=for-the-badge&logo=Firebase&logoColor=white) ![MicrosoftSQLServer](https://img.shields.io/badge/Microsoft%20SQL%20Server-CC2927?style=for-the-badge&logo=microsoft%20sql%20server&logoColor=white) ![MySQL](https://img.shields.io/badge/mysql-%2300f.svg?style=for-the-badge&logo=mysql&logoColor=white) ![Postgres](https://img.shields.io/badge/postgres-%23316192.svg?style=for-the-badge&logo=postgresql&logoColor=white) ![SQLite](https://img.shields.io/badge/sqlite-%2307405e.svg?style=for-the-badge&logo=sqlite&logoColor=white)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| **OS**                                          | ![Windows](https://img.shields.io/badge/Windows-0078D6?style=for-the-badge&logo=windows&logoColor=white)  ![macOS](https://img.shields.io/badge/mac%20os-000000?style=for-the-badge&logo=macos&logoColor=F0F0F0)  ![Arch](https://img.shields.io/badge/Arch%20Linux-1793D1?logo=arch-linux&logoColor=fff&style=for-the-badge)                                                                                                                                                                                                                                                                       |\n| **Tools & Platform**                            | ![Visual Studio Code](https://img.shields.io/badge/Visual%20Studio%20Code-0078d7.svg?style=for-the-badge&logo=visual-studio-code&logoColor=white) ![Android Studio](https://img.shields.io/badge/Android%20Studio-3DDC84.svg?style=for-the-badge&logo=android-studio&logoColor=white) ![PyCharm](https://img.shields.io/badge/pycharm-143?style=for-the-badge&logo=pycharm&logoColor=black&color=black&labelColor=green) ![Git](https://img.shields.io/badge/git-%23F05033.svg?style=for-the-badge&logo=git&logoColor=white)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n| **Cloud Platform** | ![Google Cloud](https://img.shields.io/badge/GoogleCloud-%234285F4.svg?style=for-the-badge&logo=google-cloud&logoColor=white) ![Google Colab](https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&color=525252) ![Play Store](https://img.shields.io/badge/Google_Play-414141?style=for-the-badge&logo=google-play&logoColor=white) ![Heroku](https://img.shields.io/badge/heroku-%23430098.svg?style=for-the-badge&logo=heroku&logoColor=white)|\n| **Machine Learning / Deep Learning frameworks** | ![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white) ![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white) ![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white) ![OpenCV](https://img.shields.io/badge/opencv-%23white.svg?style=for-the-badge&logo=opencv&logoColor=white)|\n\n\n\n<h2>ðŸ“« Like to meet me?</h2>\nPick a slot if you'd like to meet me and chat about anything you are passionate about - but make sure to describe the agenda\n<br><br>\n<a href=\"https://calendly.com/ssoad/30min\" target=\"_blank\"><img width=\"498\" alt=\"meet_link\" src=\"https://user-images.githubusercontent.com/15426564/144297439-f530f383-e73e-41e0-9914-a9b7d3f432e5.png\"></a>\n<br><br>\n\n- ðŸ‘¨â€ðŸ’» All of my projects are available at [ssoad.github.io](ssoad.github.io)\n\n- ðŸ“ I regularly write articles on [ssoad.me](ssoad.me)\n\n- ðŸ“« How to reach me **mdsoad@gmail.com**\n\n- ðŸ“„ Know about my experiences [ssoad.me](ssoad.me)\n\n- âš¡ Fun fact **Completely Introvert**\n\n<!--START_SECTION:waka-->\n![Code Time](http://img.shields.io/badge/Code%20Time-1%2C327%20hrs%2049%20mins-blue)\n\n![Lines of code](https://img.shields.io/badge/From%20Hello%20World%20I%27ve%20Written-9.9%20million%20lines%20of%20code-blue)\n\n**ðŸ± My GitHub Data** \n\n> ðŸ“¦ 3.3 MB Used in GitHub's Storage \n > \n> ðŸ† 384 Contributions in the Year 2024\n > \n> ðŸ’¼ Opted to Hire\n > \n> ðŸ“œ 87 Public Repositories \n > \n> ðŸ”‘ 35 Private Repositories \n > \n**I'm a Night ðŸ¦‰** \n\n```text\nðŸŒž Morning                40 commits          â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   00.78 % \nðŸŒ† Daytime                542 commits         â£¿â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   10.51 % \nðŸŒƒ Evening                1428 commits        â£¿â£¿â£¿â£¿â£¿ï¿½ï¿½â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   27.68 % \nðŸŒ™ Night                  3149 commits        â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   61.04 % \n```\nðŸ“… **I'm Most Productive on Thursday** \n\n```text\nMonday                   515 commits         â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   09.98 % \nTuesday                  448 commits         â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   08.68 % \nWednesday                399 commits         â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   07.73 % \nThursday                 2161 commits        â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   41.89 % \nFriday                   437 commits         â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   08.47 % \nSaturday                 779 commits         â£¿â£¿â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   15.10 % \nSunday                   420 commits         â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   08.14 % \n```\n\n\nðŸ“Š **This Week I Spent My Time On** \n\n```text\nðŸ•‘ï¸Ž Time Zone: Asia/Dhaka\n\nðŸ’¬ Programming Languages: \nOther                    4 hrs 33 mins       â£¿ï¿½ï¿½â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   49.02 % \nPython                   2 hrs 42 mins       â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   29.18 % \nDart                     1 hr 35 mins        â£¿â£¿â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   17.21 % \nYAML                     19 mins             â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   03.47 % \nJSON                     3 mins              â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   00.65 % \n\nðŸ”¥ Editors: \nVS Code                  4 hrs 48 mins       â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   51.68 % \nChrome                   4 hrs 29 mins       â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   48.32 % \n\nðŸ’» Operating System: \nMac                      9 hrs 17 mins       â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿   100.00 % \n```\n\n**I Mostly Code in Dart** \n\n```text\nDart                     24 repos            â£¿â£¿â£¿â£¿â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   25.26 % \nPython                   24 repos            â£¿â£¿â£¿â£¿â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   25.26 % \nJavaScript               8 repos             â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   08.42 % \nJava                     8 repos             â£¿â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   08.42 % \nHTML                     4 repos             â£¿â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€   04.21 % \n```\n\n\n\n**Timeline**\n\n![Lines of Code chart](https://raw.githubusercontent.com/ssoad/ssoad/master/assets/bar_graph.png)\n\n\n Last Updated on 10/06/2024 17:36:07 UTC\n<!--END_SECTION:waka-->\n\n\n## My Current Stack Roadmap Status\n\n[![roadmap.sh](https://api.roadmap.sh/v1-badge/wide/646350e5410780a6d9b5a637?variant=dark&roadmaps=flutter%2Ccpp)](https://roadmap.sh)\n\n## My Github Stats\n<table align=\"center\">\n    <tr>\n        <td>\n            <a href=\"https://github.com/anuraghazra/github-readme-stats\"><img alt=\"Sohanuzzaman Soad's Github Stats\" src=\"https://github-readme-stats.vercel.app/api?username=ssoad&show_icons=true&count_private=true&theme=react&hide_border=true&bg_color=0D1117\" /></a>\n        </td>\n        <td>\n            <a href=\"https://github.com/anuraghazra/github-readme-stats\"><img alt=\"Sohanuzzaman Soad's Top Languages\" src=\"https://github-readme-stats.vercel.app/api/top-langs/?username=ssoad&langs_count=8&count_private=true&layout=compact&theme=react&hide_border=true&bg_color=0D1117\" /></a>\n        </td>\n    </tr>\n</table>\n\n\n<p align=\"center\">\n        <img src=\"https://streak-stats.demolab.com?user=ssoad&theme=react&hide_border=false&background=0D1117\"/>\n</p>\n\n"},"licenseInfo":{"id":"MDc6TGljZW5zZTEz"},"primaryLanguage":{"name":"PowerShell","color":"#012456"},"languages":{"nodes":[{"name":"PowerShell","color":"#012456"}]}}]}}}}